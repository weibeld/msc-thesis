\lettrine{I}{n this chapter} we treat several topics that serve as a background for the rest of the thesis. In particular, the goal of this chapter is to set the stage for our description of the Fribourg construction in Chapter~\ref{chap_construction}, and the setup of our empirical performance investigation in Chapter~\ref{chap_investigation}, as well as the corresponding results in Chapter~\ref{chap_results}.

In Section~\ref{2_automata} we summarise some aspects about Büchi automata and other types of \om-automata that are relevant to Büchi complementation. In Section~\ref{2_run_analysis}, we describe the principal run analysis techniques for non-deterministic automata. This topic has a particular relevance to Büchi complementation. Furthermore, one of the run analysis techniques that we describe in this section, reduced split trees, is the core of the Fribourg construction. In Section~\ref{2_review}, we provide a review of the Büchi complementation constructions that have been proposed since the introduction of Büchi automata in 1962. We organise the presentation of these constructions along the four main Büchi complementation approaches, Ramsey-based, determinisation-based, rank-based, and slice-based.

\section{Büchi Automata and Other Omega-Automata}
\label{2_automata}
Büchi automata are a type of \om-automata. These are finite state automata that run on infinite words (so-called \om-words). In principle, \om-automata look the same as ordinary finite state automata on finite words. The difference between \om-automata and automata on finite words is their acceptance condition. An automaton on finite words accepts a word, if after finishing reading it, the automaton is in an accepting state. For \om-automata, this acceptance condition is not possible, because an \om-automaton never finishes reading a word (because the word ``never ends''). Instead, the acceptance condition of \om-automata is defined on the set of the so-called \textit{infinitely recurring states}. In this section, we are going to describe this and other concepts.

In Section~\ref{2_buchi_automata} we first describe Büchi automata, and in Section~\ref{2_om-automata} we describe the principal other types of \om-automata, in particular, Muller, Rabin, Streett, and parity automata. In this section, we also introduce a shorthand notation for different types of \om-automata that we will use throughout the thesis.

Note that in what follows (as well as in the rest of the thesis) we omit overly formal notation. For the purpose of our thesis, such a rigorous approach is not necessary. For more comprehensive and formally rigorous treatments of \om-automata, we refer to the works by Thomas~\cite{Thomas:1991,1996_thomas}, or Wilke~\cite{2014_wilke}.

\subsection{Büchi Automata}
\label{2_buchi_automata}
In this section, we summarise the most relevant aspects of Büchi automata. This includes the acceptance condition of Büchi automata, the expressiveness of non-deterministic and deterministic Büchi automata, and the characteristics of the complementation of deterministic and non-deterministic Büchi automata. In the course of this, we always stress the difference between deterministic and non-deterministic Büchi automata, as this is one of the main sources for the high complexity of Büchi complementation~\cite{niessner1997deterministic}.  

\subsubsection{Definition and Acceptance Condition}
A non-deterministic Büchi automaton $A$  is defined by the 5-tuple $A = (Q, \Sigma, \delta, q_0 F)$ with the following components:
\begin{itemize}
\item $Q$: a finite set of states
\item $\Sigma$: a finite alphabet
\item $\delta$: a transition function, $\delta: Q \times \Sigma \rightarrow 2^Q$
\item $q_0$: an initial state, $q_0 \in Q$
\item $F$: a set of accepting states, $F \subseteq Q$
\end{itemize}

Note that this is the same definition as for ordinary non-deterministic finite state automata on finite words~\cite{hopcroft2006automata}. The difference between Büchi automata and automata on finite words is only the acceptance condition of Büchi automata that we describe below. For deterministic Büchi automata, the definition is similar as the above one, but with a different transition function $\delta$ that returns none or a single state, instead of a set of states

An important concept in automata theory the notion of a \textit{run} of an automaton on a given word. A run $\rho$ of automaton $A$ on word $\alpha$ is a sequence of states $q \in Q$ that $A$ visits in the process of reading $\alpha$. For finite words, the length of a run is finite. However, for \om-words, the length of a run may be infinite. Note that deterministic automata have at most one run for a given word, whereas non-deterministic automata may have multiple possible runs for the same word.

The Büchi acceptance condition decides whether a run $\rho$ is accepting or non-accepting. This in turn determines the acceptance or non-acceptance of a word: a word $\alpha$ is accepted by an automaton $A$, if and only if it has at least one accepting run in $A$. The decision whether a run $\rho$ is accepting or non-accepting is based on the set of \textit{infinitely recurring states} of $\rho$ that we denote by $\textsf{inf}(\rho)$. This set contains all the states that occur infinitely often in $\rho$. In particular, the Büchi acceptance condition is as follows:

\begin{quote}
\centering
\textit{Run $\rho$ is accepting} $\Longleftrightarrow$ $\textsf{inf}(\rho)$ \textit{contains at least one accepting state}
\end{quote}

That is, a run is accepting, if and only if the run contains at least one accepting state infinitely often. Formally, this can be written as $\textsf{inf}(\rho) \cap F \neq \varnothing$. 

An intuitive way for describing the Büchi acceptance condition has been given by Vardi~\cite{1996_vardi}. Imagine the automaton having a green light that blinks whenever the automaton visits an accepting state. A run is accepted if and only if we observe the green light blinking infinitely many times. This description works, because, the fact that there are only finitely man accepting states implies that at least one accepting state is being visited infinitely often, if the light blinks infinitely many times.

\subsubsection{Expressiveness}
A peculiarity of Büchi automata is that deterministic and non-deterministic automata are \textit{not} expressively equivalent. In particular, the class of languages corresponding to the deterministic Büchi automata is a strict subset of the class of languages corresponding to the non-deterministic automata. This result has been proved by Büchi himself in his 1962 paper~\cite{buchi1960decision}.

This contrasts, for example, with finite state automata on finite words. In this case, non-deterministic and deterministic automata are expressively equivalent, and consequently every non-deterministic automaton can be turned into an equivalent deterministic automaton. With Büchi automata, however, this is not possible, because there exist languages that can be expressed by a non-deterministic Büchi automaton, but not by a deterministic one. An example of such a language is $(0+1)^*1^\omega$, that is, the language of all words of 0 and 1 ending with an infinite sequence of 1. A non-deterministic automaton representing this language, cannot be turned into an equivalent deterministic automaton~~\cite{1996_vardi, 2002_roggenbach}. Because of this fact, we say that Büchi automata can \textit{in general} not be determinised to other Büchi automata. This fact has implications on the complementation of non-deterministic Büchi automata, as we will see below.

The class of languages that is equivalent to the \textit{non-deterministic} Büchi automata is the class of \textit{\om-regular languages}. A formal description of the \om-regular languages can be found, for example, in~\cite{Thomas:1991,1996_thomas,2014_wilke}. The class of languages that is equivalent to deterministic automata is consequently a strict subset of the \om-regular languages.

% Büchi automata are expressively equivalent to the \om-regular languages. This means that every language recognised by a Büchi automaton is an \om-regular language, and that for every \om-regular language there exists a Büchi automaton that recognises it. This property has been proved by Büchi himself in his initial publication in 1962~\cite{buchi1960decision}.

% However, this equivalence with the \om-regular languages does only hold for \textit{non-deterministic} Büchi automata. Deterministic Büchi automata are less expressive than non-deterministic Büchi automata. In particular, the class of languages represented by deterministic Büchi automata is a strict subset of the class of languages represented by non-deterministic Büchi automata. This property has also been proved by Büchi~\cite{buchi1960decision}.

% This means that there exist languages that can be recognised by a non-deterministic Büchi automaton, but not by a deterministic one. A typical example is the language $(0+1)^*1^\omega$. This is the language of all words consisting of 0 and 1 with a finite number of 0 and an infinite number of 1. It is proved in various publications that this language can be recognised by a non-deterministic Büchi automaton, but not by a deterministic Büchi automaton~\cite{1996_vardi}\cite{2002_roggenbach}.

% The most important consequence of this fact is that Büchi automata can, in general, not be determinised. This means that it is not possible to turn \textit{every} non-deterministic Büchi automaton into a deterministic one. This contrasts with the case of the classical finite state automata on finite words, where \textit{every} non-deterministic automata (NFA) can be turned into a deterministic automaton (DFA), by the means of, for example, the subset constrution introduced by Rabin and Scott in 1959~\cite{1959_rabin}.

% It has been stated that the fact that Büchi automata can in general not be determinised is the main reason that Büchi complementation is such a hard problem~\cite{niessner1997deterministic}. We will see why this is the case below.

\subsubsection{Complementation}
Non-deterministic Büchi automata are closed under complementation. This means that the complement of every non-deterministic Büchi automaton is another non-deterministic Büchi automaton. This result has been proved by Büchi in his 1962 paper~\cite{buchi1960decision}\footnote{Actually, the proof of closure under complementation of non-deterministic Büchi automata was a necessary step for Büchi to prove the equivalence of Büchi automata and S1S formulas (Büchi's Theorem). In order to prove this closure under complementation, Büchi described the first Büchi complementation construction.}. Deterministic Büchi automata, on the other hand, are not closed under complementation~\cite{Thomas:1991}. In particular, the complement of a deterministic Büchi automaton is still a Büchi automaton, however, it may be a non-deterministic one.

As we already mentioned, the algorithmic difficulty and complexity of complementation is very different for deterministic and non-deterministic automata. For deterministic Büchi automata, there exists a simple construction, introduced in 1987 by Kurshan~\cite{Kurshan198759}. This construction can complement a deterministic Büchi automaton to a non-deterministic Büchi automaton in polynomial time and linear space.

For non-deterministic Büchi automata, however, there exists no easy solution. The main reason is that Büchi automata can in general not be determinised. If they could be determinised, then a solution would be to transform a non-deterministic Büchi automaton to an equivalent deterministic Büchi automaton (determinise the non-deterministic Büchi automaton), and then complement the deterministic Büchi automaton with Kurshan's construction. This is actually the approach that is used for the complementation of non-deterministic automata on finite words: determinise a non-deterministic automaton with the subset construction~\cite{1959_rabin}, and then trivially complement the deterministic automaton by making its accepting states non-accepting, and its non-accepting states accepting. Unfortunately, for Büchi automata this approach is not possible, and other ways for constructing the complement of a non-deterministic Büchi automaton have to be found. This can be seen as the main reason that Büchi complementation is such a hard problem~\cite{niessner1997deterministic}.

% Büchi automata are closed under complementation. This means that the complement of every Büchi automaton (non-deterministic or deterministic) is in turn a Büchi automaton. This result has been proved by Büchi in his introducing paper from 1962~\cite{buchi1960decision}.

% The difficulty of the concrete complementation problem does however strongly depend on whether the Büchi automaton is deterministic or non-deterministic. For deterministic Büchi automata, the complementation is ``easy'' and regarded as a ``solved problem''. There is a well-known construction introduced by Kurshan in 1987 that complements a deterministic Büchi automaton in polynomial time~\cite{Kurshan198759}. The resulting complement is a non-deterministic Büchi automaton and has a size that is at most the double of the input automaton.

% For non-deterministic Büchi automata, on the other hand, the complementation problem is much more difficult. The main reason is, as mentioned, the fact that non-deterministic Büchi automata cannot be determinised. If they could be determinised, then a non-deterministic Büchi automata could be complemented by first determinising it, and then complementing the deterministic automaton with the Kurshan construction. If the determinisation construction would also be efficient (that is, having polynomial complexity), then we would have an efficient complementation procedure for non-deterministic Büchi automata. In this case, ``Büchi complementation'' would probably be no active research topic but rather a solved problem.

% However, non-deterministic Büchi automata cannot be determinised, and hence this straightforward complementation approch is not possible. Consequently, different ways for complementing non-deterministic Büchi automata have to be found, and these ways turn out to be very complex. It is this complexity that makes Büchi complementation an active research topic as, regarding the concrete usages of Büchi complementation in, for example, model checking, it is of great importance to find more and more efficient ways to complement non-deterministic Büchi automata. 


\subsection{Other Omega-Automata}
\label{2_om-automata}
After the introduction of Büchi automata in 1962, several other types of \om-automata have been introduced. These automata differ from Büchi automata only in their acceptance condition, that is, in the way they decide whether a run $\rho$ is accepting or non-accepting. All these acceptance condition are however based on the set of infinitely recurring states $\textsf{inf}(\rho)$ of a run $\rho$. The following are the most important of these alternative \om-automata along with the year of their introduction.

\begin{itemize}
\item Muller automata (1963)~\cite{1963_muller}
\item Rabin automata (1969)~\cite{rabin1969decidability}
\item Streett automata (1982)~\cite{Streett1982121}
\item Parity automata (1985)~\cite{1985_mostowski}
\end{itemize}

Some of these automata types are used in complementation constructions, especially in determinisation-based complementation constructions (see Section~\ref{2_review}). Table~\ref{acc_conditions} lists a formal description of the Muller, Rabin, Streett, and parity acceptance conditions, along with the Büchi acceptance condition for comparison.

% After the introduction of Büchi automata in 1962, several other types of \om-automata have been proposed. The most notable ones are Muller automata (Muller, 1963~\cite{1963_muller}), Rabin automata (Rabin, 1969~\cite{rabin1969decidability}), Streett automata (Streett, 1982~\cite{Streett1982121}), and parity automata (Mostowski, 1985~\cite{1985_mostowski}).

% Description in \cite{2014_wilke}

% These automata differ from Büchi automata only in their acceptance condition, that is, the condition that a run $\rho$ is accepted. Table~\ref{acc_conditions} gives a formal definition of the acceptance conditions of these types of \om-automata.

\begin{table}[htb]
\centering
\begin{tabular}{lll}
\hline
Type & Definitions & Condition \\
\hline
Muller  & $U \subseteq 2^Q$ &
          $\textsf{inf}(\rho) \in U$ \\
Rabin   & $\{(U_1,V_1),\dots,(U_r,V_r)\},\,U_i, V_i \subseteq Q$ &
          $\exists i: \textsf{inf}(\rho) \cap U_i = \varnothing \, \wedge \, \textsf{inf}(\rho) \cap V_i \neq \varnothing$ \\
Streett & $\{(U_1,V_1),\dots,(U_r,V_r)\},\,U_i, V_i \subseteq Q$ &
          $\forall i: \textsf{inf}(\rho) \cap U_i \neq \varnothing \, \vee \, \textsf{inf}(\rho) \cap V_i = \varnothing$ \\
Parity  & $\pi: Q \rightarrow \{1,\dots,k\},\,k \in \mathbb{N}$ &
          $\textsf{min}(\{\pi(q)\;|\;q \in \textsf{inf}(\rho) \}) \; \textsf{mod} \; 2 = 0$ \\
Büchi   & &
          $\textsf{inf}(\rho) \cap F \neq \varnothing$ \\
\hline
\end{tabular}
\caption{Acceptance conditions of Muller, Rabin, Streett, parity, and Büchi automata. Note that $Q$ denotes the set of states and $F$ the set of accepting states of the corresponding automaton.}
\label{acc_conditions}
\end{table}

In the following, we briefly explain the acceptance conditions of Muller, Rabin, Streett, and parity automata in words. Note that more detailed descriptions of these acceptance conditions can be found, for example, in~\cite{1998_loeding_msc}, or~\cite{2014_wilke}.

{\setlist[description]{leftmargin=0.5cm, itemsep=\parskip}
\begin{description}
\item[Muller acceptance condition]
Includes a set $U$ of subsets of states. A run $\rho$ is accepting if and only if $\textsf{inf}(\rho)$ equals one of the pre-defined subsets of $U$. The Muller acceptance condition is the most general one, and the Rabin, Streett, parity, and Büchi acceptance conditions can be expressed as a Muller acceptance condition~\cite{1998_loeding_msc,2014_wilke}.

\item[Rabin acceptance condition]
Includes a list of pairs $(U, V)$ where $U$ and $V$ are subsets of states. A run $\rho$ is accepting if and only if \textit{there is} at least one pair for which $U$ does not contain any states of $\textsf{inf}(\rho)$ \textit{and} $V$ contains at least one state of $\textsf{inf}(\rho)$. A pair $(U, V)$ is called a Rabin pair.

\item[Streett acceptance condition]
Inludes a list of pairs $(U, V)$ where $U$ and $V$ are subsets of states. A run $\rho$ is accepting if and only if \textit{for all} the pairs either $U$ contains at least one state of $\textsf{inf}(\rho)$ \textit{or} $V$ does not contain any states of $\textsf{inf}(\rho)$. A pair $(U, V)$ is called a Streett pair. Note that the Streett condition is the dual of the Rabin condition. This means that if we have two identical Rabin and Streett automata with an identical list of pairs, then the Streett automaton is the complement of the Rabin automaton~\cite{klein2005linear}.

\item[Parity acceptance condition]
Assigns a number to each of the states of the automaton. A run $\rho$ is accepting if and only if the smallest-numbered element of $\textsf{inf}(\rho)$ has an even number. The numbers that are assigned to the states are sometimes called colours~\cite{1999_loeding}.
\end{description}}

Regarding the expressiveness of these automata, it turns out that they are all equivalent to non-deterministic Büchi automata, and thus to the \om-regular languages~\cite{2014_wilke}. This holds for non-deterministic \textit{and} deterministic automata of these types. That means that, unlike Büchi automata, deterministic and non-deterministic Muller, Rabin, Streett, and parity automata are expressively equivalent.

At this point we introduce a notation that we will occasionally use for denoting different types of \om-automata. This notation has been used by Piterman~\cite{2006_piterman} and later by Tsai et al.~\cite{2011_tsai}. It consists of three-letter acronyms of the form
\[
\{N, D\} \times \{B, M, R, S, P\} \times W
\]
The first letter specifies whether the automaton is non-deterministic ($N$) or deterministic ($D$). The second letter stands for the acceptance condition: $B$ for Büchi, $M$ for Muller, $R$ for Rabin, $S$ for Streett, and $P$ for parity. The last letter specifies on which structure the automaton runs. In our case these are always words, thus the last letter is always $W$. For example, NBW stands for non-deterministic Büchi automaton, DBW stands for deterministic Büchi automaton, NMW stands for non-deterministic Muller automaton, DMW stands for deterministic Muller automaton, and so on.


% The Rabin and Streett acceptance conditions are the negations of each other. This means that a run satisfies the Rabin acceptance condition, if and only if it does not satisfy the Streett acceptance condition. They both use a list of pairs of state sets. A run is accepted if there is a pair for which the first element contains an infinitely occuring state and the second element does not (Rabin condition), or if for all pairs the first elements do not contain an infinitely occuring state or all the second elements do contain an infinitely occuring state (Streett condition).
% \end{description}}

% All these automata types are equivalent to the \om-regular languages~\cite{2014_wilke}.

% \subsubsection{Muller}
% For the Muller acceptance condition, the set of infinitely occuring states of a run ($\textsf{inf}(\rho)$) must match one of several predefined set of states. The Muller acceptance condition is the most general one, and all the other acceptance conditions in Table~\ref{acc_conditions} can be expressed by the Muller condition~\cite{1999_loeding}.

% \subsubsection{Rabin}
% The Rabin and Streett acceptance conditions are the negations of each other. This means that a run satisfies the Rabin acceptance condition, if and only if it does not satisfy the Streett acceptance condition. They both use a list of pairs of state sets. A run is accepted if there is a pair for which the first element contains an infinitely occuring state and the second element does not (Rabin condition), or if for all pairs the first elements do not contain an infinitely occuring state or all the second elements do contain an infinitely occuring state (Streett condition).

% The parity condition assigns a number (color) to each state. A run is accpted if and only if the infinitely often occuring state with the smallest number has an even number.

% At this point we will start using a notation for the different types of \om-automata that has been used by Piterman~\cite{2006_piterman} and also later by Tsai et al.~\cite{2011_tsai}. It consists of a three-letter acronymes of the form $\{D, W\} \times \{B, M, R, S, P\} \times W$. The first letter, $D$ or $N$ specifies whether the automaton is deterministic or non-deterministc. The second letter is the initial letter of the automaton type, that is, $B$ for Büchi, $M$ for Muller, $R$ for Rabin, $S$ for Streett, and $P$ for parity automata. The third letter specifies on which the automaton runs, and is in our case always $W$ meaning ``words''. Thus, throughout this thesis we will use DBW for deterministic Büchi automata, NBW for non-deterministic Büchi automata, DMW for deterministic Muller automata, and so on.

% Regarding the expressiveness of Muller, Rabin, Streett, and parity automata, it turned out that they are equivalent to the \om-regular languages~\cite{Thomas:1991}. However, unlike Büchi automata, for Muller, Rabin, Streett, and parity automata this equivalence holds for deterministic \textit{and} non-deterministic automata. That is, these automata \textit{can} be determinised. In summary, there is thus an equivalence between NBW, DMW, NMW, DRW, NRW, DSW, NSW, DPW, NPW, and the \om-regular languages. Only the DBW, as a special case, has a different expressiveness, which is a strict subset of the expressivities of the other automata types. 



\section{Run Analysis for Non-Deterministic Automata}
\label{2_run_analysis}
As mentioned, in a deterministic automaton, every input word has at most one run. In a non-deterministic automaton, however, every input word may have multiple runs. The analysis of the different runs of a non-deterministic automaton on a given input word is called \textit{run analysis} and is central to Büchi complementation constructions.

The reason that run analysis is central to Büchi complementation constructions is as follows. For complementing a Büchi automaton, we are given a non-deterministic Büchi automaton $A$, and we attempt to construct its complement $B$. For constructing $B$ we have in fact to decide for every word $\alpha$ whether $B$ must accept it or not. This decision is intrinsically tied to the set of \textit{all} the runs of $A$ on $\alpha$ as follows:

\begin{quote}
\centering
\textit{$B$ accepts $\alpha$} $\Longleftrightarrow$ \textit{All the runs of $A$ on $\alpha$ are non-accepting}
\end{quote}

$B$ must accept a word $\alpha$, if and only if \textit{all} the runs of $A$ on $\alpha$ are non-accepting. If, for example, $A$ has 10 runs on $\alpha$, and 9 of them are non-accepting and one is accepting, then $A$ still accepts the word $\alpha$, and consequently, $B$ must not accept it. Only if all of the 10 runs of $A$ on $\alpha$ are non-accepting, $A$ does not accept $\alpha$, and consequently $B$ must accept $\alpha$. This means that for constructing the complement $B$, we need to consider \textit{all} the runs of the input automaton $A$ on specific words. The way this can be done is by a run analysis of $A$.

In this section, we present the principal run analysis techniques for non-deterministic Büchi automata~\cite{2014_wilke}. We start with \textit{run DAGs} (DAG stands for directed acyclic graphs) in Section~\ref{2_run_dags}. Then in Sections~\ref{2_run_trees}, \ref{2_split_trees}, and~\ref{2_red_split_trees}, we present three techniques that are based on trees. These techniques are called \textit{run trees}, \textit{split trees}, and \textit{reduced split trees}, and they are increasingly sophisticated in this order. Note that reduced split trees lie at the heart of the Fribourg construction that we describe in Chapter~\ref{chap_construction}.

In the following subsections, we will give examples for the different run analysis techniques that are based on the non-deterministic Büchi automaton in Figure~\ref{ex_aut_1}. Note that the alphabet of this automaton is $\Sigma=\{a\}$, and thus the only \om-word in $\Sigma^\omega$ is $a^\omega$. That is, this automaton can only process the single word. However, as can be seen, the automaton has multiple (in fact, infinitely many) runs for this word.

\begin{figure}[htb]
\centering
\Automaton
\caption{Non-deterministic Büchi automaton used as an example automaton in the present section.}
\label{ex_aut_1}
\end{figure}


\subsection{Run DAGs}
\label{2_run_dags}
Run DAGs arrange all the runs of an automaton $A$ on a word in a directed acyclic graph (DAG). This graph can be thought of as a matrix with rows and columns. The rows are called levels, and each column corresponds to a state of $A$. Each level $i$ (starting from 0) corresponds to the situation after reading the first $i$ symbols of the word. Figure~\ref{run_dag} shows the first five levels of the run DAG of the example automaton in Figure~\ref{ex_aut_1} on the word \aom.

\begin{figure}[htb]
\centering
\RunDAG
\caption{First five levels of the run DAG for the runs of the automaton in Figure~\ref{ex_aut_1} on the word \aom.}
\label{run_dag}
\end{figure}

Note that throughout this thesis, we use rectangles with rounded corners for states of automata, and rectangles with sharp corners for vertices of graphs and nodes of trees. In graphs and trees, we indicate vertices or nodes that correspond to accepting automaton states with double-bordered rectangles.

As can be seen in Figure~\ref{run_dag}, every path of a run DAG corresponds to a run of the automaton on the given word. A run DAG is a structure that is able to represent an infinite number of runs by keeping a finite width. The width of a run DAG is the number of states on a level, which equals the number of states of the automaton. The number of levels of a run DAG is infinite for \om-words. A formal description of run DAGs can be found, for example, in \cite{fogarty2013unifying}.

Run DAGs are the basic structure for the rank-based complementation constructions, that we review in Section~\ref{2_rank-based}. Regarding this application, the fact that run DAGs have finite width is important, because in these complementation constructions, the levels of run DAGs are mapped to states of the output automaton.

\subsection{Run Trees}
\label{2_run_trees}
Trees are after DAGs the second structure that is used for run analysis. Run trees are the most basic of these tree structures. A run tree is basically a direct unwinding of all the runs of an automaton on a word as a tree. Figure~\ref{run_tree} shows the first five levels of the run tree for the automaton in Figure~\ref{ex_aut_1} on the word \aom.

% Run trees are the simplest form of the different tree variants. A run tree is basically a direct unwinding of all the runs of an automaton on a word in tree form. Uach node in the tree represents a state of the automaton, and each non-deterministic transition in the automaton is representd in the tree as a child of a node.

% Figure~\ref{run_tree} shows the first few levels of the run tree of the example automaton $A$ (see Figure~\ref{ex_aut_1}) on the word \aom. A note on notation: during this thesis we will adopt the convention to use rectangles with sharp corners for nodes of a tree. Furthermore, we will use double-lined rectangles for nodes that correspond to a accepting states of the automaton.

\begin{figure}[htb]
\centering
\RunTree
\caption{First five levels of the run tree for the runs of the automaton in Figure~\ref{ex_aut_1} on the word \aom.}
\label{run_tree}
\end{figure}

As can be see in Figure~\ref{run_tree}, there is a one-to-one mapping of paths in a run tree (from the root to the leaves) to runs of the corresponding automaton. This means that if the automaton has an infinite number of runs on a given word, then the corresponding run tree has an infinite maximum width. This makes run trees impractical to be used in Büchi complementation construction. The following tree techniques, split trees and reduced split trees, sacrifice a part of the information about individual runs, for the benefit of making the tree more compact.

\subsection{Split Trees}
\label{2_split_trees}
A split tree is basically a run tree where the accepting and non-accepting children of every node are merged to two separate children. Consequently, a node of a split tree does not represent a single state of the automaton, but a set of states. The reduction of the number of children to at most 2, makes the split tree a binary tree. Figure~\ref{split_tree} shows the first five levels of the split tree of the automaton in Figure~\ref{ex_aut_1} on the word \aom.

\begin{figure}[htb]
\centering
\SplitTreeRightLeft
\caption{First five levels of the split tree for the runs of the automaton in Figure~\ref{ex_aut_1} on the word \aom.}
\label{split_tree}
\end{figure}

Split trees sacrifice a part of the information about individual runs. For example, in the split tree in Figure~\ref{split_tree}, we can see that there must be a run that starts in \q0 (root node) and is in \q0 after reading four symbols (leftmost node on level 4). However, the split tree does not provide the exact sequence of states of this run. All that it reveals is that the sequence is $q_{0}q^1_?q^2_?q^3_?q_{0}$, where each $q^i_?$ is either \q0 or \q2. The run tree in Figure~\ref{run_tree}, on the other hand, shows the actual sequence of states, which is \q0\q0\q0\q0\q0, unambiguously. Thus, the run tree contains more information than the split tree.

However, the split tree still contains an important piece of information. Namely that the sequence $q_{0}q^1_?q^2_?q^3_?q_{0}$, whatever it really looks like, does not contain an accepting state. This is because $q^i_?$ can only be \q0 or \q2, which are both non-accepting. It turns out that, with regard to  Büchi complementation, this is actually the needed information.

Split trees in fact embody a modified subset construction that does not mix accepting and non-accepting states. The result of applying such a construction to a non-deterministic automaton is an equivalent non-deterministic automaton whose degree of non-determinism is reduced to two (which means that each state has at most two successors for every alphabet symbol). Such a construction has been described by Ultes-Nitsche~\cite{UltesNitsche2007107}.

A formal description of split trees can be found, for example, in~\cite{vardi2007automata} or \cite{fogarty2013unifying}. Split trees are clearly more compact than run trees. However, their width can still become infinitely large. In the next section, we present a tree structure that further reduces the information contained in the tree, with the benefit of limiting the width of the tree to a finite number.

% However, it turns out that with regard to Büchi complementation this detailed information that run trees provide is not necessary. Because, whatever the actual sequence $q_{0}q^1_?q^2_?q^3_?q_{0}$ looks like, it is certain that it does not contain an accepting state, because 


% It turns out, however, that with regard to Büchi complementation this detailed information is not necessary. Because what we \textit{can} deduce from the split tree is, whathever the unknown states in $q_{0}q^1_?q^2_?q^3_?q_{0}$ are, they are non-accepting

%  a part of a run from \q0 in the root to \q0 on the fifth level. However, we cannot recognise the exact sequence of states of this run chunk, but only that it must be of the form $q_{0}q^1_?q^2_?q^3_?q_{0}$, where $q^1_?$, $q^2_?$, and $q^3_?$ are either \q0 or \q2. In the corresponding run tree in Figure~\ref{run_tree}, we see that the sequence of states is actually \q0\q0\q0\q0\q0. However, it turns out that, with respect to Büchi complementation, this information is not necessary. Because what we can deduce from the split tree is whathever the unknown states of $q_{0}q^1_?q^2_?q^3_?q_{0}$ are, they must be non-accepting states, and consequently, the entire sequence consists of only non-accepting states. 

% Descriptions: \cite{vardi2007automata}



% Compared to run trees, split trees give up information on individual runs. By looking at the split tree in Figure~\ref{split_tree}, we can see that, for example, there must be a run from \q0 in the root to \q0 at level 4, but we cannot see which states this run visits on its way. What we can however see is that this run for sure does not visit any accepting states, but only non-accepting states. It turns out that with regard to Büchi complementation, this is the actually essential information that we need to know about runs. 

% Split trees in fact embody a modified subset construction where accepting and non-accepting successor input-states are not mixed and added as two separate states to the output automaton. Applying this construction to an NBW results in an equivalent NBW whose degree of non-determinism is however reduced to two. Such a construction has been described in~\cite{UltesNitsche2007107}.

% In our split tree in Figure~\ref{split_tree} we always put the accepting child to the right of the non-accepting child. This convention is necessary for a property of split trees that leads to \textit{reduced} split trees (see next section), namely the presence or ``greedy'' rightmost runs. Note that the reverse convention, putting the accepting child to the left of the non-accepting child, is also possible. We refer to the former case (accepting right, non-accepting left) as the \textit{right-to-left} version, and to the latter (accepting left, non-accepting right) as the \textit{left-to-right} version.


\subsection{Reduced Split Trees}
\label{2_red_split_trees}
Reduced split trees are in fact split trees with some nodes removed. The rule is that on each level, going from right to left or from left to right, only the first occurrence of each state is kept, and the others are not included in the nodes of the tree. If in this way all the states of a node are omitted, then the node is not added to the tree. This limits the maximum width of the tree to the number of states of the corresponding automaton, because there cannot be more nodes than states.

The direction in which the first occurrence of a state is determined depends on whether so-called right-to-left or left-to-right split trees are used. In \textit{right-to-left} split trees, the accepting child is put to the right of the non-accepting child. The split tree in Figure~\ref{split_tree} is thus a right-to-left split tree. In \textit{left-to-right} split trees, on the other hand, the accepting child is put to the left of the non-accepting child. In the literature both versions are used. For example, Vardi and Wilke~\cite{vardi2007automata} use the left-to-right version, whereas Fogarty et al.~\cite{fogarty2013unifying} use the right-to-left version. In this thesis, we use exclusively right-to-left split trees.

In a right-to-left reduced split tree, the levels are processed from right to left. This means that only the rightmost occurrence of each state on a level is kept and the others are omitted. Figure~\ref{reduced_split_tree} shows the first five levels of the reduced split tree of the automaton in Figure~\ref{ex_aut_1} on the word $a^\omega$.

% Reduced split trees are split trees where only one occurrence of a state on each level is kept and the others are removed. The state that is kept is either the rightmost one, if right-to-left split trees ar used, or the leftmost one, if left-to-right split trees are used. While both versions are used in the literature, in this this thesis, we will use the right-to-left version. Figure~\ref{reduced_split_tree} shows the first few levels of the (right-to-left) reduced split tree of the automaton $A$ (Figure~\ref{ex_aut_1}) on the word \aom.

\begin{figure}[htb]
\centering
\ReducedSplitTreeRightLeft
\caption{First five levels of the reduced split tree for the runs of the automaton in Figure~\ref{ex_aut_1} on \aom.}
\label{reduced_split_tree}
\end{figure}

As can be seen in Figure~\ref{reduced_split_tree}, each level contains at most one occurrence of each of the states \q0, \q1, and \q2. Comparing the reduced split tree in Figure~\ref{reduced_split_tree} with the split tree in Figure~\ref{split_tree} reveals which states have been omitted in the reduced split tree. The root level and level~1 are similar in both trees. On level~2, the state \q2 in the leftmost node is omitted. This is because there is already a \q2 farther to the right, namely in the rightmost node of level~2. In level 3, there are two omissions of \q2 for the same reason. One of them causes an entire node to disappear, because this node contained \q2 as its only state. Finally, on level 4, there are three omissions of \q2.

In the following, we explain what this omission of states entails and why the resulting ``truncated'' run analysis is still usable for Büchi complementation construction. By omitting states, we obviously omit runs from the tree. This omission of runs is targeted at so-called \textit{re-joining runs}. Re-joining runs are runs that after a certain number of steps end up in the same state again. For example, the automaton from Figure~\ref{ex_aut_1} has seven re-joining runs that after four steps end up in the state \q2. This can be easily seen in the corresponding run tree in Figure~\ref{run_tree}, because it has seven nodes containing \q2 on level~4. A reduced split tree keeps exactly one of a group of re-joining runs and removes the others. This can be seen in the reduced split tree in Figure~\ref{reduced_split_tree} which contains only one run from \q0 to \q2 in four steps, because it contains only one occurrence of \q2 on level~4.

The run that is kept is referred to as the \textit{rightmost run}. This name comes from the fact that such a run is located rightmost of a group or re-joining runs in the tree\footnote{Note that everything we explain here is also valid for left-to-right split trees, but one has to exchange \textit{right} and \textit{rightmost} with \textit{left} and \textit{leftmost}, respectively.}. The rightmost run of a group of re-joining runs has the following crucial property:

\begin{quote}
\centering
\textit{Any re-joining run is accepting} $\Longrightarrow$ \textit{The rightmost re-joining run is accepting}
\end{quote}

That is, if a group of re-joining runs contains an accepting run, then the rightmost run is accepting too. On the other hand, if the rightmost run is non-accepting, then all the other re-joining runs are non-accepting as well. A proof of this relation can be found, for example, in~\cite{vardi2007automata} (Lemma 2.6).

Practically, this means that we can reduce the existential question about the presence of acceptance in a group of runs to the rightmost run. Remember that for Büchi complementation we are interested in exactly such an existential question: is there an accepting run of the automaton $A$ on the word $\alpha$? If yes (it does not matter how many accepting runs there are), then $A$ accepts $\alpha$ and the complement must not accept it. If no, then $A$ does not accept $\alpha$ and the complement must accept it. By considering only the rightmost runs, we can still reliably answer this question.

Thus, reduced split trees entail a significant reduction of the number of runs to be analysed. However, they still retain all information that is needed for Büchi complementation. Furthermore, this reduction of runs limits the width of the trees to a finite number. This makes reduced split trees usable for Büchi complementation constructions, because in these construction levels of reduced split trees define the states of the constructed automaton. The type of constructions that are based on reduced split trees are the slice-based constructions, that we explain in Section~\ref{2_slice-based}. Since the Fribourg construction is a slice-based construction, it is also based on reduced split trees.

Note that an alternative name for rightmost run is \textit{greedy} run~\cite{2014_joel_ulrich}. This name refers to the fact that the rightmost run is the first of a group of re-joining runs that visits an accepting state. This makes it ``greedy''. It is interesting to note that reduced split trees are related to Muller-Schupp trees that are used in the Büchi determinisation construction by Muller and Schupp~\cite{Muller199569} (cf.~\cite{vardi2007automata,fogarty2013unifying}). As a last remark, formal descriptions of reduced split trees can be found, for example, in~\cite{vardi2007automata} and~\cite{2014_wilke} (left-to-right version), or~\cite{fogarty2013unifying} (right-to-left version).

This concludes our presentation of run analysis techniques. In the next section we will review the most prominent Büchi complementation constructions that have been proposed over the past 50 years. Some of them are based on the run analysis techniques that we have described in the present section.


% Comparing the reduced split tree with the corresponding split tree (Figure~\ref{split_tree}) reveals which states have been removed in the reduced split tree. The root and level 1 are similar in both trees. On level 2, the state \q2 is removed from the leftmost node, because \q2 already appears farther to the right on this level. On level 3, the state \q2 in the second node from the right is removed because there is already a \q2 to the right of it. As \q2 was the only state of this node, this causes the entire node to disappear. On the same level, \q2 of the leftmost node is also removed for the same reason. On level 4, following the same pattern, three occurrences of \q2 are removed. 

% A possible procedure for constructing a new level of a reduced split tree is to start creating children at the rightmost node and then proceed from right to left. In the level under construction, a specific state is only added if it does \textit{not already} occur \textit{to the right} of it. This processing from right to left gives the name to right-to-left reduced split trees.

% This omission of states (and thus entire runs) is ``tailored'' to the Büchi complementation problem. It in fact removes all but one of the runs that, after a certain number of steps, end up in the same state. We will call these runs \textit{re-joining} runs. For example, in the split tree in Figure~\ref{split_tree}, there are four runs that, after reading four symbols, ``re-join'' in \q2. In the reduced split tree (Figure~\ref{reduced_split_tree}), three of these re-joining runs are removed and only one is kept.

% The run that is kept is always the one that is farthest at the right in the tree, and we call it the \textit{rightmost} run. An alternative name for the rightmost run is \textit{greedy} run. This comes from the fact that this run visits an accepting state earlier than the other re-joining runs. For example, in our previous example with the runs re-joining in \q2, the run that is kept in the reduced split tree visits an accepting state (\q1) already after the first symbol, whereas the other runs visit an accepting state only after the second or third symbol, respectively, or not at all.

% Note that visiting an accepting state corresponds to a \textit{right-turn} in a right-to-left split tree. This is because the accepting states are always in the right child of the current node. Thus, the greedy run has actually the earliest right-turn, which in turn is the reason that it is farthest at the right, and thus the rightmost run of all the re-joining runs. In the following, we will use the terms greedy and rightmost interchangeably\footnote{Note that for left-to-right split trees, ``rightmost'' must be substituted by ``leftmost''.}

% Summarising, a reduced split tree is thus a split tree where we keep only the rightmost one of a couple of rejoining runs. The base of this rule is the following observation:

% \begin{quote}
% Any re-joining run is accepting $\Longrightarrow$ The rightmost re-joining run is accepting
% \end{quote}

% That is, if any of the re-joining runs is accepting, then the rightmost run is accepting too, and on the other hand, if the rightmost run is not accepting, then none of the re-joining runs is accepting. A proof of this claim can be found in~\cite{vardi2007automata}\footnote{In this work, the authors use left-to-right split trees, in which case the greedy run is the leftmost rather than the rightmost run.}. 

% Coming back to our problem of Büchi complementation, the main information we need from the run analysis of the input automaton is whether \textit{all} the runs on a specific word are non-accepting or not. By considering only greedy runs, we actually test a couple of runs for this property at once. If the greedy run is non-accepting, then we know  instantly that all its related re-joining runs are also non-accepting. If on the other hand the greedy run is accepting, then there is at least one accepting run anyway, and the complement automaton must reject the word. Thus, reduced split trees are a clever way to reduce the problem of analysing the large number of runs of a non-deterministic Büchi automaton on a specific word, by keeping only the information that is essential for the purpose of Büchi complementation.

% The most important property of reduced split trees is that their width (the number of states on a level) is bounded by the number of states of the corresponding automaton, and thus finite. This does not hold for split trees. For example, the width of the split tree in Figure~\ref{split_tree} becomes infinite with an infinite number of levels. The width of the reduced split tree in Figure~\ref{reduced_split_tree}, however, never exceeds three, because three is the number of states of the input automaton.

% The bounded width of reduced split trees is actually what makes them usable for Büchi complementation constructions, in particular the slice-based construction, including the Fribourg construction. Because in these constructions, levels of reduced split trees define states of the output automaton, and this is only possible if there is a finite number of distinct levels, so that there is a finite number of possible states in the output automaton.


\section{Review of Büchi Complementation Constructions}
\label{2_review}
Since the introduction of Büchi automata in 1962, many different Büchi complementation constructions have been proposed. In this section, we review some of the most important of them. Many of the constructions that we describe in this section are implemented in the \goal{} tool, that we use for the empirical performance investigation of the Fribourg construction (see Chapter~\ref{chap_investigation}). Three of them are actively used in our investigation for comparing against the Fribourg construction, namely the constructions by Piterman~\cite{2006_piterman,2007_piterman}, Schewe~\cite{schewe2009buchi}, and Vardi and Wilke~\cite{vardi2007automata}.

We organise our review of Büchi complementation constructions along the four main complementation approaches that have been proposed by Tsai et al.~\cite{2011_tsai}: \textit{Ramsey-based}, \textit{determinisation-based}, \textit{rank-based}, and \textit{slice-based}. For an easier overview, we list below all the constructions that are included in our review.

\newcommand{\ii}{\hspace{5mm}}
\newcommand{\vstrut}{\vphantom{$2^{2^2}$}}
\begin{longtable}[l]{lll}
\multicolumn{3}{l}{Ramsey-based} \\
\hline
\ii\hyperref[2_buchi62]{Büchi} & 1962 & \cite{buchi1960decision} \\
\ii\hyperref[2_svw87]  {Sistla, Vardi, and Wolper} & 1987 & \cite{1985_sistla,PrasadSistla1987217} \\
\multicolumn{3}{l}{Determinisation-based\vstrut} \\
\hline
\ii\hyperref[2_safra88]{Safra} & 1988 & \cite{1988_safra_2,1988_safra_1} \\
\ii\hyperref[2_ms95]{Muller and Schupp} & 1995 & \cite{Muller199569} \\
\ii\hyperref[2_pit07]{Piterman} & 2007 & \cite{2006_piterman,2007_piterman} \\
\multicolumn{3}{l}{Rank-based\vstrut} \\
\hline
\ii\hyperref[2_kla91]{Klarlund} & 1991 & \cite{1991_klarlund} \\
\ii\hyperref[2_kv01]{Kupferman and Vardi} & 1997/2001 & \cite{1997_vardi,Kupferman:2001} \\
\ii\hyperref[2_th99]{Thomas} & 1999 & \cite{1999_thomas} \\
\ii\hyperref[2_fkv06]{Friedgut, Kupferman, and Vardi} & 2006 & \cite{2004_friedgut,friedgut2006buchi} \\
\ii\hyperref[2_schewe09]{Schewe} & 2009 & \cite{schewe2009buchi} \\
\multicolumn{3}{l}{Slice-based\vstrut} \\
\hline
\ii\hyperref[2_vw07]{Vardi and Wilke} & 2007 & \cite{vardi2007automata} \\
\ii\hyperref[2_kw08]{Kähler and Wilke} & 2008 & \cite{2008_kaehler} \\
\end{longtable}


\subsection{Ramsey-Based Approach}
\label{2_ramsey-based}
The Ramsey-based complementation approach is the oldest approach and includes the earliest Büchi complementation constructions, including the original construction described by Büchi~\cite{buchi1960decision}. Ramsey-based constructions are based on a branch of combinatorics called Ramsey theory~\cite{graham1990ramsey}\footnote{Ramsey was a British mathematician who lived at the beginning of the 20th century}, hence the name Ramsey-based approach. They proceed by directly constructing the complement automaton out of the input automaton by applying combinatorial arguments.

% The Ramsey-based approach has its name from a Ramsey-based combinatorial argument that is used in the complementation constructions. Ramsey was a British mathematician who lived at the beginning of the 20th century and founded a branch of combinatorics called the Ramsey theory~\cite{graham1990ramsey}.

% Common to the  Ramsey-based complementation constructions is that they stay completely within in the framework of Büchi automata. That is, they do not include intermediate automata of different types, as for example the determinization-based constructions. Rather, Ramsey-based constructions construct the complement automata directly by combinatorial operations on the states and transitions.

\subsubsection{Büchi (1962)}
\label{2_buchi62}
The first Büchi complementation construction in the history of Büchi automata, has been described by Büchi in his 1962 paper~\cite{buchi1960decision}. This construction is based on a combinatorial argument introduced by Ramsey in 1930~\cite{1930ramsey}. The construction is rather complicated~\cite{vardi2005buchi}, and has a doubly-exponential worst-case state growth of $2^{2^{O\left(n\right)}}$~\cite{2007_vardi}. This worst-case staste growth is very large. For example, given an automaton with 9 states, the maximum size of the complement is $1.3 \times 10^{154}$ states. This is a tremendously larger number as there are atoms in the observable universe\footnote{Assuming a number of $10^{80}$ atoms in the observable universe, according to \url{http://www.wolframalpha.com/input/?i=number+of+atoms+in+the+universe}.}.

However, as mentioned in our discussion in in Section~\ref{1_motivation} about the use of the worst-case state growth as a performance measure, this number applies only to the worst case, which is a very unlikely to occur in practice. Furthermore, we believe that Büchi's aim was not to create an \textit{efficient} construction, but rather to prove that such a construction exists in the first place. Because for Büchi this construction served mainly as a proof for the closure of Büchi automata under complementation, which was required for the proof of Büchi's Theorem~\cite{vardi2007automata}.


% The first Büchi complementation construction at all was described by Büchi himself, along with the introduction of Büchi automata in 1962~\cite{buchi1960decision}. This complemenation construction is a Ramsey-based construction. It involves a combinatorial argument based on work by Ramsey~\cite{1930ramsey}. The construction is complicated, and has a doubly-exponential worst-case state complexity of $2^{2^{O\left(n\right)}}$~\cite{vardi2005buchi}. This means that if we assume, for example, the concrete complexity to be $2^{2^n}$, then an automaton with 6 states may result in a complement with at most $2^{2^6}$ states, which is more than 18 quintillions (18 billion billions).

% The complexity of this worst-case is very high, and it would probably be impossible to complement such a worst-case automaton in practice. This is why all the subsequent complementation constructions, until today, have the goal to reduce this worst-case complexity. In this way, the worst-case state complexity became the main measure of performance for Büchi complementation constructions.

\subsubsection{Sistla, Vardi, and Wolper (1987)}
\label{2_svw87}
In 1987, Sistla, Vardi, and Wolper proposed an improvement of Büchi's construction~\cite{PrasadSistla1987217}\footnote{This paper was preliminarily published in 1985~\cite{1985_sistla}.}. This construction was the first to include only an exponential, rather than doubly-exponential, worst-case state growth. The state growth function of the construction is $O(16^{n^2})$~\cite{PrasadSistla1987217}. Thus, given an automaton with 9 states, the maximum size of the complement is $3.4 \times 10^{97}$ states. 

% Another Ramsey-based construction has been introduced by Sistla, Vardi, and Wolper in 1987~\cite{PrasadSistla1987217} (first published in 1985~\cite{1985_sistla}). It is an improvement of Büchi's construction and the first one that involves only an exponential, instead of a doubly-exponential, worst-case state complexity. The complexity of this construction has been calculated to be $O\left(2^{4n^2}\right)$ (see~\cite{1988_safra_2}\cite{Pecuchet198695}).

% The Ramsey-based approach is the oldest of the four approaches and it was particularly 


\subsection{Determinisation-Based Approach}
\label{2_determinisation-based}
The determinisation-based approach achieves complementation by chaining several conversions between different types of \om-automata. The most important of these conversions is the transformation of the non-deterministic Büchi automaton to a deterministic \om-automaton of a different type. Thus, the first step is to determinise the input automaton, hence the name determinisation-based approach.

Note that in this context \textit{determinisation} refers to the conversion of a Büchi automaton to a \textit{different type} of \om-automata, such as a Muller, Rabin, Streett, or parity automaton (see Section~\ref{2_om-automata}). As mentioned in Section~\ref{2_buchi_automata}, the determinisation of a Büchi automaton to a deterministic Büchi automaton is in general not possible, because deterministic Büchi automata are less expressive than non-deterministic Büchi automata.

This approach harnesses the fact that the complementation of deterministic automata of these types is relatively easy. In summary, the idea of the determinisation-based approach is to convert a non-deterministic Büchi automaton to a deterministic \om-automaton, complement the deterministic \om-automaton, and convert the complemented automaton back to a non-deterministic Büchi automaton.


% The determinization-based complementation constructions proceed by converting an NBW to a deterministic automaton, complementing the deterministic automaton, and finally converting the complement automaton back to an NBW. The deterministic automaton cannot be a DBW (because NBW and DBW are not equivalent), however it can be a DMW, DRW, DSW, or DPW.

% The idea behind this approach is that the complementation of deterministic \om-automata is easier than the complementation of non-deterministic \om-automata. The complementation problem is then in fact reduced to conversions between different types of automata. From these conversions, the conversion from the initial NBW to a deterministic \om-automaton is the most difficult and crucial one.

\subsubsection{Safra (1988)}
\label{2_safra88}
The first determinisation-based complementation construction has been described in 1988 by Safra~\cite{1988_safra_2,1988_safra_1}. Safra's main focus was actually a construction for converting a non-deterministic Büchi automaton (NBW) to a deterministic Rabin automaton (DRW)\footnote{This is the notation for \om-automata types that we introduced in Section~\ref{2_om-automata}.}, thus a determinisation construction. This determinisation construction is what today commonly is known as \textit{Safra's construction}. However, Safra also describes a series further conversions that, when chained together, result in a complementation construction. The complete series of conversions to complement an NBW is as follows:

% The first determinisation-based complementation construction has been described by Safra in 1988~\cite{1988_safra_2,1988_safra_1}. Safra's main work was actually a determinisation construction for converting an NBW to a DRW. This is what today is known as \textit{Safra's construction}. Safra then describes complementation as a possible application of his determinisation construction. He also presents the additional conversions that are needed for the entire complementation construction. The conversion steps of Safra's complementation procedure are as follows.

% Simulate enumerate with a table
\newlength{\myitemindent}
\setlength{\myitemindent}{\itemindent+1pt}
\hspace{\myitemindent}
{\renewcommand{\tabcolsep}{4pt}
\begin{tabular}{lllll}
1. & NBW       & $\longrightarrow$ & DRW      & (Safra's construction) \\
2. & DRW       & $\longrightarrow$ & \ob{DSW} & (Complementation)      \\
3. & \ob{DSW}  & $\longrightarrow$ & \ob{DRW} &                        \\
4. & \ob{DRW}  & $\longrightarrow$ & \ob{NBW} &                        \\
\end{tabular}}

That is, first the NBW is converted to a DRW with Safra's determinisation construction. This DRW is then complemented to a DSW, which is converted to a DRW, which in turn is converted back to an NBW. The resulting NBW is the complement of the input NBW. Note that in the above notation, a horizontal bar above an automaton indicates that the automaton accepts the complement language of the input automaton.

Safra's construction is in fact a modified subset construction that guarantees the equivalence of the input and output automata\footnote{Safra shows in his papers~\cite{1988_safra_2,1988_safra_1} nicely that applying the classical subset construction to an NBW $A$ results in a DBW $B$ that may accept some words that are not accepted by $A$. This means that the subset construction is not \textit{sound} with respect to Büchi automata.}. The main difference of Safra's construction to the classical subset construction is that the states of the output automaton are labelled by trees of subsets of states, rather than just subsets of states. These trees are called \textit{Safra trees}. Alternative detailed analyses and explanations of Safra's construction can be found, for example, in~\cite{2002_roggenbach,klein2005linear,2006_althoff,1998_loeding_msc}.

The complementation step from the DRW to the complement DSW can be trivially done by interpreting the Rabin acceptance condition as a Streett acceptance condition~\cite{klein2005linear}. This works, because, as mentioned in Section~\ref{2_om-automata}, the two acceptance conditions are the duals of each other. The final conversions from DSW to DRW, and DRW to NBW are described by Safra in~\cite{1988_safra_2,1988_safra_1} or alternatively in~\cite{klein2005linear}.

The entire construction from an NBW to a complement NBW has a worst-case state complexity of $2^{O\left(n\, \text{log}\, n\right)}$. With this result, Safra's complementation construction matched the lower bound of $n!$ that has been introduced in the same year by Michel~\cite{michel1988}. However, as pointed out by Vardi~\cite{2007_vardi}, the big-$O$ notation hides a large gap between the two functions, and Safra's complementation construction is thus not as ``optimal'' as it seems. Thus, the quest for finding Büchi complementation constructions with an even lower worst-case state complexity continued.

% The complementation step from a DRW to a DSW that accepts the complement language can be trivially done by interpreting the Rabin acceptance condition as a Streett acceptance condition. This is possible, because these two acceptance conditions are the negations of each other (see Section~\ref{om-automata}. The conversions from DSW to DRW, and from DRW to NBW are not of major difficulty or complexity, and are described by Safra in~\cite{1988_safra_2} (Lemma~3 and Lemma~5).

% The core is the conversion from NBW to DRW (Safra's construction). This construction is basically a modified subset construction. That is, the output automaton is built up from an initial state step-by-step by adding new states and transitions. The main difference to the subset construction is that in Safra's construction, the output-states consist of trees of subsets of input-states, rather than just of subsets of input-states. These trees of subsets of states are called \textit{Safra trees}. The details of the construction are rather intricate, but well described in~\cite{1988_safra_2}. The deterministic automaton that results from Safra's construction can then be interpreted as a Rabin automaton.

% The state growth of Safra's construction is $2^{O\left(n\, \text{log}\, n\right)}$, where $n$ is the number of states of the input automaton. The additional conversions (DSW to DRW, and DRW to NBW) have a lower state complexity than this, so that the overall complexity of the entire complementation procedure is still $2^{O(n\, \text{log}\, n}$.

\subsubsection{Muller and Schupp (1995)}
\label{2_ms95}
In 1995, Muller and Schupp proposed and improvement of Safra's determinisation construction~\cite{Muller199569}. This construction can be used at the place of Safra's original construction in the conversation chain that we described above for Safra's construction. Muller and Schupp's construction uses \textit{Muller-Schupp trees} instead of Safra trees. While the principles of the two constructions are very similar, it is said that Muller and Schupp's construction is simpler and more intuitive than Safra's construction~\cite{2002_roggenbach}. However, the drawback is that in many concrete cases Muller and Schupp's construction produces larger output automata than Safra's construction~\cite{2006_althoff}. The worst-case state complexity of Muller and Schupp's construction is, similarly to Safra's construction, $2^{O\left(n\, \text{log}\, n\right)}$.  A detailed comparison of the determinisation constructions by Muller and Schupp, and Safra can be found in~\cite{2006_althoff}.

% Most other determinisation-based complementation constructions are based on improvements of Safra's construction. One of them is the construction for converting NBW to DRW proposed in 1995 by Muller an Schupp~\cite{Muller199569}. This construction is said to be simpler and more intuitive than Safra's construction~\cite{2002_roggenbach}, however, often produces larger output automata in practice~\cite{2006_althoff}. The theoretically caluclated state complexity of the Muller-Schupp construction is $2^{O\left(n\, \text{log}\, n\right)}$, that is, similar to Safra's construction. A comparison of the Muller-Schupp construction and Safra's construction can be found in~\cite{2006_althoff}.

\subsubsection{Piterman (2007)}
\label{2_pit07}
A further improvement of Safra's determinisation construction has been proposed in 2007 by Piterman from EPF Lausanne~\cite{2007_piterman}\footnote{A preliminary version of this paper has appeared in 2006~\cite{2006_piterman}.}. The main difference to Safra's construction is that Piterman's construction converts the input Büchi automaton to a deterministic parity automaton (DPW), rather than a deterministic Rabin automaton (DRW). Furthermore, Piterman uses a more compact version of Safra trees, what results by trend in smaller output automata. Also in terms of worst-case complexity, Piterman's construction is more efficient than Safra's construction. The blow-up in Piterman's construction from the NBW to the DPW is $2n^nn!$, whereas in Safra's construction the blow-up from the NBW to the DRW is $12^nn^{2n}$~\cite{2006_piterman,2007_piterman}.

Since Piterman's determinisation construction produces a DPW, it entails different conversions for complementation than Safra's construction. In particular, the conversion chain is as follows~\cite{2011_tsai}: 

% Another improvement of Safra's construction has been proposed in 2007 by Piterman from EPF Lausanne~\cite{2007_piterman} (first presented at a conference in 2006~\cite{2006_piterman}). This construction converts a NBW to a DPW, rather than a DRW. Piterman's construction uses a more compact version of Safra trees, which allows it to produce smaller output automata. The concrete worst-case state growth of Piterman's construction is $2n^nn!$, opposed to $12^nn^{2n}$ of Safra's construction~\cite{2007_piterman}. Complementation with Piterman's construction is done in the following steps.

% Simulate enumerate with a table
\setlength{\myitemindent}{\itemindent+1pt}
\hspace{\myitemindent}
{\renewcommand{\tabcolsep}{4pt}
\begin{tabular}{lllll}
1. & NBW       & $\longrightarrow$ & DPW      & (Piterman's construction) \\
2. & DPW       & $\longrightarrow$ & \ob{DPW} & (Complementation)      \\
3. & \ob{DPW}  & $\longrightarrow$ & \ob{NBW} &                        \\
\end{tabular}}

The complementation of the DPW can be trivially done by increasing the number assigned to each state by one~\cite{2011_tsai} (see Section~\ref{2_om-automata} for an explanation of the parity acceptance condition). The complemented DPW can then be converted directly to an NBW~\cite{2011_tsai}.

% The complementation step from a DPW to a DPW accepting the complement language can be trivially done by, for example, increasing the number of each state by 1. The conversion from a DPW to an NBW can alse be done without major complexity~\cite{2011_tsai}.

\subsection{Rank-Based Approach}
\label{2_rank-based}
The rank-based approach is based on run analysis with run DAGs (see Section~\ref{2_run_dags}). The basic ``mechanics'' of rank-based construction is similar to the subset construction. That is, the output automaton is constructed state by state, by adding to every state a successor state for every symbol of the alphabet. In rank-based constructions, these states are derived from levels of a run DAG. The idea is that the run analysis with run DAGs is interweaved with the construction, so that the states of the output automaton represent the levels of ``virtual'' run DAGs.

As we have seen in Section~\ref{2_run_analysis}, the purpose of run analysis is to find out whether \textit{all} runs of an input automaton $A$ on a word $\alpha$ are non-accepting. Because in this case, the complement $B$ must accept $\alpha$, and in all other cases it must not accept it. In rank-based constructions this is achieved by the means of natural numbers called \textit{ranks} that are assigned to the vertices of a run DAG (hence the name rank-based approach). These ranks are assigned in such a way that vertices corresponding to \textit{accepting} states only get \textit{even} ranks. Furthermore the ranks along paths of the run DAG are monotonically decreasing. The effect of this is that every path gets eventually trapped in a rank. If for a given path this trapped rank is odd, it means that the corresponding run does not visit any accepting states anymore starting from a certain point. Consequently, this run is non-accepting. If all the paths of a run DAG get trapped in an odd rank, then all the runs of the automaton on the given word are non-accepting. This situation is called \textit{odd-ranking} and indicates that the complement must accept the word.

This basic idea is the same for all rank-based construction and described in many places, for example, \cite{fogarty2013unifying,Kupferman:2001,friedgut2006buchi,2007_vardi,2009_karmarkar,schewe2009buchi}. The individual rank-based constructions differ between each other mainly in the details how the ranking is done.

% The rank-based approach was the third of the four proposed main complementation approaches. It does neither include Ramsey theroy, nor determinisation. Rather, it is based on run analysis with run DAGs. The link of run analysis with run DAGs to complementation is as follows. A run DAG allows to summarise all the possible runs of an automaton on a specific word. If all these runs are rejecting, then we say that the entire run DAG is rejecting. In this case, the automaton does not accept the word, and consequently, the complement automaton must accept this word. Conversely, if one or more runs in the run DAG are not rejecting, then the entire run DAG is not rejecting. In this case, the automaton accepts the word, and consequently, the complement automaton must no accept this word.

% The information of whether a run DAG is rejecting or not is expressed with so-called ranks. These are numbers that are assigned to the vertices of a run DAG, one rank per vertex. These ranks are assigned in a way that each path of a run DAG eventually gets trapped in a rank. From this information it is then possible to deduce whether the run DAG is rejecting or not. This in turn determines whether the complement automaton must accept the given word, or not.

% This entire analysis of run DAGs with ranks is included in a subset construction. This means that the individual run DAGs are not constructed explicitly for each word, but rather implicitly ``on-the-fly'' within the complement automaton under construction. From a practical point of view, this means that rank-based constructions proceed in a subset construction based fashion. That is, the construction of the complement automaton is started with an initial state, and then step-by-step, successor states are added. Each output state consists of subsets of input-states.

\subsubsection{Klarlund (1991)}
\label{2_kla91}
Klarlund's construction~\cite{1991_klarlund} rather foreshadowed the rank-based constructions than being one itself. It was one of the first constructions that was neither Ramsey-based nor determinisation-based~\cite{1991_klarlund,Kupferman:2001}. Its fundamental idea is very similar to the later rank-based constructions, but it does not use the term ``rank'' and is not explicitly based on run DAGs. However, Klarlund uses so-called \textit{progress measures}, which have a very similar role as the ranks of later constructions. This construction served as the base for Kupferman and Vardi's rank-based construction in 1997~\cite{1997_vardi}. The worst-case state growth of Klarlund's construction is $2^{O(n\, \text{log}\, n)}$

% The first rank-based construction has been proposed in 1991 by Klarlund~s. However, Klarlund used the term \textit{progress measure} instead of \textit{rank}. This is because he looked at the ranks as a measure for the ``progress'' of a run towards the satisfaction of a certain property. The term \textit{rank} has, to the best of our knowledge, been introduced by Thomas in 1999~\cite{1999_thomas}. Klarlund also did not mention run DAGs, but they are implicit in his description of the construction. The construction works as described above by performing a modified subset construction. 

\subsubsection{Kupferman and Vardi (1997/2001)}
\label{2_kv01}
This construction has been published for the first time in 1997~\cite{1997_vardi} and again in 2001~\cite{Kupferman:2001}. Both publications are entitled ``Weak Alternating Automata Are Not That Weak''. Kupferman and Vardi basically pick up Klarlund's construction and describe it in a different way~\cite{Kupferman:2001}. Actually, they provide two different descriptions for the same construction, one based on weak alternating automata (WAA)\footnote{Weak alternating automata have been introduced by Muller, Saoudi, and Schupp in 1986~\cite{1986_muller}.}, and one using the idea of ranks that we explained above.

The first description includes several conversions between \om-automata types. It starts by interpreting the input NBW as a universal co-Büchi automaton (UCW) which accepts the complement language of the initial NBW. This UCW is converted to a weak alternating automaton (WAA), which is finally converted back to an NBW. The second description equals the rank-based approach that we described in the introduction to this section. Kupferman and Vardi state that their two versions and Klarlund's construction produce identical results. However, they claim that their descriptions make the construction easier to understand and implement.~\cite{Kupferman:2001}.

% This construction by Kupferman and Vardi has been published as a preliminary conference version in 1997~\cite{1997_vardi}, and as a journal version in 2001~\cite{Kupferman:2001}. Both publications are entitled ``Weak Alternating Automata Are Not That Weak''. The idea of the construction described by Kupferman and Vardi is the same as Klarlund's construction from 1991~\cite{1991_klarlund}. However, Kupferman and Vardi provide two different descriptions for this idea.

% The first description does not use run DAGs and ranks, but rather converst the input automaton to a weak alternating automaton, which is complemented, and then converted back to a non-deterministic Büchi automata. Weak alternating automata (WAA) have been introduced in 1986 by Muller, Saoudi, and Schupp~\cite{1986_muller}. Kupferman and Vardi state that this construction is conceptually simpler and easier implementable than Klarlund's construction~\cite{1991_klarlund}. This first version of Kupferman and Vardi's construction is described in both, the publications from 1997~\cite{1997_vardi} and 2001~\cite{Kupferman:2001}.

% Description of alternating automata: \cite{1996_vardi} (Section 2.5)


% The second description in turn is rank-based, as described above, and works in the subset construction fashion without intermediate automata. Kupferman and Vardi point out that this version of the construction is identical to Klarlund's construction. What changes is just the terminology, for example ``ranks'' instead of ``progress measure''. This second version of Kupferman and Vardi's construction is to the best of our knowledge only described in the publication from 2001~\cite{Kupferman:2001}, however, we are not sure, because we could not access the publication from 1997\cite{1997_vardi}.

% There is an \textit{odd ranking} if and only if all the runs of the run DAG are rejecting. Odd ranking: all the paths get trapped in an odd rank. Only non-accepting states have odd ranks.

% Description in \cite{fogarty2013unifying}~\cite{2007_vardi}

% The automata produced by the two versions of Kupferman and Vardi's construction are identical. The worst-case state complexity has been calculated to be approximately $(6n)^n$~\cite{schewe2009buchi}\cite{2007_vardi}.

\subsubsection{Thomas (1999)}
\label{2_th99}
This construction by Thomas~\cite{1999_thomas} is based on the concept of alternating automata, like the previous construction by Kupferman and Vardi (1997) that proceeds via a WAA~\cite{1997_vardi}. The difference of Thomas' construction is that it performs the complementation step in the framework of alternating automata. In particular, the input NBW is converted to a weak alternating parity automaton (WAPA), which is complemented to another WAPA, which finally is converted back to an NBW. Note that Thomas uses the concept of ranks that are assigned to the states of an alternating automaton in a similar way as we described in the introduction to this section. Thus, we categorise this construction under the rank-based approach, even though it proceeds in a different way.

% This construction by Thomas~\cite{1999_thomas} is based on the WAA construction by Kupferman and Vardi from 1997~\cite{1997_vardi}. It uses the concept of ranks, but does not proceed in the subset construction manner, as Klarlund's construction~\cite{1991_klarlund} and Kupferman and Vardi's second version~\cite{Kupferman:2001}. Rather, it transforms the input NBW to an intermediate automaton, complements it, and converts the result back to an NBW. That is, it proceeds in a similar fashion as Kupferman and Vardi's first version~\cite{1997_vardi}. The type of the intermediate automaton is a weak alternating parity automaton (WAPA), that is, a weak alternating automaton with the parity acceptance condition.

\subsubsection{Friedgut, Kupferman, and Vardi (2006)}
\label{2_fkv06}
In 2006, Friedgut, Kupferman, and Vardi~\cite{friedgut2006buchi}\footnote{This paper has been preliminarily appeared in 2004~\cite{2004_friedgut}.} proposed an improvement of the rank-based construction by Kupferman and Vardi~\cite{Kupferman:2001}. The improvement consists in a better ranking function called \textit{tight ranking} that reduces the maximum number of states in the output automaton\footnote{Alternative descriptions of the tight ranking function can be found, for example, in~\cite{fogarty2013unifying}, \cite{schewe2009buchi}, or~\cite{2007_vardi}.} The worst-case state complexity of the construction is $(0.96n)^n$, which is an enormous reduction from the 2001 construction by Kupferman and Vardi with a worst-case state complexity of $(6n)^n$. The title of Friedgut, Kupferman, and Vardi's paper is ``Büchi Complementation Made Tighter''. It refers to the fact that this construction provides a new upper bound for the precise state complexity of Büchi complementation that considerably \textit{tightens} the gap between the best known upper bound and the then known lower bound by Michel~\cite{michel1988} of $n!$.

%  published a paper entitled ``Büchi Complementation Made Tighter''~\cite{friedgut2006buchi} (a preliminary version of the paper has appeared in 2004~\cite{2004_friedgut}). There, they describe an improvement to the second (rank-based) version of Kupferman and Vardi's construction from 2001~\cite{Kupferman:2001}. The improvement consists in the so-called \textit{tight ranking}, a more sophisticated ranking function. It allows to massively reduce the worst-case state complexity of the construction to $(0.96n)^n$.

% Tight rankings: description in \cite{fogarty2013unifying}~\cite{2007_vardi}

\subsubsection{Schewe (2009)}
\label{2_schewe09}
The work by Schewe~\cite{schewe2009buchi} is an optimisation to the construction by Friedgut, Kupferman, and Vardi~\cite{friedgut2006buchi}. It consists of the use of \textit{turn-wise} tests in the \textit{cut point construction}~\cite{schewe2009buchi}. This optimisation allows to reduce the worst-case state complexity of the construction to $(0.76n)^n$ modulo a polynomial factor in $O(n^2)$~\cite{schewe2009buchi}, that is, around $O((0.76n)^nn^2)$. This comes very near to the lower bound of $(0.76n)^n$ that has previously been established by Yan~\cite{2006_yan,DBLP:journals/corr/abs-0802-1226}. Schewe's paper is entitled ``Büchi Complementation Made Tight'', which refers to the fact that finally the gap between the lower and upper bounds for Büchi complementation has been made really ``tight'' (after having been made ``tighter'' by Friedgut, Kupferman, and Vardi~\cite{friedgut2006buchi}).

% In 2009, Schewe presented another improvement to the construction by Friedgut, Kupferman, and Vardi from 2006~\cite{schewe2009buchi}. His paper is entitled ``Büchi Complementation Made Tight'', which hints at the relation to the paper by Friedgut, Kupferman, and Vardi~\cite{friedgut2006buchi}. Schewe's improvement consists in a further refinement of the construction, in particular the use of turn-wise tests in the cut-point construction step. This improvement allows to further reduce the worst-case state complexity of the construction to $\left(0.76\left(n+1\right)\right)^{n+1}$. This coincides, modulo a polynomial factor, with the lower bound for the state complexity of Büchi complementation of $(0.76n)^n$ that has been previously established by Yan in 2006~\cite{2006_yan}\cite{DBLP:journals/corr/abs-0802-1226}.

% This result narrows down the possible range for the real worst-case state complexity of Büchi complementation considerably. It cannot be lower than the lower bound of $(0.76n)^n$ by Yan, and it cannot be higher than the complexity of Schwewe's construction of $\left(0.76\left(n+1\right)\right)^{n+1}$. For this reason, we say that the proven worst-case complexity of a specific construction serves as an upper bound for the actual complexity of the problem.

\subsection{Slice-Based Approach}
\label{2_slice-based}
The slice-based approach can be seen as the brother of the rank-based approach. The main difference is that the slice-based approach is based on \textit{reduced split trees} (see Section~\ref{2_red_split_trees}), rather than run DAGs. As for the rank-based approach, the ``mechanics'' of the slice-based approach is similar to the subset construction, that is, the output automaton is constructed state by state. In a slice-based construction these states are derived from levels of reduced split trees (as opposed to rank-based constructions where the states are derived from levels of run DAGs). The nodes on a level of a reduced split tree define the components of a state of a slice-based construction. The levels of reduced split trees are called \textit{slices}~\cite{vardi2007automata}, hence the name slice-based approach.

Slice-based constructions use decorations, also called colours~\cite{2014_joel_ulrich}, that are assigned to the nodes of the corresponding reduced split trees (and thus to the components of the states that are derived from the slices of the tree). These decorations serve the same role as the ranks in rank-based constructions, namely the detection whether all runs of the input automaton on a specific word are non-accepting, in  which case the complement must accept the word. A comparative analysis of the slice-based and the rank-based approach has been done by Fogarty et al.~\cite{fogarty2013unifying}\footnote{In this work, the authors even propose a construction that unifies the two approaches.}. Below we present two important slice-based constructions. 

% The slice-based approach was the last approach that has been proposed. Its idea is very similar to the rank-based approach, but the main difference is the use of reduced split trees instead of run DAGs. The basic idea is to look at a state of the output automaton under construction as a horizontal level of a reduced split tree. Based on this, for each alphabet symbol, the succeeding level of the reduced split tree is determined, which results in a new state in the output automaton. These levels of reduced split trees are called \textit{slices}, hence the name slice-based approach.

% Like rank-based constructions, slice-based construction are essentially enhanced subset constructions. The slice-based constructions, however, include two runs of a subset construction, where the second one is typically more sophisticated than the first one.


\subsubsection{Vardi and Wilke (2007)}
\label{2_vw07}
With this construction, Vardi and Wilke have established the slice-based approach~\cite{2011_tsai}. The construction is divided into an \textit{initial phase} and a \textit{repetition phase}. In the initial phase, slices (and thus states) are constructed without decorations. At some point, the construction guesses to transfer to the repetition phase in which the nodes of the slices (thus, components of states) are decorated by one of the decorations \textit{inf}, \textit{new}, or \textit{die}. These decorations determine whether the enclosing state is accepting or non-accepting. A loose upper bound for the worst-case state complexity of this construction is $(3n)^n$~\cite{vardi2007automata}. Vardi and Wilke describe their construction using left-to-right reduced split trees.

% The first slice-based Büchi complementation construction has been proposed in 2007 by Vardi and Wilke~\cite{vardi2007automata}. In this work, the authors review translations from various logics, including monadic second order logic of one successor (S1S), to \om-automata. They devise the slice-based complementation construction as a by-product of a determinisation construction for Büchi automata that they also introduce in this work.

% Vardi and Wilke use left-to-right reduced split trees for their construction. That means, accepting states are put to the left of non-accepting states, and only the left most occurrence of each state is kept. The construction works by two passes of the enhanced subset construction. The first one (initial phase) is as described above. The second one (repetition phase), does additionally include decorations of the vertices of the reduced split trees (subsets) consisting of the three labels \textit{inf}, \textit{die}, and \textit{new}. These decoration serves to keep track of the criterion that a word is rejected if and only if all of the branches of the corresponding reduced split tree contain only a finite number of left-turns. The worst-case state complexity of Vardi and Wilke's construction is $(3n)^n$~\cite{vardi2007automata}.

% The slice-based construction by Vardi and Wilke is very similar to the Fribourg construction that we describe in Chapter~\ref{chap_construction}. An obvious difference is that the Fribourg construction uses right-to-left, rather than left-to-right, reduced split trees. However, this is an arbitrary choice, and has no influence on the result of the constructions. Another difference is that the transition from the initial phase to the repetition phase is handled quite differently by Vardi and Wilke, than for the corresponding automata parts in the Fribourg construction.

\subsubsection{Kähler and Wilke (2008)}
\label{2_kw08}
This construction by Kähler and Wilke~\cite{2008_kaehler} is a generalisation of the previous slice-based construction by Vardi and Wilke~\cite{vardi2007automata}. The construction is modified such that it can treat complementation and disambiguation\footnote{Disambiguation means the conversion of an automaton to an equivalent \textit{unambiguous} automaton. An automaton is unambiguous if every accepted word has only one accepting run~\cite{2012_mohri}. Note that this differs from determinisation, as in an unambiguous automaton a word may still have multiple runs, but only one accepting run.} of Büchi automata in a uniform way~\cite{2011_tsai}. The generalisation however comes at the price of a higher worst-case state complexity of $4(3n)^n$~\cite{2011_tsai}. Kähler and Wilke also use left-to-right trees for their construction.

% The slice-based construction by Kähler and Wilke from 2008~\cite{2008_kaehler} is a generalisation of the construction by Vardi and Wilke from 2007~\cite{vardi2007automata}. Kähler and Wilke proposed a construction idea that can be used for both, complementation and disambiguation. Consequently, this construction is less efficient than Vardi and Wilke's construction. It has a worst-case state complexity of $4(3n)^n$~\cite{2011_tsai}.

% A comparison of the rank-based and slice-based complementation approaches has been done by Fogarty, Kupferman, Wilke, and Vardi~\cite{fogarty2013unifying}. In this work, the authors also describe a translation of the slice-based construction by Kähler and Wilke~\cite{2008_kaehler} to a rank-based construction.


With this brief review of the slice-based complementation approach, we conclude the present chapter. In the next chapter we present the Fribourg construction, which is another slice-based construction. 


% \section{Run Analysis}
% A deterministic automaton has exactly one run on every word. A non-deterministic automaton, on the other hand, may have multiple runs on a given word. The analysis of all runs of a word, in some form or another, an integral part of Büchi complemenation constructions. Remember that a non-deterministic automaton accepts a word if there is \emph{at least one} accepting run. Consequently, a word is rejected if only if \emph{all} the runs are rejecting. That is, if $B$ is the complement Büchi automaton of $A$, then $B$ has to accept a word $w$ if and only if \emph{all} the runs of $A$ on $w$ are rejecting. For constructing the complement $B$, we have thus to consider all the possible runs of $A$ on every word.

% There are two main data structures that are used for analysing the runs of a non-deterministic automaton on a word. These are trees and DAGs (directed acyclic graphs)~\cite{2014_wilke}. In this section, we present both of them. We put however emphasis on trees, as they are used by the subset-tuple construction presented in Chapter~\ref{fribourg_construction}.

% \subsection{From Run Trees to Split Trees}

% \begin{figure}
% \centering
% \Automaton
% \caption{Example NBW $A$ that will be used in different places throughout this thesis. The alphabet of $A$ consists of the single symbol $a$, consequently, $A$ can only process the single \om-word $a^\omega$. This word is rejected by $A$, so the automaton is empty.}
% \label{automaton}
% \end{figure}

% The one tree data-structure that truly represents \emph{all} the runs of an automaton on a word are run trees. The other variants of trees that we present in this section are basically derivations of run trees that sacrifice information about individual runs, by merging or discarding some of them, at the benefit of becoming more concise. Figure~\ref{run_tree} shows the first few levels of the run tree of the example automaton $A$ from Figure~\ref{automaton} on the word \aom.

% \begin{figure}
% \centering
% \RunTree
% \caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
% \label{run_tree}
% \end{figure}

% In a run tree, every vertex represents a single state and has a descendant for every $a$-successor of this state, if $a$ is the current symbol of the word. A run is thus represented as a branch of the run tree. In particular, there is a one-to-one mapping between branches of a run tree and runs of the automaton on the given word.

% We mentioned that the other tree variants that we talk about in this section,  split trees and reduced split trees, make run trees more compact by not keeping information about individual runs anymore. They thereby relinquish the one-to-one mapping between branches of the tree and runs. Let us look at one extreme of this aggregation of runs which is done by the subset construction. This will motivate the definition of split trees, and at the same time shows why the subset construction fails for determinising NBW~\footnote{The NBW that \emph{can} be turned into DBW.}.

% For determinising an automaton $A$, the subset construction in effect merges all the diverse runs of $A$ on word $w$ to one single run by merging all the states on a level of the corresponding run tree to one single state. This state will be a state of the output automaton $B$, and is labelled with the set of $A$-states it includes. Figure~\ref{subset_construction_tree} shows this effect with our example automaton from Figure~\ref{automaton} and the word \aom. 

% \begin{figure}
% \centering
% \SubsetConstructionTree
% \caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
% \label{subset_construction_tree}
% \end{figure}

% Clearly, this form of tree created by the subset construction is the most concise form a run tree can be brought to. However, almost all information about individual runs in $A$ has been lost. All that can be said by looking at the structure in Figure~\ref{subset_construction_tree} is that there must be at least one continued $A$-run on \aom (all the other runs visiting the other $A$-states on each level, might be discontinued). But which states a possible continued run visits cannot be deduced.

% This lack of identification $A$-runs is the reason why the subset construction fails for determinising Büchi automata. Note that a $B$-state of the subset construction is accepting if the set of $A$-states it represents contains at least one accepting $A$-state. For our example, this means that the state \qqqq012 is accepting (this is also indicated in Figure~\ref{subset_construction_tree}). This state is visited infinitely often by the unified run on \aom. Hence, the DBW $B$, resulting from applying the subset construction to the NBW $A$, accepts \aom while $A$ does not accept it.

% By looking closer at the trees in Figure~\ref{subset_construction_tree} and~\ref{run_tree}, the reason for this problem becomes apparent. If we look for example at the second level of the subset-construction tree we can deduce that there must be an $A$-run that visits the accepting $A$-state \q1. Let us call this run $r_{q_1}$. However, at the third level, we cannot say anything about $r_{q_1}$ anymore, whether it visits one of the non-accepting states or again \q1 on the third level, or whether it even ended at the second level. In turn, what we know on the third level in our example is that there is again an $A$-run, $r_{q_1}^\prime$, that visits \q1. However, whether $r_{q_1}^\prime$ is $r_{q_1}$, and in turn the future of $r_{q_1}^\prime$ cannot be deduced. In our example we end up with the situation that there are infintiely many visits to \q1 in the unifed $B$-run, but we don't know if the reaon for this are one or more $A$-runs that visit \q1 infinitely often, or infinitely man $A$-runs where each one visits \q1 only finitely often (the way it is in our example). In the first case, it would be correct ot accept the $B$-run, in the second case however it would be wrong as the input automaton $A$ does not accept the word. The subset construction does not distinguish these two cases and hence the determinised automaton $B$ may accept words that the input automaton $A$ rejects. In general, the language of an output DBW of the subset construction is a superset of the language of the input NBW.

% This raises the question how the subset construction can be minimally modified such that the output automaton is equivalent to the input automaton. One solution is to not mix accepting and non-accepting $A$-states in the $B$-states. That is, instead of creating one $B$-state that contains all the $A$-states, as in the subset construction, one creates two $B$-states where one contains the accepting $A$-states and the other the non-accepting $A$-states. Such a construction has been formalised in~\cite{UltesNitsche2007107}. The output automaton $B$ is then not deterministic, but it is equivalent to $A$. The type of run analysis trees that correspond to this refined subset construction are split trees. Figure~\ref{split_tree} shows the first five levels of the split tree of our example automaton $A$ on the word \aom. 

% \begin{figure}
% \centering
% \SplitTreeRightLeft
% \caption{Automaton $A$ and the first five levels of the split tree of the runs of $A$ on the word $a^\omega$.}
% \label{split_tree}
% \end{figure}

% Let us see why the splitted subset construction produces output automata that are equivalent to the input automata. For this equivalence to hold, a branch of a reduced split tree must include infinitely many accepting vertices if and only if there is an $A$-run that visits at least one accepting $A$-state infinitely often. For an infinite branch of a split tree, there must be at least one continued $A$-run. If this infinite branch includes infinitely many accepting vertices, then this $A$-run must infinitely many times go trough an accepting $A$-state. This is certain, because an accepting vertex in a split tree contains \emph{only} accepting $A$-states. Since there are only finitely many accepting $A$-states, the $A$-run must visit at least one of them infinitely often. On the other hand, if an $A$-run includes infinite visits to an accepting state, then this results in a branch of the split tree with infinitely many accepting vertices, since every $A$-run must be ``contained'' in a branch of the split tree.

% Split trees can be seen as run trees where some of the branches are contracted to unified branches. In particular, a split tree unifies as many branches as possible, such that the resulting tree still correctly represents the Büchi acceptance of all the runs included in a unified branch. This can form the basis for constructions that transform an NBW to another equivalent NBW. Split trees are for example the basis for Muller-Schupp trees in Muller and Schupp's Büchi determinisation construction~\cite{Muller199569}, cf.~\cite{2006_althoff}.

% \subsection{Reduced Split Trees}

% It turns out that split trees can be compacted even more. The resulting kind of tree is called reduced split tree. In a reduced split tree, each $A$-state occurs at most once on every level. Figure~\ref{reduced_split_tree} shows the reduced split tree corresponding to the split tree in Figure~\ref{split_tree}. As can be seen, only one occurrence of each $A$-state on each level is kept, the other are discarded. To allow this, however, the order of the accepting and non-accepting siblings in the tree matters. Either the accepting child is always put to the right of the non-accepting child (as in our example in Figure~\ref{reduced_split_tree}, or vice versa. We call the former variant a right-to-left reduced split tree, and the latter a left-to-right reduced split tree. In this thesis, we will mainly adopt the right-to-left version.

% \begin{figure}
% \centering
% \ReducedSplitTreeRightLeft
% \caption{Automaton $A$ and the first five levels of the reduced split tree of the runs of $A$ on the word $a^\omega$.}
% \label{reduced_split_tree}
% \end{figure}

% A reduced split tree is constructed like a split tree, with the following restrictions.
% \begin{itemize}
% \item For determining the vertices on level $n+1$, the parent vertices on level $n$ have to be processed from right to left
% \item From every child vertex on level $n+1$, subtract the $A$-states that occur in some vertex to the right of it on level $n+1$
% \item Put the accepting child to the right of the non-accepting child on level $n+1$
% \end{itemize}

% % Fixed witdth
% A very important property of reduced split trees is that they have a fixed width. The width of a tree is the maximal number of vertices on a level. For reduced split trees, this is the number of states of the input automaton $A$. As we will see, the subset-tuple construction (like other slice-based constructions) uses levels of a reduced split tree as states othe output automaton, and the limited size of these levels ensures an upper bound on the number of states these constructions can create.

% % We delete runs, we keep the "greedy" runs
% By deleting $A$-states from a level of a reduced split tree, we actually delete $A$-runs that reach the same $A$-state on the same substring of the input word. For example, in the split tree in Figure~\ref{split_tree} we see that there are at least for $A$-runs on the string $aaaa$ from the inital state \q0 to \q2. The reduced split tre in Figure~\ref{reduced_split_tree}, however, contains only one run on $aaaa$ from \q0 to \q2, namely the rightmost branch of the tree. The information about all the other runs is lost. This single run that is kept is very special and, as we will see shorty, it represents the deleted runs. We will call this run the \emph{greedy run}. The reason for calling it greedy is that it visits an accepting state earlier than any of the deleted runs. In a right-to-left reduced split tree, the greedy run is always the rightmost of the runs from the root to a certain $A$-state on a certain level. In left-to-right reduced split tree, the greedy run would in turn be the leftmost of these runs.

% % Proof that if any of the deleted runs would be accepting, then the greedy run is accepting
% We mentioned that the greedy run somehow represents the deleted runs. More precisely, the relation is as follows and has been proved in~\cite{vardi2007automata}: if any of the deleted runs is a prefix of a run that is Büchi-accepted (that is, an infinite run visiting infinitely many accepting $A$-states), then the greedy run is so too. That means that if the greedy cannot be expanded to a Büchi-accepting run, then none of the deleted runs could be either. Conversely, if any of the deleted runs could become Büchi-accepting, then the greedy run can so too. So, the greedy run is sufficient to indicate the existence or non-existence of a Büchi-accepting run with this prefix, and it is safe to delete all the other runs.

% \subsection{Run DAGs}
% DAGs (directed acyclic graphs) are, after trees, the second form for analysing the runs of a non-deterministic automaton on a given word. A run DAG has the form of a matrix with one column for each $A$-state and a row for each position in the word. The directed edges go from the vertices on one row to the vertices on the next row (drawn below) according to the transitions in the automaton on the current input symbol. Figure~\ref{run_dag} shows the first five rows of the run DAG of the example automaton in Figure~\ref{automaton} on the word \aom. 

% \begin{figure}
% \centering
% \RunDAG
% \caption{Automaton $A$ and the first five levels of the run DAG of the runs of $A$ on the word $a^\omega$.}
% \label{run_dag}
% \end{figure}

% Like run trees, run DAGs represent all the runs of an automaton on a given word. However, run DAGs are more compact than run trees. The rank-based complementation constructions are based on run DAGs. 



% \section{Run Analysis}
% In a deterministic automaton every word has exactly one run. In a non-deterministic automaton, howevever, a given word may have multiple runs. The analysis of the different runs of a given word on an automaton plays an important role in the complementation of Büchi automata. There are several techniques for analysing the runs of a word that we present in this section.

% \subsection{Run Trees}
% The simplest of run analyis technique is the run tree. A run tree is a direct unfolding of all the possible runs of an automaton $A$ on a word $w$. Each vertex $v$ in the tree represents a state of $A$ that we denote by $\sigma(v)$. The descendants of a vetex $v$ on level $i$ are vertices representing the successor states of $\sigma(n)$ on the symbol $w(i+1)$ in $A$. In this way, every branch of the run tree originating in the root represents a possible run of automaton $A$ on word $w$.

% Figure~\ref{run_tree} shows an example automaton $A$ and the first five levels of the run tree for the word $w = a^\omega$ (infinite repetitions of the symbol $a$). Each branch from the root to one of the leaves represents a possible way for reading the first four positions of $w$. On the right, as a label for all the edges on the corresponding level, is the symbol that causes the depicted transitions.

% \begin{figure}
% \begin{center}
% \RunTree
% \end{center}
% \caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
% \label{run_tree}
% \end{figure}

% ($A$ does not accept any word, it is empty. The only word it could accept is $a^\omega$ which it does not accept.)

% We define by the width of a tree the maximum number of vertices occurring at any level~\cite{Muller199569}. Clearly, for \om-words the width of a run tree may become infinite, because there may be an infinite number of levels and each level may have more vertices than the previous one. 

% \subsection{Failure of the Subset-Construction for Büchi Automata}
% Run trees allow to conveniently reveal the cause why the subset construction does not work for determinising Büchi automata, which in turn motivates the basic idea of the next run analysis technique, split trees.

% Applying the subset construction to the same NBW $A$ used in the previous example, we get the automaton $A^\prime$ shown in Figure~\ref{subset_construction_1}. Automaton $A^\prime$ is indeed a DBW but it accepts the word $a^\omega$ which $A$ does not accept. If we look at the run tree of $A$ on word $a^\omega$, the subset construction merges the individual states occuring at level $i$ of the tree to one single state $s_i$, which is accepting if at least one of its components is accepting. Equally, the individual transitions leading to and leaving from the individual components of $s_i$ are merged to a unified transition. The effect of this is that we lose all the information about these indiviudal transitions. This fact is depicted in Figure~\ref{subset_construction_2}. For the NFA acceptance condition this does not matter, but for NBW it is crucial because the acceptance condition depends on the history of specific runs. In the example in Figure~\ref{subset_construction_1}, a run $\rho$ of $A$ visiting the accepting state $q_1$ can never visit an accepting state anymore even though the unified run of which $\rho$ is part visits $q_1$ infinitely often. But the latter is achieved by infinitely many different runs each visiting $q_1$ just once.

% It turns out that enough information about individual runs to ensure the Büchi acceptance condition could be kept, if accepting and non-accepting state are not mixed in the subset construction. Such a constructio has bee proposed in~\cite{UltesNitsche2007107}. Generally, the idea of treating accepting and non-accepting states separately is important in the run analyis of Büchi automata.





% \subsection{Split Trees}
% Split trees can be seen as run trees where the accepting and non-accepting descendants of a node $n$ are aggregated in two nodes. We will call the former the \emph{accepting child} and the latter the \emph{non-accepting child} of $n$. Thus in a split tree, every node has at most two descendants (if either the accepting or the non-accepting child is empty, it is not added to the tree), and the nodes represent sets of states rather than individual states. Figure~\ref{split_tree} shows the first five levels of the split tree of automaton $A$ on the word $a^\omega$.

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \SplitTreeRightLeft
% \end{center}
% \caption{Automaton $A$ and the first five levels of the split tree of the runs of $A$ on the word $a^\omega$.}
% \label{split_tree}
% \end{figure}


% The order in which the accepting and non-accepting child are 

% The notion of split trees (and reduced split trees, see next section) has been introduced by Kähler and Wilke in 2008 for their slice-based complementation construction~\cite{2008_kaehler}, cf.~\cite{fogarty2013unifying}. However, the idea of separating accepting from non-accepting states has already been used earlier, for example in Muller and Schupp's determinisation-based complementation construction from 1995~\cite{Muller199569}. Formal definitions os split trees can be found in~\cite{2008_kaehler}\cite{fogarty2013unifying}.

% \subsection{Reduced Split Trees}
% The width of a split tree can still become infinitely large. A reduced split tree limits this width to a finite number with the restriction that on any level a given state may occur at most once. This is in effect the same as saying that if in a split tree there are multiple ways of going from the root to state $q$, then we keep only one of them.

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \ReducedSplitTreeLeftRight
% \end{center}
% \caption{Automaton $A$ and the first five levels of the left-to-right reduced split tree of the runs of $A$ on the word $a^\omega$.}
% \label{r_split_tree_lr}
% \end{figure}

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \ReducedSplitTreeRightLeft
% \end{center}
% \caption{Automaton $A$ and the first five levels of the left-to-right reduced split tree of the runs of $A$ on the word $a^\omega$.}
% \label{r_split_tree_rl}
% \end{figure}


% \subsection{Run DAGs}
% A run DAG (DAG stands for directed acyclic graph) can be seen as a graph in matrix form with one column for every state of $A$ and one row for every position of word $w$. The edges are defined similarly than in run trees. Figure~\ref{run_dag} shows the run DAG of automaton $A$ on the word $w = a^\omega$.

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \RunDAG
% \end{center}
% \caption{Automaton $A$ and the first five levels of the run DAG of the runs of $A$ on the word $a^\omega$.}
% \label{run_dag}
% \end{figure} 






% \section{Empirical Performance Investigations}

% \section{Preliminaries}


% \subsection{Büchi Automata}
% Büchi automata have been introduced in 1962 by Büchi~\cite{buchi1960decision} in order to show the decidability of monadic second order logic; over the successor structure of the natural numbers~\cite{2012_breuers}.

% he had proved the decidability of the monadic-second order theory of the natural numbers with successor func- tion by translating formulas into finite automata~\cite{vardi2007automata} (p. 1)

% %To check whether a given S1S formulaφ=φ(V0,...,Vm−1)is satisfiable one simply constructs the Büchi automaton which is guaranteed to exist by Büchi’s Theorem and checks this automaton for non-emptiness~\cite{vardi2007automata} (p. 9).

% Büchi needed to create a complementation construction (proof the closure under complementation of Büchi automata) in order to prove Büchi's Theorem.

% Büchi's Theorem: S1S formulas and Büchi automata are expressively equivalent (there is a NBW for every S1S formula, and there is a S1S formula for every NBW).

% \subsubsection{Definitions}
% Informally speaking, a Büchi automaton is a finite state automaton running on input words of infinite length. That is, once started reading a word, a Büchi automaton never stops. A word is accepted if it results in a run (sequence of states) of the Büchi automaton that includes infinitely many occurrences of at least one accepting state.
% % A word is accepted by a Büchi automaton, if there exists a run (sequence of states) for it that includes infinite repetitions of at least one accepting state. In other words, if during reading a word a Büchi automaton goes through one or more accepting states infinitely often, the word is accepted, and otherwise it is rejected.

% More formally, a Büchi automaton $A$ is defined by the 5-tuple $A = (Q, \Sigma, q_0, \delta, F)$ with the following components.
% \begin{itemize}
% \item $Q$: a finite set of states
% \item $\Sigma$: a finite alphabet
% \item $q_0$: an initial state, $q_0 \in Q$
% \item $\delta$: a transition function, $\delta: Q \times \Sigma \rightarrow 2^Q$ %(mapping combinations of a state and a symbol to zero, one, or more other states)
% \item $F$: a set of accepting states, $F \in 2^Q$
% \end{itemize}

% We denote by $\Sigma^\omega$ the set of all words of infinite length over the alphabet $\Sigma$. A Büchi automaton runs on the elements of $\Sigma^\omega$. In the following, we define the acceptance behaviour of a Büchi automaton $A$ on a word $\alpha \in \Sigma^\omega$.

% % A Büchi automaton runs on infinite words over the alphabet $\Sigma$. We denote by $\Sigma^\omega$ the set of all possible words of infinite length (\om-words) over $\Sigma$. 

% % What distinguishes a Büchi automaton from a finite state automaton on finite words are its conditions for accepting or rejecting words. In the following, we define the acceptance behaviour of a Büchi automaton.

% \begin{itemize}
% % \item $\Sigma^\omega$ is the set of all possible words of infinite length over alphabet $\Sigma$
% \item A \emph{run} of Büchi automaton $A$ on a word $\alpha \in \Sigma^\omega$ is a sequence of states $q_0q_1q_2\dots$ such that $q_0$ is $A$'s initial state and $\forall i \geq 0: q_{i+1} \in \delta(q_i, \alpha_i)$
% \item $\textsf{inf}(\rho) \in 2^Q$ is the set of states that occur infinitely often in a run $\rho$
% \item A run $\rho$ is accepting if an only if $\textsf{inf}(\rho) \cap F \neq \varnothing$
% \item A Büchi automaton $A$ accepts a word $\alpha \in \Sigma^\omega$ if and only if there is an accepting run of $A$ on $\alpha$
% \end{itemize}

% The set of all the words that are accepted by a Büchi automaton $A$ is called the \emph{language} $L(A)$ of $A$. Thus, $L(A) \subseteq \Sigma^\omega$. On the other hand, the set of all words of $\Sigma^\omega$ that are rejected by $A$ is called the \emph{complement language} $\overline{L(A)}$ of $A$. The complement language can be defined as $\overline{L(A)} = \Sigma^\omega \setminus L(A)$.

% Büchi automata are closed under union, intersection, concatenation, and complementation~\cite{1996_vardi}.

% Continued/discontinued runs

% A deterministic Büchi automaton (DBW) is a special case of a non-determnistic Büchi automaton (NBW). A Büchi automaton is a DBW if $|\delta(q,\alpha)| = 1, \, \forall q \in Q, \forall \alpha \in \Sigma $. That is, every state has for every alphabet symbol exactly one successor state. A DBW can also be defined directly by replacing the transition function $\delta: Q \times \Sigma \rightarrow 2^Q$ with $\delta: Q \times \Sigma \rightarrow Q$ in the above definition.

% \subsubsection{Expressiveness}
% It has been showed by Büchi that NBW are expressively equivalent the \om-regular languages~\cite{buchi1960decision}. That means that every language that is recognised by a NBW is a \om-regular language, and on the other hand, for every \om-regular language there exists a NBW recognising it.

% However, this equivalence does not hold for DBW (Büchi showed it too). There are \om-regular languages that cannot be recognised by any DBW. A typical example is the language $(0+1)^*1^\omega$. This is the language of all infinite words of 0 and 1 with only finitely many 0. It can be shown that this language can be recognised by a NBW (it is thus a \om-regular language) but not by a DBW~\cite{1996_vardi}\cite{2002_roggenbach}. The class of languages recognised by DBW is thus a strict subset of \om-regular languages recognised by NBW. We say that DBW are less expressive than NBW.

% An implication of this is that there are NBW for which no DBW recognising the same language exists. Or in other words, there are NBW that cannot be converted to DBW. Such an inequivalence is not the case, for example, for finite state automata on finite words, where every NFA can be converted to a DFA with the subset construction~\cite{hopcroft2006automata}\cite{1959_rabin}. In the case of Büchi automata, this inequivalence is the main cause that Büchi complementation problem is such a hard problem~\cite{niessner1997deterministic} and until today regarded as unsolved. 



% \subsubsection{Deterministic and Non-Deterministic Büchi Automata}
% As for normal finite state automata, there are deterministic and non-deterministic versions of Büchi automata. The difference lies in the transition function. For the non-deterministic case it is $\delta: \Sigma \times Q \rightarrow 2^Q$, but for the deterministic case it is strictly $\delta: \Sigma \times Q \rightarrow Q$. That means, whereas in a non-deterministic Büchi automaton a state $q$ may have zero, one, or more successors on a given symbol $a$ (denoted by $\delta(q,a) \geq 0$), in a deterministic Büchi automaton this number is always exactly one ($\delta(q,a) = 1$).

% The definition of a Büchi automaton given above is thus in fact the definition of a non-deterministic Büchi automaton. This coincides with a convention that we adopt in this thesis. If not explicitly stated, when we say ``Büchi automaton'' we actually mean a non-deterministi Büchi automaton. This is first, because deterministic Büchi automata are a special case of non-deterministic Büchi automata, and second, the problem of complementation that this thesis is about is only significant for the non-deterministic case.

% A Büchi automaton is complete if every state has at least one outgoing transition for every symbol of the alphabet. Formally, this means that $|\delta(q,a)| \geq 1, \forall q \in Q, \forall a \in \Sigma$. Note that deterministic Büchi automata are always complete, and thus only non-deterministic Büchi automata can be incomplete

% \subsubsection{Equivalences}
% An important property of Büchi automata is that deterministic Büchi automata are less expressive than non-deterministic Büchi automata. That means that there exist non-deterministic Büchi automata for which no deterministic Büchi automata accepting the same language exists.

% Non-deterministic Büchi automata in turn are equivalent to the \om-regular languages. That means that every language that is recognised by any Büchi automaton is an \om-regular language, and for every \om-regular language there exists a non-deterministic Büchi automaton recognising it.

% Furthermore, non-deterministic Büchi automata are equivalent to other classes of \om-automata such as Muller, Rabin, Streett, and Parity automata. Within these classes, determinstic and non-deterministic automata are equivalent. This means that every Büchi automaton can be translated to an equivalent deterministic or non-deterministic Muller, Rabin, Streett, or Parity automaton, and any of these latter automata can be translated to a non-deterministic Büchi automaton. Figure~\ref{equivalences} summarises these expressive relations of Büchi automata.



% \subsection{Other \om-Automata}
% %     - Muller, Rabin, Streett, Parity
% %     - McNaughton's Theorem (NBW = DMW)
% %     - Complete picture of equivalences
% After the introduction of Büchi automata in 1962, several other types of \om-automata have been proposed. The best-known ones are by Muller (Muller automata, 1963)~\cite{1963_muller}, Rabin (Rabin automata, 1969)~\cite{rabin1969decidability}, Streett (Streett automata, 1982)~\cite{Streett1982121}, and Mostowski (parity automata, 1985)~\cite{1985_mostowski}.

% % The best-known ones are Muller (1963)~\cite{1963_muller}, Rabin (1969)~\cite{rabin1969decidability}, Streett (1982)~\cite{Streett1982121}, and parity (1985)~\cite{1985_mostowski} automata. 

% All these automata differ from Büchi automata, and among each other, only in their acceptance condition, that is, the condition for accepting or rejecting a run $\rho$. We can write a general definition of \om-automata that covers all of these types as $(Q, \Sigma, q_0, \delta, Acc)$. The only difference to the 5-tuple defining Büchi automata is the last element, $Acc$, which is a general acceptance condition. We list the acceptance condition of all the different \om-automata types below~\cite{1999_loeding}. Note that again a run $\rho$ is a sequence of states, and $\textsf{inf}(\rho)$ is the set of states that occur infinitely often in run $\rho$. 

% % Itemize of all acceptance conditions, including Büchi
% \begin{tabular}{|l|l|l|}
% \hline
% \textbf{Type} & \textbf{Definitions} & \textbf{Run $\rho$ accepted if and only if\dots} \\
% \hline
% Büchi & $F \subseteq Q$ & $\textsf{inf}(\rho) \cap F \neq \varnothing$ \\
% \hline
% Muller & $F \subseteq 2^Q$ & $\textsf{inf}(\rho) \in F$ \\
% \hline
% Rabin & $\{(E_1,F_1),\dots,(E_r,F_r)\},\,E_i, F_i \subseteq Q$ & $\exists i: \textsf{inf}(\rho) \cap E_i = \varnothing \, \wedge \, \textsf{inf}(\rho) \cap F_i \neq \varnothing$ \\
% \hline
% Streett & $\{(E_1,F_1),\dots,(E_r,F_r)\},\,E_i, F_i \subseteq Q$ & $\forall i: \textsf{inf}(\rho) \cap E_i \neq \varnothing \, \vee \, \textsf{inf}(\rho) \cap F_i = \varnothing$ \\
% \hline
% Parity & $c: Q \rightarrow \{1,\dots,k\},\,k \in \mathbb{N}$ & $\textrm{min}\{c(q)\;|\;q \in \textsf{inf}(\rho) \} \; \textrm{mod} \; 2 = 0$ \\
% \hline
% \end{tabular}

% In the Muller acceptance condition, the set of infinitely occuring states of a run ($\textsf{inf}(\rho)$) must match a predefined set of states.
% % The Muller acceptance condition is the most general one, and all of the other listed conditions can be expressed as a Muller acceptance condition~\cite{1999_loeding}.
% The Rabin and Streett conditions use pairs of state sets, so-called accepting pairs. The Rabin and Streett conditions are the negations of each other. This allows for easy complementation of deterministic Rabin and Streett automata~\cite{1999_loeding}, which will be used for certain Büchi complementation construction, as we will see in Section\ref{review}. The parity condition assigns a number (color) to each state and accepts a run if the smallest-numbered of the infinitely often occuring states has an even number. For all of these automata there exist non-deterministic and deterministic versions, and we will refer to them as NMW, DMW (for non-deterministic and deterministic Muller automata), and so on.

% In 1966, McNaughton made an important proposition, known as \emph{McNaughton's Theorem}~\cite{McNaughton1966}. Another proof given in~\cite{Thomas:1991}. It states that the class of languages recognised by deterministic Muller automata are the \om-regular languages. This means that non-deterministic Büchi automata and deterministic Muller automata are equivalent, and consequently every NBW can be turned into a DMW. This result is the base for the determinisation-based Büchi complementation constructions, as we will see in Section~\ref{det-based}.

% It turned out that also all the other types of the just introduced \om-automata, non-deterministic and determinstic, are equivalent among each other~\cite{2002_roggenbach}\cite{2006_klein}\cite{klein2005linear}\cite{1999_loeding}\cite{Thomas:1991}. This means that all the \om-automata mentioned in this thesis, with the exception of DBW, are equivalent and recognise the \om-regular languages. This is illustrated in Figure~\ref{equivalences}



% % For all of them exist deterministic and non-deterministic versions
% % Properties, such as Rabin acceptance condition is dual of Streett

% % McNaughtons Theorem (1966) \cite{McNaughton1966}, another proof in \cite{Thomas:1991}: NBW = DMW

% % It turns out that all of NMW, DMW, NRW, DRW, NSW, DSW, NPW, DPW are equivalent among each other

% % Picture of expressive equivalences
% \begin{figure}[htb]
% \begin{center}
% \Equivalences
% \caption{Non-deterministic Büchi automata (NBW) are expressively equivalent to Muller, Rabin, Streett, and parity automata (both deterministic and non-deterministic), and to the \om-regular languages. Deterministic Büchi automata (DBW) are less expressive than NBW.}
% \label{equivalences}
% \end{center}
% \end{figure}


% \subsection{Complementation of Büchi Automata}
% \label{intro:complementation}
% Büchi automata are closed under complementation. This result has been proved by Büchi himself when he introduced Büchi automata in~\cite{buchi1960decision}. Basically, this means that for every Büchi automata $A$, there exists another Büchi automaton $B$ that recognises the complement language of $A$, that is, $L(B) = \overline{L(A)}$.

% It is interesting to see that this closure does not hold for the specific case of DBW. That means that while for every DBW a complement Büchi automaton does indeed exist, following from the above closure property for Büchi automata in general, this automaton is not necessarily a DBW. The complement of a DBW may be, and often is, as we will see, a NBW. This result is proved in~\cite{Thomas:1991} (p. 15).

% The problem of Büchi complementation consists now in finding a procedure (usually called a construction) that takes as input any Büchi automaton $A$ and outputs another Büchi automaton $B$ with $L(B) = \overline{L(A)}$, as shown below.

% \hbox to \hsize{\hfill{\Complementation}\hfill}

% For complementation of automata in general, construction usually differ depending on whether the input automaton $A$ is deterministic or non-deterministic. Complementation of deterministic automata is often simpler and may sometimes even provide a solution for the complementation of the non-deterministic ones.

% To illustrate this, we can briefly look at the complementation of the ordinary finite state automata on finite words (FA). FA are also closed under complementation~\cite{hopcroft2006automata} (p. 133). A DFA can be complemented by simply switching its accepting and non-accepting states~\cite{hopcroft2006automata} (p. 133). Now, since NFA and DFA are equivalent~\cite{hopcroft2006automata} (p. 60), a NFA can be complemented by converting it to an equivalent DFA first, and then complement this DFA. Thus, the complementation construction for DFA provides a solution for the complementation of NFA.

% Returning to Büchi automata, the case is more complicated due to the inequivalence of NBW and DBW. The complementation of DBW is indeed ``easy'', as was the complementation of DFA. There is a construction, introduced in 1987 by Kurshan~\cite{Kurshan198759}, that can complement a DBW to a NBW in polynomial time. The size of the complement NBW is furthermore at most the double of the size of the input DBW.

% If now for every NBW there would exist an equivalent DBW, an obvious solution to the general Büchi complementation problem would be to transform the input automaton to a DBW (if it is not already a DBW) and then apply Kurshan's construction to the DBW. However, as we have seen, this is not the case. There are NBW that cannot be turned into equivalent DBW.

% Hence, for NBW, other ways of complementing them have to be found. In the next section we will review the most important of these ``other ways'' that have been proposed in the last 50 years since the introduction of Büchi automata. The Fribourg construction, that we present in Chapter~\ref{fribourg_construction}, is another alternative way of achievin this same aim.


% \subsection{Complexity of Büchi Complementation}

% % (0.76n)^n
% % n = 15
% % (0.76*15)^15 = 7.138 * 10^15 = 7.138 quadrillions
% % 1 quadrillion = 10^15 = 10^6*10^9 = 1 million billions

% Constructions for complementing NBW turned out to be very complex. Especially the blow-up in number of states from the input automaton to the output automaton is significant. For example, the original complementation construction proposed by Büchi~\cite{buchi1960decision} involved a doubly exponential blow-up. That is, if the input automaton has $n$ states, then for some constant $c$ the output automaton has, in the worst case, $c^{c^n}$ states~\cite{PrasadSistla1987217}. If we set $c$ to 2, then an input automaton with six states would result in a complement automaton with about 18 quintillion ($18 \times 10^{18}$) states.

% Generally, state blow-up functions, like the $c^{c^n}$ above, mean the absolute worst cases. It is the maximum number of states a construction \emph{can} produce. For by far most input automata of size $n$ a construction will produce much fewer states. Nevertheless, worst case state blow-ups are an important (the most important?) performance measure for Büchi complementation constructions. A main goal in the development of new constructions is to bring this number down.

% A question that arises is, how much this number can be brought down? Researchers have investigated this question by trying to establish so called lower bounds. A lower bound is a function for which it is proven that no state blow-up of any construction can be less than it. The first lower bound for Büchi complementation has been established by Michel in 1988 at $n!$~\cite{michel1988}. This means that the state blow-up of any Büchi complementation construction can never be less than $n!$.

% There are other notations that are often used for state blow-ups. One has the form $(xn)^n$, where $x$ is a constant. Michel's bound of $n!$ would be about $(0.36n)^n$ in this case~\cite{2006_yan}. We will often use this notation, as it is convenient for comparisons. Another form has 2 as the base and a big-O term in the exponent. In this case, Michel's $n!$ would be $2^{O(n\,log\,n)}$~\cite{2006_yan}.

% Michel's lower bound remained valid for almost two decades until in 2006 Yan showed a new lower bound of $(0.76n)^n$~\cite{2006_yan}. This does not mean that Michel was wrong with his lower bound, but just too reserved. The best possible blow-up of a construction can now be only $(0.76n)^n$ and not $(0.36n)^n$ as believed before. In 2009, Schewe proposed a construction with a blow-up of exactly $(0.76n)^n$ (modulo a polynomial factor)~\cite{schewe2009buchi}. He provided thus an upper bound that matches Yan's lower bound. The lower bound of $(0.76n)^n$ can thus not rise any further and seems to be definitve.

% Maybe mention note on exponential complexity in \cite{1996_vardi} p. 8.


% \subsection{Complementation of Büchi Automata}
% It has been proved by Büchi himself that Büchi automata are closed under complementation~\cite{buchi1960decision}. That means that for every Büchi automaton, there exists another Büchi automaton accepting the complement language of the initial automaton.

% Let us denote by $L(A)$ the language recognised by Büchi automaton $A$. Then the complement language $\overline{L(A)}$ of $L(A)$ is $\overline{L(A)} = \Sigma^\omega \setminus L(A)$.

% \hbox to \hsize{\hfill{
% \begin{tikzpicture}[item/.style={rectangle,draw,text width=2.5cm}]
% \node[] (left) {$A$ with $L(A)$};
% \node[item] (middle) [right=of left] {Complementation algorithm};
% \node[] (right)  [right=of middle] {$B$ with $L(B) = \overline{L(A)}$}; 
% \path[->] (left) edge (middle)
%           (middle) edge (right);
% \end{tikzpicture}}\hfill}

% The problem of Büchi complementation can thus be summarised as follows. Given a Büchi automaton $A$, find a Büchi automaton $B$, such that $L(B) = \overline{L(A}$. For solving this problem we need an algorithm that takes $A$ as input and returns $B$ as output. 

% As a starting point, let us look at the complementation problem for normal finite state automata on finite words. Normal finite state automata recognise the regular languages and are also closed under complementation. For deterministic finite state automata, a possible complementation algorithm consists in simply inverting the accepting and non-accepting states of the automaton. Inuitively, every word that leaves the input automaton in an accepting state will leave the output automoaton in a non-accepting state, and vice versa. For the case of non-deterministic automata, one can take adavantage of the fact that every non-deterministic automata can be converted to an equivalent deterministic automaton. A standard algorithm for this conversion is the subset-construction, which is described in detail in [cite Hopcroft, Sec. 2.3.5]. The subset-construction basically takes all the subsets of states of the input automaton as states of the output automaton. A possible complementation algorithm for non-deterministic finite state automata consists thus in determinisation by the subset-construction and complementation by switching accepting and non-accepting states.

% Again, the cases of deterministic and non-deterministic automata are treated separately. For DBW, the method of switching accepting and non-accepting states does not work. Imagine for example that $\rho$ is the run of the word $x \in \Sigma^\omega$ of automaton $A$ (a DBW has exactly one run for every word of $\Sigma^\omega$). If $\textsf{inf}(\rho)$ contains both an accepting and a non-accepting state, then the switching of accepting and non-accepting states has no effect on the acceptance of $x$, as it is accepted in both cases. A working procedure for complementing DBW has been described by Kurshan [cite Kurshan, 1987]. Kurshan's construction is relatively easy and can be described in one sentence: make all states of the input automaton $A$ non-accepting, add another copy of $A$, remove all its accepting states and make the non-accepting states accepting, and finally add transitions from the states of the first copy of $A$ to the corresponding destination states in the second copy of $A$. The resulting automaton is an NBW $B$ that accepts the complement language of the input DBW $A$.

% In the case of finite-word automata, the complementation procedure for DFA provided a solution for the complementationn of NFA, because there is a translation from every NFA to an equivalent DFA. For Büchi automata this is however not the case. As mentioned above, there are NBW for which no equivalent DBW exists. We say that NBW can in general not be determinised.



% \section{Review of Büchi Complementation Constructions}
% \label{review}
% \subsection{Ramsey-Based Approaches}
% \label{ramsey-based}
% The method is called Ramsey-based because its correctness relies on a combinatorial result by Ramsey to obtain a periodic decomposition of the possible behaviors of a Büchi automaton on an infinite word~\cite{2012_breuers}.

% \subsection{Determinisation-Based Approaches}
% \label{det-based}
% \subsection{Rank-Based Approaches}
% \label{rank-based}
% \subsection{Slice-Based Approaches}
% \label{slice-based}

% \section{Empirical Performance Investigations}