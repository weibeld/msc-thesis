In this chapter we treat several topics that serve as a background for the rest of the thesis. In particular, the goal of this chapter is to set the stage for our description of the Fribourg construction in Chapter~\ref{chap_construction}, and the setup of our empirical performance investigation of the Fribourg construction in Chapter~\ref{chap_investigation}, as well as its results in Chapter~\ref{chap_results}.

In Section~\ref{2_automata} we summarise some aspects about Büchi automata, as well as about other types of automata on infinite words, that are relevant to the purpose of Büchi complementation. In Section~\ref{2_run_analysis}, we describe the principal techniques for run analysis of non-deterministic automata. This topic has a particular relation to Büchi complementation, and one of the run analysis techniques, reduced split trees, is the core of the Fribourg construction. In Section~\ref{2_review}, we provide a review of proposed Büchi complementation constructions from the introduction of Büchi automata in 1962 until today. We organise the presentation of these constructions along the four main Büchi complementation approaches Ramsey-based, determinisation-based, rank-based, and slice-based. Some of the constructions that we describe in this section will be used in the performance investigation of the Fribourg construction in Chapter~\ref{chap_investigation}.

\section{Büchi Automata and Other Omega-Automata}
\label{2_automata}
Büchi automata are a type of \om-automata. These are fninite state automata that run on infinite words (so-called \om-words). Externally, \om-automata look the same as the traditional finite state automata on finite words. It is possible to interpret any such automaton on finite words as an \om-automaton, and vice versa.

The difference between \om-automata and automata on finite words is their acceptance condition. An automaton on finite words accepts a word, if after finishing reading it, the automaton is in an accepting state. For \om-automata, this acceptance condition is not possible, because an \om-automaton never finishes reading a word (because the word ``never ends''). Instead, the acceptance condition of \om-automata is defined on the set of the so-called \textit{infinitely recurring states}. We are going to describe this concept in Subsection~\ref{2_buchi_automata} below. 

In Subsection~\ref{2_buchi_automata} of this section, wer first treat Büchi automata, and in Subsection~\ref{2_om-automata} the principal other types of \om-automata, in particular, Muller, Rabin, Streett, and parity automata. In the latter subsection, we also introduce a shorthand notation for different types of \om-automata that we will use throughout the thesis.

Note that in the entire section we omit overly formal notation and proofs of any kind, because it is not necessary for the aim of this thesis. More comprehensive and formally rigorous treatments of \om-automata can be found, for example, in the works by Thomas~\cite{Thomas:1991,1996_thomas}, or Wilke~\cite{2014_wilke}.

\subsection{Büchi Automata}
\label{2_buchi_automata}
Below we summarise the aspects of Büchi automata that are most significant for our purposes, including the acceptance condition of Büchi automata, the expressivity of non-deterministic and deterministic Büchi automata, and basics about the complementation of non-deterministic and deterministic Büchi automata. In the course of this, we always stress the difference between deterministic and non-deterministic Büchi automata, as this is one of the main sources for the intricacy of Büchi complementation~\cite{niessner1997deterministic}.  

\subsubsection{Definition and Acceptance Condition}
A non-deterministic Büchi automaton $A$  is defined by the 5-tuple $A = (Q, \Sigma, \delta, q_0 F)$ with the following components:
\begin{itemize}
\item $Q$: a finite set of states
\item $\Sigma$: a finite alphabet
\item $\delta$: a transition function, $\delta: Q \times \Sigma \rightarrow 2^Q$
\item $q_0$: an initial state, $q_0 \in Q$
\item $F$: a set of accepting states, $F \subseteq Q$
\end{itemize}

Note that this is the same definition as for non-deterministic finite state automata on finite words~\cite{hopcroft2006automata}. The difference between Büchi automata and automata on finite words is only the acceptance condition of Büchi automata that we describe below. For deterministic Büchi automata, the definition is similar to the above one, but with a different transition function $\delta$ that returns none or a single state, instead of a set of states

An important concept in automata theory the notion of a \textit{run} of an automaton on a given word. A run $\rho$ of automaton $A$ on word $\alpha$ is a sequence of states $q in Q$ that $A$ visits in the process of reading $\alpha$. For finite words, the length of a run is finite as well, however, for \om-words, the length of a run may be infinite. Note that deterministic automata have at most one run for a given word, whereas non-deterministic automata may have multiple possible runs for the same word.

The Büchi acceptance condition decides whether a run $\rho$ is accepting or non-accepting. This in turn determines the acceptance or non-acceptance of a word: a word $\alpha$ is accepted by an automaton $A$, if and only if it has at least one accepting run in $A$. The decision whether a run $\rho$ is accepting or non-accepting is based on the set of \textit{infinitely recurring states} of $\rho$ that we denote by $\textsf{inf}(\rho)$. This set contains all the states that occur infinitely often in $\rho$. In particular, the Büchi acceptance condition is as follows:

\begin{quote}
\centering
Run $\rho$ is accepting $\Longleftrightarrow$ $\textsf{inf}(\rho)$ contains at least one accepting state
\end{quote}

That is, a run is accepting, if and only if the run contains at least one accepting state infintely often. Formally, this can be written as $\textsf{inf}(\rho) \cap F \neq \varnothing$. 

An intuitive way for describing the Büchi acceptance condition has been given by Vardi~\cite{1996_vardi}. If we imagine the automaton having a green light that blinks whenever the automaton visits an accepting state, then the run is accepting if we observe the green light blinking infinitely many times. The fact that there are only finitely man accepting states, but the light blinks infinitely many times, implies that at least one accepting state is being visited infinitely often.

\subsubsection{Expressivity}
A particularity of Büchi automata is that deterministic and non-deterministic automata are \textit{not} expressively equivalent. In particular, the class of languages corresponding to the deterministic Büchi automata is a strict subset of the class of languages corresponding to the non-deterministic automata. This result has been proved by Büchi himself in his 1962 paper~\cite{buchi1960decision}.

This contrasts, for example, with finite state automata on finite words. In this case, non-deterministic and deterministic automata are expressively equivalent, and consequently every non-deterministic automaton can be turned into an equivalent deterministic automaton. With Büchi automata, however, this is not possible, because there exist languages that can be expressed by a non-deterministic Büchi automaton, but not by a deterministic one. An example of such a language is $(0+1)^*1^\omega$, that is, the language of all words of 0 and 1 ending with an infinite sequence of 1. A non-deterministic automaton representing this language, cannot be turned into an equivalent deterministic automaton~~\cite{1996_vardi, 2002_roggenbach}. Because of this fact, we say that Büchi automata can \textit{in general} not be determinised. This fact has implications on the complementation of non-deterministic Büchi automata, as we will see below.

The class of languages that is equivalent to the \textit{non-deterministic} Büchi automata is the class of \textit{\om-regular languages}. A formal description of the \om-regular languages can be found, for example, in~\cite{Thomas:1991,1996_thomas,2014_wilke}. Regarding deterministic Büchi automata, consequently the set of languages that is equivalent to them is a strict subset of the \om-regular languages.

% Büchi automata are expressively equivalent to the \om-regular languages. This means that every language recognised by a Büchi automaton is an \om-regular language, and that for every \om-regular language there exists a Büchi automaton that recognises it. This property has been proved by Büchi himself in his initial publication in 1962~\cite{buchi1960decision}.

% However, this equivalence with the \om-regular languages does only hold for \textit{non-deterministic} Büchi automata. Deterministic Büchi automata are less expressive than non-deterministic Büchi automata. In particular, the class of languages represented by deterministic Büchi automata is a strict subset of the class of languages represented by non-deterministic Büchi automata. This property has also been proved by Büchi~\cite{buchi1960decision}.

% This means that there exist languages that can be recognised by a non-deterministic Büchi automaton, but not by a deterministic one. A typical example is the language $(0+1)^*1^\omega$. This is the language of all words consisting of 0 and 1 with a finite number of 0 and an infinite number of 1. It is proved in various publications that this language can be recognised by a non-deterministic Büchi automaton, but not by a deterministic Büchi automaton~\cite{1996_vardi}\cite{2002_roggenbach}.

% The most important consequence of this fact is that Büchi automata can, in general, not be determinised. This means that it is not possible to turn \textit{every} non-deterministic Büchi automaton into a deterministic one. This contrasts with the case of the classical finite state automata on finite words, where \textit{every} non-deterministic automata (NFA) can be turned into a deterministic automaton (DFA), by the means of, for example, the subset constrution introduced by Rabin and Scott in 1959~\cite{1959_rabin}.

% It has been stated that the fact that Büchi automata can in general not be determinised is the main reason that Büchi complementation is such a hard problem~\cite{niessner1997deterministic}. We will see why this is the case below.

\subsubsection{Complementation}
Non-deterministic Büchi automata are closed under complementation. This means that the complement of every non-deterministic Büchi automaton is another non-deterministic Büchi automaton. This result has been proved by Büchi in his 1962 paper~\cite{buchi1960decision}\footnote{Actually, the proof of closure under complementation of non-deterministic Büchi automata was a necessary step for Büchi to prove the equivalence of Büchi automata and S1S formulas (Büchi's Theorem). In order to prove this closure under complementation, Büchi described the first Büchi complementation construction in history.}. Deterministic Büchi automata, on the other hand, are not closed under complementation~\cite{Thomas:1991}. In particular, this means that the complement of a deterministic Büchi automaton is still a Büchi automaton, however, possibly a non-deterministic one.

As we already mentioned, the algorithmic difficulty and complexity of complementation is very different for deterministic and non-deterministic automata. For deterministic Büchi automata, there exists a simple procedure, introduced in 1987 by Kurshan~\cite{Kurshan198759}, that can complement a deterministic Büchi automaton to a non-deterministic Büchi automaton in polynomial time and linear space.

For non-deterministic Büchi automata, however, there exists no easy solution. The main reason is that Büchi automata can in general not be determinised. If they could be determinised, then a solution would be to transform a non-deterministic Büchi automaton to an equivalent deterministic one, and complement the deterministic Büchi automaton with Kurshan's construction. This is by the wy the approach that is used for the complementation of non-deterministic automata on finite words: determinise a non-deterministic automaton with the subset construction~\cite{1959_rabin}, and then trivially complement the deterministic automaton by making the accepting states non-accepting, and vice versa. Unfortunately, for Büchi automata such a simple procedure is not possible, and this can be seen as the main reason that Büchi complementation is such a hard problem~\cite{niessner1997deterministic}.

% Büchi automata are closed under complementation. This means that the complement of every Büchi automaton (non-deterministic or deterministic) is in turn a Büchi automaton. This result has been proved by Büchi in his introducing paper from 1962~\cite{buchi1960decision}.

% The difficulty of the concrete complementation problem does however strongly depend on whether the Büchi automaton is deterministic or non-deterministic. For deterministic Büchi automata, the complementation is ``easy'' and regarded as a ``solved problem''. There is a well-known construction introduced by Kurshan in 1987 that complements a deterministic Büchi automaton in polynomial time~\cite{Kurshan198759}. The resulting complement is a non-deterministic Büchi automaton and has a size that is at most the double of the input automaton.

% For non-deterministic Büchi automata, on the other hand, the complementation problem is much more difficult. The main reason is, as mentioned, the fact that non-deterministic Büchi automata cannot be determinised. If they could be determinised, then a non-deterministic Büchi automata could be complemented by first determinising it, and then complementing the deterministic automaton with the Kurshan construction. If the determinisation construction would also be efficient (that is, having polynomial complexity), then we would have an efficient complementation procedure for non-deterministic Büchi automata. In this case, ``Büchi complementation'' would probably be no active research topic but rather a solved problem.

% However, non-deterministic Büchi automata cannot be determinised, and hence this straightforward complementation approch is not possible. Consequently, different ways for complementing non-deterministic Büchi automata have to be found, and these ways turn out to be very complex. It is this complexity that makes Büchi complementation an active research topic as, regarding the concrete usages of Büchi complementation in, for example, model checking, it is of great importance to find more and more efficient ways to complement non-deterministic Büchi automata. 


\subsection{Other Omega-Automata}
\label{2_om-automata}
After the introduction of Büchi automata in 1962, several other types of \om-automata have been introduced. These automata differ from Büchi automata only in their acceptance condition, that is, in the way they decide whether a run $\rho$ is accepting or non-accepting. All these acceptance condition are however based on the set of infintely recurring states $\textsf{inf}(\rho)$ of $\rho$. The following are the most important of these alternative \om-automata along with the year of their introduction.

\begin{itemize}
\item Muller automata (1963)~\cite{1963_muller}
\item Rabin automata (1969)~\cite{rabin1969decidability}
\item Streett automata (1982)~\cite{Streett1982121}
\item Parity automata (1985)~\cite{1985_mostowski}
\end{itemize}

Some of these automata types are used in complementation constructions, especially in determinisation-based complementation constructions (see Section~\ref{2_review}). Table~\ref{acc_conditions} lists the Muller, Rabin, Streett, and parity acceptance conditions, along with the Büchi acceptance condition for comparison.

% After the introduction of Büchi automata in 1962, several other types of \om-automata have been proposed. The most notable ones are Muller automata (Muller, 1963~\cite{1963_muller}), Rabin automata (Rabin, 1969~\cite{rabin1969decidability}), Streett automata (Streett, 1982~\cite{Streett1982121}), and parity automata (Mostowski, 1985~\cite{1985_mostowski}).

% Description in \cite{2014_wilke}

% These automata differ from Büchi automata only in their acceptance condition, that is, the condition that a run $\rho$ is accepted. Table~\ref{acc_conditions} gives a formal definition of the acceptance conditions of these types of \om-automata.

\begin{table}[htb]
\centering
\begin{tabular}{lll}
\hline
Type & Definitions & Condition \\
\hline
Muller  & $U \subseteq 2^Q$ &
          $\textsf{inf}(\rho) \in U$ \\
Rabin   & $\{(U_1,V_1),\dots,(U_r,V_r)\},\,U_i, V_i \subseteq Q$ &
          $\exists i: \textsf{inf}(\rho) \cap U_i = \varnothing \, \wedge \, \textsf{inf}(\rho) \cap V_i \neq \varnothing$ \\
Streett & $\{(U_1,V_1),\dots,(U_r,V_r)\},\,U_i, V_i \subseteq Q$ &
          $\forall i: \textsf{inf}(\rho) \cap U_i \neq \varnothing \, \vee \, \textsf{inf}(\rho) \cap V_i = \varnothing$ \\
Parity  & $\pi: Q \rightarrow \{1,\dots,k\},\,k \in \mathbb{N}$ &
          $\textsf{min}(\{\pi(q)\;|\;q \in \textsf{inf}(\rho) \}) \; \textsf{mod} \; 2 = 0$ \\
Büchi   & &
          $\textsf{inf}(\rho) \cap F \neq \varnothing$ \\
\hline
\end{tabular}
\caption{Acceptance conditions of Muller, Rabin, Streett, parity, and Büchi automata. Note that $Q$ denotes the set of states and $F$ the set of accepting states of the corresponding automaton.}
\label{acc_conditions}
\end{table}

Below, we briefly explain the acceptance conditions of Muller, Rabin, Streett, and parity automata in words.

{\setlist[description]{leftmargin=0.5cm, itemsep=\parskip}
\begin{description}
\item[Muller acceptance condition]
Includes a set $U$ of subsets of states. A run $\rho$ is accepting if and only if $\textsf{inf}(\rho)$ equals one of the pre-defined subsets in $U$. The Muller acceptance condition is the most general one, and the Rabin, Streett, parity, and Büchi acceptance conditions can be expressed as Muller acceptance conditions~\cite{2014_wilke,1999_loeding}.

\item[Rabin acceptance condition]
Inludes a list of pairs $(U, V)$ where $U$ and $V$ are subsets of states. A run $\rho$ is accepting if and only if \textit{there is} at least one pair for which $U$ does not contain any states of $\textsf{inf}(\rho)$ \textit{and} $V$ contains at least one state of $\textsf{inf}(\rho)$. A pair $(U, V)$ is called a Rabin pair.

\item[Streett acceptance condition]
Inludes a list of pairs $(U, V)$ where $U$ and $V$ are subsets of states. A run $\rho$ is accepting if and only if \textit{for all} the pairs either $U$ contains at least one state of $\textsf{inf}(\rho)$ \textit{or} $V$ does not contain any states of $\textsf{inf}(\rho)$. A pair $(U, V)$ is called a Streett pair. Note that the Streett condition is the complement of the Rabin condition. This means that if we have two identical Rabin and Streett automata with an identical list of pairs, then the Streett automaton accepts a run if and only if the Rabin automaton does not accept the same run.

\item[Parity acceptance condition]
Assigns a number to each of the states of the automaton. A run $\rho$ is accepting if and only if the smallest-numbered element of $\textsf{inf}(\rho)$ has an even number. The numbers that are assigned to the states are sometimes called colours~\cite{1999_loeding}.
\end{description}}

Regarding the expressivity of these automata, it turns out that they are all equivalent to non-deterministic Büchi automata, and thus to the \om-regular languages~\cite{2014_wilke}. This holds for non-determnistic \textit{and} deterministic automata of these types. That means that, unlike Büchi automata, deterministic and non-deterministic Muller, Rabin, Streett, and parity automata are expressively equivalent.

At this point we introdue a notation that we will occasionally use for denoting different types of \om-automata. This notation has been used by Piterman~\cite{2006_piterman} and later by Tsai et al.~\cite{2011_tsai}. It consists of three-letter acronymes of the form
\[
\{N, D\} \times \{B, M, R, S, P\} \times W
\]
The first letter specifies whether the automaton is non-deterministic ($N$) or deterministic ($D$). The second letter stands for the acceptance condition: $B$ for Büchi, $M$ for Muller, $R$ for Rabin, $S$ for Streett, and $P$ for parity. The last letter specifies on which structure the automaton runs. In our case these are always words, thus the last letter is always $W$. For example, NBW means non-deterministic Büchi automaton, DBW means deterministic Büchi automaton, NMW means non-deterministic Muller automaton, DMW means deterministic Muller automaton, and so on.


% The Rabin and Streett acceptance conditions are the negations of each other. This means that a run satisfies the Rabin acceptance condition, if and only if it does not satisfy the Streett acceptance condition. They both use a list of pairs of state sets. A run is accepted if there is a pair for which the first element contains an infinitely occuring state and the second element does not (Rabin condition), or if for all pairs the first elements do not contain an infinitely occuring state or all the second elements do contain an infinitely occuring state (Streett condition).
% \end{description}}

% All these automata types are equivalent to the \om-regular languages~\cite{2014_wilke}.

% \subsubsection{Muller}
% For the Muller acceptance condition, the set of infinitely occuring states of a run ($\textsf{inf}(\rho)$) must match one of several predefined set of states. The Muller acceptance condition is the most general one, and all the other acceptance conditions in Table~\ref{acc_conditions} can be expressed by the Muller condition~\cite{1999_loeding}.

% \subsubsection{Rabin}
% The Rabin and Streett acceptance conditions are the negations of each other. This means that a run satisfies the Rabin acceptance condition, if and only if it does not satisfy the Streett acceptance condition. They both use a list of pairs of state sets. A run is accepted if there is a pair for which the first element contains an infinitely occuring state and the second element does not (Rabin condition), or if for all pairs the first elements do not contain an infinitely occuring state or all the second elements do contain an infinitely occuring state (Streett condition).

% The parity condition assigns a number (color) to each state. A run is accpted if and only if the infinitely often occuring state with the smallest number has an even number.

% At this point we will start using a notation for the different types of \om-automata that has been used by Piterman~\cite{2006_piterman} and also later by Tsai et al.~\cite{2011_tsai}. It consists of a three-letter acronymes of the form $\{D, W\} \times \{B, M, R, S, P\} \times W$. The first letter, $D$ or $N$ specifies whether the automaton is deterministic or non-deterministc. The second letter is the initial letter of the automaton type, that is, $B$ for Büchi, $M$ for Muller, $R$ for Rabin, $S$ for Streett, and $P$ for parity automata. The third letter specifies on which the automaton runs, and is in our case always $W$ meaning ``words''. Thus, throughout this thesis we will use DBW for deterministic Büchi automata, NBW for non-deterministic Büchi automata, DMW for deterministic Muller automata, and so on.

% Regarding the expressivity of Muller, Rabin, Streett, and parity automata, it turned out that they are equivalent to the \om-regular languages~\cite{Thomas:1991}. However, unlike Büchi automata, for Muller, Rabin, Streett, and parity automata this equivalence holds for deterministic \textit{and} non-deterministic automata. That is, these automata \textit{can} be determinised. In summary, there is thus an equivalence between NBW, DMW, NMW, DRW, NRW, DSW, NSW, DPW, NPW, and the \om-regular languages. Only the DBW, as a special case, has a different expressivity, which is a strict subset of the expressivities of the other automata types. 



\section{Run Analysis of Non-Deterministic Automata}
\label{2_run_analysis}

In a deterministic automaton, every input word has exactly one run. In a non-deterministic automaton, however, an input word may have a large number of different runs.

It is this fact that generally makes the complementation of non-deterministic automata much harder than the complementation of deterministic automata. Because for the complementation of an automaton $A$ to its complement automaton $B$, there is the following principle:

\begin{quote}
\centering
\textit{All} the runs of $A$ on word $\alpha$ are non-accepting $\Longleftrightarrow$ $B$ accepts the word $\alpha$
\end{quote}

For deterministic automata, there is only a single run of $A$ on $\alpha$. Thus, for concluding that the complement $B$ must accept $\alpha$, it is enough to verify that the corresponding run of $A$ on $\alpha$ is non-accepting. However, if $A$ is a non-deterministic automaton, then there are potentially infinitely many (for \om-automata) runs of $A$ on $\alpha$. To conclude that the complement $B$ must accept $\alpha$ requires thus to verify that \textit{all} these runs of $A$ are non-accepting.

Complementation of non-deterministic automata thus requires 

There are two main structures that are used to investigate all the runs of a non-deterministic \om-automaton on a specific word, directed acyclic graphs (DAGs) and trees~\cite{2014_wilke}. 

\subsection{Run DAGs}
Run DAGs arrange all the runs of a non-deterministic automaton on a specific word in a directed acyclic graph. This graph is structured into levels, and on each level there is a vertex for every state of the automaton. The width of a run DAG is the number of states on a level, and is thus $n$ if the automaton has $n$ states. The number of levels is infinite for an \om-word.

Figure~\ref{example_automaton_1} shows an example non-deterministic Büchi automaton $A$ that we will use to demonstrate the different run analysis techniques in this and the following sections. Figure~\ref{run_dag} shows the first few levels of the run DAG of the automaton $A$ on the word \aom. 

\begin{figure}
\centering
\Automaton
\caption{Non-deterministic Büchi automaton $A$.}
\label{example_automaton_1}
\end{figure}

\begin{figure}
\centering
\RunDAG
\caption{First few levels of the run DAG for the runs of automaton $A$ (Figure~\ref{example_automaton_1} on the word \aom.}
\label{run_dag}
\end{figure}

Descriptions: \cite{fogarty2013unifying} (runs are \textit{paths})~\cite{2014_wilke}

\subsection{Run Trees}
Trees are the second structure that is used for analysing all the runs of a non-deterministic automaton on a specific word. Run trees are the simplest form of the different tree variants. A run tree is basically a direct unwinding of all the runs of an automaton on a word in tree form. Uach node in the tree represents a state of the automaton, and each non-deterministic transition in the automaton is representd in the tree as a child of a node.

Figure~\ref{run_tree} shows the first few levels of the run tree of the example automaton $A$ (see Figure~\ref{example_automaton_1}) on the word \aom. A note on notation: during this thesis we will adopt the convention to use rectangles with sharp corners for nodes of a tree. Furthermore, we will use double-lined rectangles for nodes that correspond to a accepting states of the automaton.

\begin{figure}
\centering
\RunTree
\caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
\label{run_tree}
\end{figure}

Naturally, the number of levels of a run tree is infinite for an \om-word. More importantly, however, the width of a level (number of nodes on a level) is not bounded and may become infinite as well. 



\subsection{Split Trees}
A split tree is an enhancement of a run tree where all the non-accepting and accepting children of a node are aggregated so that each node has at most two children, a non-accepting one and an accepting one. This makes a split tree a binary tree. Furthermore, a node of a split tree does not correspond to a single state of the automaton, but to a set of states. In Figure~\ref{split_tree}, we show the first few levels of the split tree of the example automaton $A$ (see Figure~\ref{example_automaton_1}) on the word \aom.

Descriptions: \cite{vardi2007automata}

\begin{figure}
\centering
\SplitTreeRightLeft
\caption{Automaton $A$ and the first five levels of the split tree of the runs of $A$ on the word $a^\omega$.}
\label{split_tree}
\end{figure}

Compared to run trees, split trees give up information on individual runs. By looking at the split tree in Figure~\ref{split_tree}, we can see that, for example, there must be a run from \q0 in the root to \q0 at level 4, but we cannot see which states this run visits on its way. What we can however see is that this run for sure does not visit any accepting states, but only non-accepting states. It turns out that with regard to Büchi complementation, this is the actually essential information that we need to know about runs. 

Split trees in fact embody a modified subset construction where accepting and non-accepting successor input-states are not mixed and added as two separate states to the output automaton. Applying this construction to an NBW results in an equivalent NBW whose degree of non-determinism is however reduced to two. Such a construction has been described in~\cite{UltesNitsche2007107}.

In our split tree in Figure~\ref{split_tree} we always put the accepting child to the right of the non-accepting child. This convention is necessary for a property of split trees that leads to \textit{reduced} split trees (see next section), namely the presence or ``greedy'' rightmost runs. Note that the reverse convention, putting the accepting child to the left of the non-accepting child, is also possible. We refer to the former case (accepting right, non-accepting left) as the \textit{right-to-left} version, and to the latter (accepting left, non-accepting right) as the \textit{left-to-right} version.


\subsection{Reduced Split Trees}
Reduced split trees are split trees where only one occurrence of a state on each level is kept and the others are removed. The state that is kept is either the rightmost one, if right-to-left split trees ar used, or the leftmost one, if left-to-right split trees are used. While both versions are used in the literature, in this this thesis, we will use the right-to-left version. Figure~\ref{reduced_split_tree} shows the first few levels of the (right-to-left) reduced split tree of the automaton $A$ (Figure~\ref{example_automaton_1}) on the word \aom.

\begin{figure}
\centering
\ReducedSplitTreeRightLeft
\caption{Automaton $A$ and the first five levels of the reduced split tree of the runs of $A$ on the word $a^\omega$.}
\label{reduced_split_tree}
\end{figure}

Comparing the reduced split tree with the corresponding split tree (Figure~\ref{split_tree}) reveals which states have been removed in the reduced split tree. The root and level 1 are similar in both trees. On level 2, the state \q2 is removed from the leftmost node, because \q2 already appears farther to the right on this level. On level 3, the state \q2 in the second node from the right is removed because there is already a \q2 to the right of it. As \q2 was the only state of this node, this causes the entire node to disappear. On the same level, \q2 of the leftmost node is also removed for the same reason. On level 4, following the same pattern, three occurrences of \q2 are removed. 

A possible procedure for constructing a new level of a reduced split tree is to start creating children at the rightmost node and then proceed from right to left. In the level under construction, a specific state is only added if it does \textit{not already} occur \textit{to the right} of it. This processing from right to left gives the name to right-to-left reduced split trees.

This omission of states (and thus entire runs) is ``tailored'' to the Büchi complementation problem. It in fact removes all but one of the runs that, after a certain number of steps, end up in the same state. We will call these runs \textit{re-joining} runs. For example, in the split tree in Figure~\ref{split_tree}, there are four runs that, after reading four symbols, ``re-join'' in \q2. In the reduced split tree (Figure~\ref{reduced_split_tree}), three of these re-joining runs are removed and only one is kept.

The run that is kept is always the one that is farthest at the right in the tree, and we call it the \textit{rightmost} run. An alternative name for the rightmost run is \textit{greedy} run. This comes from the fact that this run visits an accepting state earlier than the other re-joining runs. For example, in our previous example with the runs re-joining in \q2, the run that is kept in the reduced split tree visits an accepting state (\q1) already after the first symbol, whereas the other runs visit an accepting state only after the second or third symbol, respectively, or not at all.

Note that visiting an accepting state corresponds to a \textit{right-turn} in a right-to-left split tree. This is because the accepting states are always in the right child of the current node. Thus, the greedy run has actually the earliest right-turn, which in turn is the reason that it is farthest at the right, and thus the rightmost run of all the re-joining runs. In the following, we will use the terms greedy and rightmost interchangeably\footnote{Note that for left-to-right split trees, ``rightmost'' must be substituted by ``leftmost''.}

Summarising, a reduced split tree is thus a split tree where we keep only the rightmost one of a couple of rejoining runs. The base of this rule is the following observation:

\begin{quote}
Any re-joining run is accepting $\Longrightarrow$ The rightmost re-joining run is accepting
\end{quote}

That is, if any of the re-joining runs is accepting, then the rightmost run is accepting too, and on the other hand, if the rightmost run is not accepting, then none of the re-joining runs is accepting. A proof of this claim can be found in~\cite{vardi2007automata}\footnote{In this work, the authors use left-to-right split trees, in which case the greedy run is the leftmost rather than the rightmost run.}. 

Coming back to our problem of Büchi complementation, the main information we need from the run analysis of the input automaton is whether \textit{all} the runs on a specific word are non-accepting or not. By considering only greedy runs, we actually test a couple of runs for this property at once. If the greedy run is non-accepting, then we know  instantly that all its related re-joining runs are also non-accepting. If on the other hand the greedy run is accepting, then there is at least one accepting run anyway, and the complement automaton must reject the word. Thus, reduced split trees are a clever way to reduce the problem of analysing the large number of runs of a non-deterministic Büchi automaton on a specific word, by keeping only the information that is essential for the purpose of Büchi complementation.

The most important property of reduced split trees is that their width (the number of states on a level) is bounded by the number of states of the corresponding automaton, and thus finite. This does not hold for split trees. For example, the width of the split tree in Figure~\ref{split_tree} becomes infinite with an infinite number of levels. The width of the reduced split tree in Figure~\ref{reduced_split_tree}, however, never exceeds three, because three is the number of states of the input automaton.

The bounded width of reduced split trees is actually what makes them usable for Büchi complementation constructions, in particular the slice-based construction, including the Fribourg construction. Because in these constructions, levels of reduced split trees define states of the output automaton, and this is only possible if there is a finite number of distinct levels, so that there is a finite number of possible states in the output automaton.

Formal descriptions of reduced split trees can be found in~\cite{vardi2007automata} and~\cite{2014_wilke}. Note that these works use left-to-right split trees, which exchanges the roles of ``right'' and ``left'' with respect to our description.

%Related to Muller-Schupp trees~\cite{Muller199569} (cited in~\cite{fogarty2013unifying})


\section{Büchi Complementation Constructions}
\label{2_review}
Since the introduction of Büchi automata in 1962, many constructions for complementing non-deterministic Büchi automata have been proposed. 



\subsection{Ramsey-Based Approach}
The Ramsey-based approach has its name from a Ramsey-based combinatorial argument that is used in the complementation constructions. Ramsey was a British mathematician who lived at the beginning of the 20th century and founded a branch of combinatorics called the Ramsey theory~\cite{graham1990ramsey}.

Common to the  Ramsey-based complementation constructions is that they stay completely within in the framework of Büchi automata. That is, they do not include intermediate automata of different types, as for example the determinization-based constructions. Rather, Ramsey-based constructions construct the complement automata directly by combinatorial operations on the states and transitions.

\subsubsection{Büchi, 1962}

The first Büchi complementation construction at all was described by Büchi himself, along with the introduction of Büchi automata in 1962~\cite{buchi1960decision}. This complemenation construction is a Ramsey-based construction. It involves a combinatorial argument based on work by Ramsey~\cite{1930ramsey}. The construction is complicated, and has a doubly-exponential worst-case state complexity of $2^{2^{O\left(n\right)}}$~\cite{vardi2005buchi}. This means that if we assume, for example, the concrete complexity to be $2^{2^n}$, then an automaton with 6 states may result in a complement with at most $2^{2^6}$ states, which is more than 18 quintillions (18 billion billions).

The complexity of this worst-case is very high, and it would probably be impossible to complement such a worst-case automaton in practice. This is why all the subsequent complementation constructions, until today, have the goal to reduce this worst-case complexity. In this way, the worst-case state complexity became the main measure of performance for Büchi complementation constructions.

\subsubsection{Sistla, Vardi, and Wolper, 1985}

Another Ramsey-based construction has been introduced by Sistla, Vardi, and Wolper in 1987~\cite{PrasadSistla1987217} (first published in 1985~\cite{1985_sistla}). It is an improvement of Büchi's construction and the first one that involves only an exponential, instead of a doubly-exponential, worst-case state complexity. The complexity of this construction has been calculated to be $O\left(2^{4n^2}\right)$ (see~\cite{1988_safra_2}\cite{Pecuchet198695}).

The Ramsey-based approach is the oldest of the four approaches and it was particularly 


\subsection{Determinization-Based Approach}
\label{2_determinisation-based}
The determinization-based complementation constructions proceed by converting an NBW to a deterministic automaton, complementing the deterministic automaton, and finally converting the complement automaton back to an NBW. The deterministic automaton cannot be a DBW (because NBW and DBW are not equivalent), however it can be a DMW, DRW, DSW, or DPW.

The idea behind this approach is that the complementation of deterministic \om-automata is easier than the complementation of non-deterministic \om-automata. The complementation problem is then in fact reduced to conversions between different types of automata. From these conversions, the conversion from the initial NBW to a deterministic \om-automaton is the most difficult and crucial one.

\subsubsection{Safra, 1988}

The first determinisation-based complementation construction has been described by Safra in 1988~\cite{1988_safra_2}. Safra's main work was actually a determinisation construction for converting an NBW to a DRW. This is what today is known as \textit{Safra's construction}. Safra then describes complementation as a possible application of his determinisation construction. He also presents the additional conversions that are needed for the entire complementation construction. The conversion steps of Safra's complementation procedure are as follows.


% Simulate enumerate with a table
\newlength{\myitemindent}
\setlength{\myitemindent}{\itemindent+1pt}
\hspace{\myitemindent}
{\renewcommand{\tabcolsep}{4pt}
\begin{tabular}{lllll}
1. & NBW       & $\longrightarrow$ & DRW      & (Safra's construction) \\
2. & DRW       & $\longrightarrow$ & \ob{DSW} & (Complementation)      \\
3. & \ob{DSW}  & $\longrightarrow$ & \ob{DRW} &                        \\
4. & \ob{DRW}  & $\longrightarrow$ & \ob{NBW} &                        \\
\end{tabular}}

The complementation step from a DRW to a DSW that accepts the complement language can be trivially done by interpreting the Rabin acceptance condition as a Streett acceptance condition. This is possible, because these two acceptance conditions are the negations of each other (see Section~\ref{om-automata}. The conversions from DSW to DRW, and from DRW to NBW are not of major difficulty or complexity, and are described by Safra in~\cite{1988_safra_2} (Lemma~3 and Lemma~5).

The core is the conversion from NBW to DRW (Safra's construction). This construction is basically a modified subset construction. That is, the output automaton is built up from an initial state step-by-step by adding new states and transitions. The main difference to the subset construction is that in Safra's construction, the output-states consist of trees of subsets of input-states, rather than just of subsets of input-states. These trees of subsets of states are called \textit{Safra trees}. The details of the construction are rather intricate, but well described in~\cite{1988_safra_2}. The deterministic automaton that results from Safra's construction can then be interpreted as a Rabin automaton.

Description of Safra trees/construction: \cite{2006_althoff}~\cite{2002_roggenbach}

The state growth of Safra's construction is $2^{O\left(n\, \text{log}\, n\right)}$, where $n$ is the number of states of the input automaton. The additional conversions (DSW to DRW, and DRW to NBW) have a lower state complexity than this, so that the overall complexity of the entire complementation procedure is still $2^{O(n\, \text{log}\, n}$.

\subsubsection{Muller and Schupp, 1995}

Most other determinisation-based complementation constructions are based on improvements of Safra's construction. One of them is the construction for converting NBW to DRW proposed in 1995 by Muller an Schupp. This construction is said to be simpler and more intuitive than Safra's construction~\cite{2002_roggenbach}, however, often produces larger output automata in practice~\cite{2006_althoff}. The theoretically caluclated state complexity of the Muller-Schupp construction is $2^{O\left(n\, \text{log}\, n\right)}$, that is, similar to Safra's construction. A comparison of the Muller-Schupp construction and Safra's construction can be found in~\cite{2006_althoff}.

Descriptionof Muller-Schupp trees: \cite{2006_althoff}

\subsubsection{Piterman, 2007}

Another improvement of Safra's construction has been proposed in 2007 by Piterman from EPF Lausanne~\cite{2007_piterman} (first presented at a conference in 2006~\cite{2006_piterman}). This construction converts a NBW to a DPW, rather than a DRW. Piterman's construction uses a more compact version of Safra trees, which allows it to produce smaller output automata. The concrete worst-case state growth of Piterman's construction is $2n^nn!$, opposed to $12^nn^{2n}$ of Safra's construction~\cite{2007_piterman}. Complementation with Piterman's construction is done in the following steps.

% Simulate enumerate with a table
\setlength{\myitemindent}{\itemindent+1pt}
\hspace{\myitemindent}
{\renewcommand{\tabcolsep}{4pt}
\begin{tabular}{lllll}
1. & NBW       & $\longrightarrow$ & DPW      & (Piterman's construction) \\
2. & DPW       & $\longrightarrow$ & \ob{DPW} & (Complementation)      \\
3. & \ob{DPW}  & $\longrightarrow$ & \ob{NBW} &                        \\
\end{tabular}}

The complementation step from a DPW to a DPW accepting the complement language can be trivially done by, for example, increasing the number of each state by 1. The conversion from a DPW to an NBW can alse be done without major complexity~\cite{2011_tsai}.

\subsection{Rank-Based Approach}
The rank-based approach was the third of the four proposed main complementation approaches. It does neither include Ramsey theroy, nor determinisation. Rather, it is based on run analysis with run DAGs. The link of run analysis with run DAGs to complementation is as follows. A run DAG allows to summarise all the possible runs of an automaton on a specific word. If all these runs are rejecting, then we say that the entire run DAG is rejecting. In this case, the automaton does not accept the word, and consequently, the complement automaton must accept this word. Conversely, if one or more runs in the run DAG are not rejecting, then the entire run DAG is not rejecting. In this case, the automaton accepts the word, and consequently, the complement automaton must no accept this word.

The information of whether a run DAG is rejecting or not is expressed with so-called ranks. These are numbers that are assigned to the vertices of a run DAG, one rank per vertex. These ranks are assigned in a way that each run of a run DAG eventually gets trapped in a rank. From this information it is then possible to deduce whether the run DAG is rejecting or not. This in turn determines whether the complement automaton must accept the given word, or not.

This entire analysis of run DAGs with ranks is included in a subset construction. This means that the individual run DAGs are not constructed explicitly for each word, but rather implicitly ``on-the-fly'' within the complement automaton under construction. From a practical point of view, this means that rank-based constructions proceed in a subset construction based fashion. That is, the construction of the complement automaton is started with an initial state, and then step-by-step, successor states are added. Each output state consists of subsets of input-states.

\subsubsection{Klarlund, 1991}
The first rank-based construction has been proposed in 1991 by Klarlund~\cite{1991_klarlund}. However, Klarlund used the term \textit{progress measure} instead of \textit{rank}. This is because he looked at the ranks as a measure for the ``progress'' of a run towards the satisfaction of a certain property. The term \textit{rank} has, to the best of our knowledge, been introduced by Thomas in 1999~\cite{1999_thomas}. Klarlund also did not mention run DAGs, but they are implicit in his description of the construction. The construction works as described above by performing a modified subset construction. 

\subsubsection{Kupferman and Vardi, 1997/2001}
This construction by Kupferman and Vardi has been published as a preliminary conference version in 1997~\cite{1997_vardi}, and as a journal version in 2001~\cite{Kupferman:2001}. Both publications are entitled ``Weak Alternating Automata Are Not That Weak''. The idea of the construction described by Kupferman and Vardi is the same as Klarlund's construction from 1991~\cite{1991_klarlund}. However, Kupferman and Vardi provide two different descriptions for this idea.

The first description does not use run DAGs and ranks, but rather converst the input automaton to a weak alternating automaton, which is complemented, and then converted back to a non-deterministic Büchi automata. Weak alternating automata (WAA) have been introduced in 1986 by Muller, Saoudi, and Schupp~\cite{1986_muller}. Kupferman and Vardi state that this construction is conceptually simpler and easier implementable than Klarlund's construction~\cite{1991_klarlund}. This first version of Kupferman and Vardi's construction is described in both, the publications from 1997~\cite{1997_vardi} and 2001~\cite{Kupferman:2001}.

Description of alternating automata: \cite{1996_vardi} (Section 2.5)


The second description in turn is rank-based, as described above, and works in the subset construction fashion without intermediate automata. Kupferman and Vardi point out that this version of the construction is identical to Klarlund's construction. What changes is just the terminology, for example ``ranks'' instead of ``progress measure''. This second version of Kupferman and Vardi's construction is to the best of our knowledge only described in the publication from 2001~\cite{Kupferman:2001}, however, we are not sure, because we could not access the publication from 1997\cite{1997_vardi}.

There is an \textit{odd ranking} if and only if all the runs of the run DAG are rejecting. Odd ranking: all the paths get trapped in an odd rank. Only non-accepting states have odd ranks.

Description in \cite{fogarty2013unifying}~\cite{2007_vardi}

The automata produced by the two versions of Kupferman and Vardi's construction are identical. The worst-case state complexity has been calculated to be approximately $(6n)^n$~\cite{schewe2009buchi}\cite{2007_vardi}.

\subsubsection{Thomas, 1999}
This construction by Thomas~\cite{1999_thomas} is based on the WAA construction by Kupferman and Vardi from 1997~\cite{1997_vardi}. It uses the concept of ranks, but does not proceed in the subset construction manner, as Klarlund's construction~\cite{1991_klarlund} and Kupferman and Vardi's second version~\cite{Kupferman:2001}. Rather, it transforms the input NBW to an intermediate automaton, complements it, and converts the result back to an NBW. That is, it proceeds in a similar fashion as Kupferman and Vardi's first version~\cite{1997_vardi}. The type of the intermediate automaton is a weak alternating parity automaton (WAPA), that is, a weak alternating automaton with the parity acceptance condition.

\subsubsection{Friedgut, Kupferman, and Vardi, 2006}
In 2006, Friedgut, Kupferman, and Vardi published a paper entitled ``Büchi Complementation Made Tighter''~\cite{friedgut2006buchi} (a preliminary version of the paper has appeared in 2004~\cite{2004_friedgut}). There, they describe an improvement to the second (rank-based) version of Kupferman and Vardi's construction from 2001~\cite{Kupferman:2001}. The improvement consists in the so-called \textit{tight ranking}, a more sophisticated ranking function. It allows to massively reduce the worst-case state complexity of the construction to $(0.96n)^n$.

Tight rankings: description in \cite{fogarty2013unifying}~\cite{2007_vardi}

\subsubsection{Schewe, 2009}
In 2009, Schewe presented another improvement to the construction by Friedgut, Kupferman, and Vardi from 2006~\cite{schewe2009buchi}. His paper is entitled ``Büchi Complementation Made Tight'', which hints at the relation to the paper by Friedgut, Kupferman, and Vardi~\cite{friedgut2006buchi}. Schewe's improvement consists in a further refinement of the construction, in particular the use of turn-wise tests in the cut-point construction step. This improvement allows to further reduce the worst-case state complexity of the construction to $\left(0.76\left(n+1\right)\right)^{n+1}$. This coincides, modulo a polynomial factor, with the lower bound for the state complexity of Büchi complementation of $(0.76n)^n$ that has been previously established by Yan in 2006~\cite{2006_yan}\cite{DBLP:journals/corr/abs-0802-1226}.

This result narrows down the possible range for the real worst-case state complexity of Büchi complementation considerably. It cannot be lower than the lower bound of $(0.76n)^n$ by Yan, and it cannot be higher than the complexity of Schwewe's construction of $\left(0.76\left(n+1\right)\right)^{n+1}$. For this reason, we say that the proven worst-case complexity of a specific construction serves as an upper bound for the actual complexity of the problem.


\subsection{Slice-Based Approach}
\label{2_slice-based}
The slice-based approach was the last approach that has been proposed. Its idea is very similar to the rank-based approach, but the main difference is the use of reduced split trees instead of run DAGs. The basic idea is to look at a state of the output automaton under construction as a horizontal level of a reduced split tree. Based on this, for each alphabet symbol, the succeeding level of the reduced split tree is determined, which results in a new state in the output automaton. These levels of reduced split trees are called \textit{slices}, hence the name slice-based approach.

Like rank-based constructions, slice-based construction are essentially enhanced subset constructions. The slice-based constructions, however, include two runs of a subset construction, where the second one is typically more sophisticated than the first one.


\subsubsection{Vardi and Wilke, 2007}
The first slice-based Büchi complementation construction has been proposed in 2007 by Vardi and Wilke~\cite{vardi2007automata}. In this work, the authors review translations from various logics, including monadic second order logic of one successor (S1S), to \om-automata. They devise the slice-based complementation construction as a by-product of a determinisation construction for Büchi automata that they also introduce in this work.

Vardi and Wilke use left-to-right reduced split trees for their construction. That means, accepting states are put to the left of non-accepting states, and only the left most occurrence of each state is kept. The construction works by two passes of the enhanced subset construction. The first one (initial phase) is as described above. The second one (repetition phase), does additionally include decorations of the vertices of the reduced split trees (subsets) consisting of the three labels \textit{inf}, \textit{die}, and \textit{new}. These decoration serves to keep track of the criterion that a word is rejected if and only if all of the branches of the corresponding reduced split tree contain only a finite number of left-turns. The worst-case state complexity of Vardi and Wilke's construction is $(3n)^n$~\cite{vardi2007automata}.

The slice-based construction by Vardi and Wilke is very similar to the Fribourg construction that we describe in Chapter~\ref{chap_construction}. An obvious difference is that the Fribourg construction uses right-to-left, rather than left-to-right, reduced split trees. However, this is an arbitrary choice, and has no influence on the result of the constructions. Another difference is that the transition from the initial phase to the repetition phase is handled quite differently by Vardi and Wilke, than for the corresponding automata parts in the Fribourg construction.

\subsubsection{Kähler and Wilke, 2008}
The slice-based construction by Kähler and Wilke from 2008~\cite{2008_kaehler} is a generalisation of the construction by Vardi and Wilke from 2007~\cite{vardi2007automata}. Kähler and Wilke proposed a construction idea that can be used for both, complementation and disambiguation. Consequently, this construction is less efficient than Vardi and Wilke's construction. It has a worst-case state complexity of $4(3n)^n$~\cite{2011_tsai}.

A comparison of the rank-based and slice-based complementation approaches has been done by Fogarty, Kupferman, Wilke, and Vardi~\cite{fogarty2013unifying}. In this work, the authors also describe a translation of the slice-based construction by Kähler and Wilke~\cite{2008_kaehler} to a rank-based construction.







% \section{Run Analysis}
% A deterministic automaton has exactly one run on every word. A non-deterministic automaton, on the other hand, may have multiple runs on a given word. The analysis of all runs of a word, in some form or another, an integral part of Büchi complemenation constructions. Remember that a non-deterministic automaton accepts a word if there is \emph{at least one} accepting run. Consequently, a word is rejected if only if \emph{all} the runs are rejecting. That is, if $B$ is the complement Büchi automaton of $A$, then $B$ has to accept a word $w$ if and only if \emph{all} the runs of $A$ on $w$ are rejecting. For constructing the complement $B$, we have thus to consider all the possible runs of $A$ on every word.

% There are two main data structures that are used for analysing the runs of a non-deterministic automaton on a word. These are trees and DAGs (directed acyclic graphs)~\cite{2014_wilke}. In this section, we present both of them. We put however emphasis on trees, as they are used by the subset-tuple construction presented in Chapter~\ref{fribourg_construction}.

% \subsection{From Run Trees to Split Trees}

% \begin{figure}
% \centering
% \Automaton
% \caption{Example NBW $A$ that will be used in different places throughout this thesis. The alphabet of $A$ consists of the single symbol $a$, consequently, $A$ can only process the single \om-word $a^\omega$. This word is rejected by $A$, so the automaton is empty.}
% \label{automaton}
% \end{figure}

% The one tree data-structure that truly represents \emph{all} the runs of an automaton on a word are run trees. The other variants of trees that we present in this section are basically derivations of run trees that sacrifice information about individual runs, by merging or discarding some of them, at the benefit of becoming more concise. Figure~\ref{run_tree} shows the first few levels of the run tree of the example automaton $A$ from Figure~\ref{automaton} on the word \aom.

% \begin{figure}
% \centering
% \RunTree
% \caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
% \label{run_tree}
% \end{figure}

% In a run tree, every vertex represents a single state and has a descendant for every $a$-successor of this state, if $a$ is the current symbol of the word. A run is thus represented as a branch of the run tree. In particular, there is a one-to-one mapping between branches of a run tree and runs of the automaton on the given word.

% We mentioned that the other tree variants that we talk about in this section,  split trees and reduced split trees, make run trees more compact by not keeping information about individual runs anymore. They thereby relinquish the one-to-one mapping between branches of the tree and runs. Let us look at one extreme of this aggregation of runs which is done by the subset construction. This will motivate the definition of split trees, and at the same time shows why the subset construction fails for determinising NBW~\footnote{The NBW that \emph{can} be turned into DBW.}.

% For determinising an automaton $A$, the subset construction in effect merges all the diverse runs of $A$ on word $w$ to one single run by merging all the states on a level of the corresponding run tree to one single state. This state will be a state of the output automaton $B$, and is labelled with the set of $A$-states it includes. Figure~\ref{subset_construction_tree} shows this effect with our example automaton from Figure~\ref{automaton} and the word \aom. 

% \begin{figure}
% \centering
% \SubsetConstructionTree
% \caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
% \label{subset_construction_tree}
% \end{figure}

% Clearly, this form of tree created by the subset construction is the most concise form a run tree can be brought to. However, almost all information about individual runs in $A$ has been lost. All that can be said by looking at the structure in Figure~\ref{subset_construction_tree} is that there must be at least one continued $A$-run on \aom (all the other runs visiting the other $A$-states on each level, might be discontinued). But which states a possible continued run visits cannot be deduced.

% This lack of identification $A$-runs is the reason why the subset construction fails for determinising Büchi automata. Note that a $B$-state of the subset construction is accepting if the set of $A$-states it represents contains at least one accepting $A$-state. For our example, this means that the state \qqqq012 is accepting (this is also indicated in Figure~\ref{subset_construction_tree}). This state is visited infinitely often by the unified run on \aom. Hence, the DBW $B$, resulting from applying the subset construction to the NBW $A$, accepts \aom while $A$ does not accept it.

% By looking closer at the trees in Figure~\ref{subset_construction_tree} and~\ref{run_tree}, the reason for this problem becomes apparent. If we look for example at the second level of the subset-construction tree we can deduce that there must be an $A$-run that visits the accepting $A$-state \q1. Let us call this run $r_{q_1}$. However, at the third level, we cannot say anything about $r_{q_1}$ anymore, whether it visits one of the non-accepting states or again \q1 on the third level, or whether it even ended at the second level. In turn, what we know on the third level in our example is that there is again an $A$-run, $r_{q_1}^\prime$, that visits \q1. However, whether $r_{q_1}^\prime$ is $r_{q_1}$, and in turn the future of $r_{q_1}^\prime$ cannot be deduced. In our example we end up with the situation that there are infintiely many visits to \q1 in the unifed $B$-run, but we don't know if the reaon for this are one or more $A$-runs that visit \q1 infinitely often, or infinitely man $A$-runs where each one visits \q1 only finitely often (the way it is in our example). In the first case, it would be correct ot accept the $B$-run, in the second case however it would be wrong as the input automaton $A$ does not accept the word. The subset construction does not distinguish these two cases and hence the determinised automaton $B$ may accept words that the input automaton $A$ rejects. In general, the language of an output DBW of the subset construction is a superset of the language of the input NBW.

% This raises the question how the subset construction can be minimally modified such that the output automaton is equivalent to the input automaton. One solution is to not mix accepting and non-accepting $A$-states in the $B$-states. That is, instead of creating one $B$-state that contains all the $A$-states, as in the subset construction, one creates two $B$-states where one contains the accepting $A$-states and the other the non-accepting $A$-states. Such a construction has been formalised in~\cite{UltesNitsche2007107}. The output automaton $B$ is then not deterministic, but it is equivalent to $A$. The type of run analysis trees that correspond to this refined subset construction are split trees. Figure~\ref{split_tree} shows the first five levels of the split tree of our example automaton $A$ on the word \aom. 

% \begin{figure}
% \centering
% \SplitTreeRightLeft
% \caption{Automaton $A$ and the first five levels of the split tree of the runs of $A$ on the word $a^\omega$.}
% \label{split_tree}
% \end{figure}

% Let us see why the splitted subset construction produces output automata that are equivalent to the input automata. For this equivalence to hold, a branch of a reduced split tree must include infinitely many accepting vertices if and only if there is an $A$-run that visits at least one accepting $A$-state infinitely often. For an infinite branch of a split tree, there must be at least one continued $A$-run. If this infinite branch includes infinitely many accepting vertices, then this $A$-run must infinitely many times go trough an accepting $A$-state. This is certain, because an accepting vertex in a split tree contains \emph{only} accepting $A$-states. Since there are only finitely many accepting $A$-states, the $A$-run must visit at least one of them infinitely often. On the other hand, if an $A$-run includes infinite visits to an accepting state, then this results in a branch of the split tree with infinitely many accepting vertices, since every $A$-run must be ``contained'' in a branch of the split tree.

% Split trees can be seen as run trees where some of the branches are contracted to unified branches. In particular, a split tree unifies as many branches as possible, such that the resulting tree still correctly represents the Büchi acceptance of all the runs included in a unified branch. This can form the basis for constructions that transform an NBW to another equivalent NBW. Split trees are for example the basis for Muller-Schupp trees in Muller and Schupp's Büchi determinisation construction~\cite{Muller199569}, cf.~\cite{2006_althoff}.

% \subsection{Reduced Split Trees}

% It turns out that split trees can be compacted even more. The resulting kind of tree is called reduced split tree. In a reduced split tree, each $A$-state occurs at most once on every level. Figure~\ref{reduced_split_tree} shows the reduced split tree corresponding to the split tree in Figure~\ref{split_tree}. As can be seen, only one occurrence of each $A$-state on each level is kept, the other are discarded. To allow this, however, the order of the accepting and non-accepting siblings in the tree matters. Either the accepting child is always put to the right of the non-accepting child (as in our example in Figure~\ref{reduced_split_tree}, or vice versa. We call the former variant a right-to-left reduced split tree, and the latter a left-to-right reduced split tree. In this thesis, we will mainly adopt the right-to-left version.

% \begin{figure}
% \centering
% \ReducedSplitTreeRightLeft
% \caption{Automaton $A$ and the first five levels of the reduced split tree of the runs of $A$ on the word $a^\omega$.}
% \label{reduced_split_tree}
% \end{figure}

% A reduced split tree is constructed like a split tree, with the following restrictions.
% \begin{itemize}
% \item For determining the vertices on level $n+1$, the parent vertices on level $n$ have to be processed from right to left
% \item From every child vertex on level $n+1$, subtract the $A$-states that occur in some vertex to the right of it on level $n+1$
% \item Put the accepting child to the right of the non-accepting child on level $n+1$
% \end{itemize}

% % Fixed witdth
% A very important property of reduced split trees is that they have a fixed width. The width of a tree is the maximal number of vertices on a level. For reduced split trees, this is the number of states of the input automaton $A$. As we will see, the subset-tuple construction (like other slice-based constructions) uses levels of a reduced split tree as states othe output automaton, and the limited size of these levels ensures an upper bound on the number of states these constructions can create.

% % We delete runs, we keep the "greedy" runs
% By deleting $A$-states from a level of a reduced split tree, we actually delete $A$-runs that reach the same $A$-state on the same substring of the input word. For example, in the split tree in Figure~\ref{split_tree} we see that there are at least for $A$-runs on the string $aaaa$ from the inital state \q0 to \q2. The reduced split tre in Figure~\ref{reduced_split_tree}, however, contains only one run on $aaaa$ from \q0 to \q2, namely the rightmost branch of the tree. The information about all the other runs is lost. This single run that is kept is very special and, as we will see shorty, it represents the deleted runs. We will call this run the \emph{greedy run}. The reason for calling it greedy is that it visits an accepting state earlier than any of the deleted runs. In a right-to-left reduced split tree, the greedy run is always the rightmost of the runs from the root to a certain $A$-state on a certain level. In left-to-right reduced split tree, the greedy run would in turn be the leftmost of these runs.

% % Proof that if any of the deleted runs would be accepting, then the greedy run is accepting
% We mentioned that the greedy run somehow represents the deleted runs. More precisely, the relation is as follows and has been proved in~\cite{vardi2007automata}: if any of the deleted runs is a prefix of a run that is Büchi-accepted (that is, an infinite run visiting infinitely many accepting $A$-states), then the greedy run is so too. That means that if the greedy cannot be expanded to a Büchi-accepting run, then none of the deleted runs could be either. Conversely, if any of the deleted runs could become Büchi-accepting, then the greedy run can so too. So, the greedy run is sufficient to indicate the existence or non-existence of a Büchi-accepting run with this prefix, and it is safe to delete all the other runs.

% \subsection{Run DAGs}
% DAGs (directed acyclic graphs) are, after trees, the second form for analysing the runs of a non-deterministic automaton on a given word. A run DAG has the form of a matrix with one column for each $A$-state and a row for each position in the word. The directed edges go from the vertices on one row to the vertices on the next row (drawn below) according to the transitions in the automaton on the current input symbol. Figure~\ref{run_dag} shows the first five rows of the run DAG of the example automaton in Figure~\ref{automaton} on the word \aom. 

% \begin{figure}
% \centering
% \RunDAG
% \caption{Automaton $A$ and the first five levels of the run DAG of the runs of $A$ on the word $a^\omega$.}
% \label{run_dag}
% \end{figure}

% Like run trees, run DAGs represent all the runs of an automaton on a given word. However, run DAGs are more compact than run trees. The rank-based complementation constructions are based on run DAGs. 



% \section{Run Analysis}
% In a deterministic automaton every word has exactly one run. In a non-deterministic automaton, howevever, a given word may have multiple runs. The analysis of the different runs of a given word on an automaton plays an important role in the complementation of Büchi automata. There are several techniques for analysing the runs of a word that we present in this section.

% \subsection{Run Trees}
% The simplest of run analyis technique is the run tree. A run tree is a direct unfolding of all the possible runs of an automaton $A$ on a word $w$. Each vertex $v$ in the tree represents a state of $A$ that we denote by $\sigma(v)$. The descendants of a vetex $v$ on level $i$ are vertices representing the successor states of $\sigma(n)$ on the symbol $w(i+1)$ in $A$. In this way, every branch of the run tree originating in the root represents a possible run of automaton $A$ on word $w$.

% Figure~\ref{run_tree} shows an example automaton $A$ and the first five levels of the run tree for the word $w = a^\omega$ (infinite repetitions of the symbol $a$). Each branch from the root to one of the leaves represents a possible way for reading the first four positions of $w$. On the right, as a label for all the edges on the corresponding level, is the symbol that causes the depicted transitions.

% \begin{figure}
% \begin{center}
% \RunTree
% \end{center}
% \caption{Automaton $A$ and the first five levels of the run tree of the runs of $A$ on the word $a^\omega$.}
% \label{run_tree}
% \end{figure}

% ($A$ does not accept any word, it is empty. The only word it could accept is $a^\omega$ which it does not accept.)

% We define by the width of a tree the maximum number of vertices occurring at any level~\cite{Muller199569}. Clearly, for \om-words the width of a run tree may become infinite, because there may be an infinite number of levels and each level may have more vertices than the previous one. 

% \subsection{Failure of the Subset-Construction for Büchi Automata}
% Run trees allow to conveniently reveal the cause why the subset construction does not work for determinising Büchi automata, which in turn motivates the basic idea of the next run analysis technique, split trees.

% Applying the subset construction to the same NBW $A$ used in the previous example, we get the automaton $A^\prime$ shown in Figure~\ref{subset_construction_1}. Automaton $A^\prime$ is indeed a DBW but it accepts the word $a^\omega$ which $A$ does not accept. If we look at the run tree of $A$ on word $a^\omega$, the subset construction merges the individual states occuring at level $i$ of the tree to one single state $s_i$, which is accepting if at least one of its components is accepting. Equally, the individual transitions leading to and leaving from the individual components of $s_i$ are merged to a unified transition. The effect of this is that we lose all the information about these indiviudal transitions. This fact is depicted in Figure~\ref{subset_construction_2}. For the NFA acceptance condition this does not matter, but for NBW it is crucial because the acceptance condition depends on the history of specific runs. In the example in Figure~\ref{subset_construction_1}, a run $\rho$ of $A$ visiting the accepting state $q_1$ can never visit an accepting state anymore even though the unified run of which $\rho$ is part visits $q_1$ infinitely often. But the latter is achieved by infinitely many different runs each visiting $q_1$ just once.

% It turns out that enough information about individual runs to ensure the Büchi acceptance condition could be kept, if accepting and non-accepting state are not mixed in the subset construction. Such a constructio has bee proposed in~\cite{UltesNitsche2007107}. Generally, the idea of treating accepting and non-accepting states separately is important in the run analyis of Büchi automata.





% \subsection{Split Trees}
% Split trees can be seen as run trees where the accepting and non-accepting descendants of a node $n$ are aggregated in two nodes. We will call the former the \emph{accepting child} and the latter the \emph{non-accepting child} of $n$. Thus in a split tree, every node has at most two descendants (if either the accepting or the non-accepting child is empty, it is not added to the tree), and the nodes represent sets of states rather than individual states. Figure~\ref{split_tree} shows the first five levels of the split tree of automaton $A$ on the word $a^\omega$.

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \SplitTreeRightLeft
% \end{center}
% \caption{Automaton $A$ and the first five levels of the split tree of the runs of $A$ on the word $a^\omega$.}
% \label{split_tree}
% \end{figure}


% The order in which the accepting and non-accepting child are 

% The notion of split trees (and reduced split trees, see next section) has been introduced by Kähler and Wilke in 2008 for their slice-based complementation construction~\cite{2008_kaehler}, cf.~\cite{fogarty2013unifying}. However, the idea of separating accepting from non-accepting states has already been used earlier, for example in Muller and Schupp's determinisation-based complementation construction from 1995~\cite{Muller199569}. Formal definitions os split trees can be found in~\cite{2008_kaehler}\cite{fogarty2013unifying}.

% \subsection{Reduced Split Trees}
% The width of a split tree can still become infinitely large. A reduced split tree limits this width to a finite number with the restriction that on any level a given state may occur at most once. This is in effect the same as saying that if in a split tree there are multiple ways of going from the root to state $q$, then we keep only one of them.

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \ReducedSplitTreeLeftRight
% \end{center}
% \caption{Automaton $A$ and the first five levels of the left-to-right reduced split tree of the runs of $A$ on the word $a^\omega$.}
% \label{r_split_tree_lr}
% \end{figure}

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \ReducedSplitTreeRightLeft
% \end{center}
% \caption{Automaton $A$ and the first five levels of the left-to-right reduced split tree of the runs of $A$ on the word $a^\omega$.}
% \label{r_split_tree_rl}
% \end{figure}


% \subsection{Run DAGs}
% A run DAG (DAG stands for directed acyclic graph) can be seen as a graph in matrix form with one column for every state of $A$ and one row for every position of word $w$. The edges are defined similarly than in run trees. Figure~\ref{run_dag} shows the run DAG of automaton $A$ on the word $w = a^\omega$.

% \begin{figure}
% \begin{center}
% \Automaton
% \hfil
% \RunDAG
% \end{center}
% \caption{Automaton $A$ and the first five levels of the run DAG of the runs of $A$ on the word $a^\omega$.}
% \label{run_dag}
% \end{figure} 






% \section{Empirical Performance Investigations}

% \section{Preliminaries}


% \subsection{Büchi Automata}
% Büchi automata have been introduced in 1962 by Büchi~\cite{buchi1960decision} in order to show the decidability of monadic second order logic; over the successor structure of the natural numbers~\cite{2012_breuers}.

% he had proved the decidability of the monadic-second order theory of the natural numbers with successor func- tion by translating formulas into finite automata~\cite{vardi2007automata} (p. 1)

% %To check whether a given S1S formulaφ=φ(V0,...,Vm−1)is satisfiable one simply constructs the Büchi automaton which is guaranteed to exist by Büchi’s Theorem and checks this automaton for non-emptiness~\cite{vardi2007automata} (p. 9).

% Büchi needed to create a complementation construction (proof the closure under complementation of Büchi automata) in order to prove Büchi's Theorem.

% Büchi's Theorem: S1S formulas and Büchi automata are expressively equivalent (there is a NBW for every S1S formula, and there is a S1S formula for every NBW).

% \subsubsection{Definitions}
% Informally speaking, a Büchi automaton is a finite state automaton running on input words of infinite length. That is, once started reading a word, a Büchi automaton never stops. A word is accepted if it results in a run (sequence of states) of the Büchi automaton that includes infinitely many occurrences of at least one accepting state.
% % A word is accepted by a Büchi automaton, if there exists a run (sequence of states) for it that includes infinite repetitions of at least one accepting state. In other words, if during reading a word a Büchi automaton goes through one or more accepting states infinitely often, the word is accepted, and otherwise it is rejected.

% More formally, a Büchi automaton $A$ is defined by the 5-tuple $A = (Q, \Sigma, q_0, \delta, F)$ with the following components.
% \begin{itemize}
% \item $Q$: a finite set of states
% \item $\Sigma$: a finite alphabet
% \item $q_0$: an initial state, $q_0 \in Q$
% \item $\delta$: a transition function, $\delta: Q \times \Sigma \rightarrow 2^Q$ %(mapping combinations of a state and a symbol to zero, one, or more other states)
% \item $F$: a set of accepting states, $F \in 2^Q$
% \end{itemize}

% We denote by $\Sigma^\omega$ the set of all words of infinite length over the alphabet $\Sigma$. A Büchi automaton runs on the elements of $\Sigma^\omega$. In the following, we define the acceptance behaviour of a Büchi automaton $A$ on a word $\alpha \in \Sigma^\omega$.

% % A Büchi automaton runs on infinite words over the alphabet $\Sigma$. We denote by $\Sigma^\omega$ the set of all possible words of infinite length (\om-words) over $\Sigma$. 

% % What distinguishes a Büchi automaton from a finite state automaton on finite words are its conditions for accepting or rejecting words. In the following, we define the acceptance behaviour of a Büchi automaton.

% \begin{itemize}
% % \item $\Sigma^\omega$ is the set of all possible words of infinite length over alphabet $\Sigma$
% \item A \emph{run} of Büchi automaton $A$ on a word $\alpha \in \Sigma^\omega$ is a sequence of states $q_0q_1q_2\dots$ such that $q_0$ is $A$'s initial state and $\forall i \geq 0: q_{i+1} \in \delta(q_i, \alpha_i)$
% \item $\textsf{inf}(\rho) \in 2^Q$ is the set of states that occur infinitely often in a run $\rho$
% \item A run $\rho$ is accepting if an only if $\textsf{inf}(\rho) \cap F \neq \varnothing$
% \item A Büchi automaton $A$ accepts a word $\alpha \in \Sigma^\omega$ if and only if there is an accepting run of $A$ on $\alpha$
% \end{itemize}

% The set of all the words that are accepted by a Büchi automaton $A$ is called the \emph{language} $L(A)$ of $A$. Thus, $L(A) \subseteq \Sigma^\omega$. On the other hand, the set of all words of $\Sigma^\omega$ that are rejected by $A$ is called the \emph{complement language} $\overline{L(A)}$ of $A$. The complement language can be defined as $\overline{L(A)} = \Sigma^\omega \setminus L(A)$.

% Büchi automata are closed under union, intersection, concatenation, and complementation~\cite{1996_vardi}.

% Continued/discontinued runs

% A deterministic Büchi automaton (DBW) is a special case of a non-determnistic Büchi automaton (NBW). A Büchi automaton is a DBW if $|\delta(q,\alpha)| = 1, \, \forall q \in Q, \forall \alpha \in \Sigma $. That is, every state has for every alphabet symbol exactly one successor state. A DBW can also be defined directly by replacing the transition function $\delta: Q \times \Sigma \rightarrow 2^Q$ with $\delta: Q \times \Sigma \rightarrow Q$ in the above definition.

% \subsubsection{Expressiveness}
% It has been showed by Büchi that NBW are expressively equivalent the \om-regular languages~\cite{buchi1960decision}. That means that every language that is recognised by a NBW is a \om-regular language, and on the other hand, for every \om-regular language there exists a NBW recognising it.

% However, this equivalence does not hold for DBW (Büchi showed it too). There are \om-regular languages that cannot be recognised by any DBW. A typical example is the language $(0+1)^*1^\omega$. This is the language of all infinite words of 0 and 1 with only finitely many 0. It can be shown that this language can be recognised by a NBW (it is thus a \om-regular language) but not by a DBW~\cite{1996_vardi}\cite{2002_roggenbach}. The class of languages recognised by DBW is thus a strict subset of \om-regular languages recognised by NBW. We say that DBW are less expressive than NBW.

% An implication of this is that there are NBW for which no DBW recognising the same language exists. Or in other words, there are NBW that cannot be converted to DBW. Such an inequivalence is not the case, for example, for finite state automata on finite words, where every NFA can be converted to a DFA with the subset construction~\cite{hopcroft2006automata}\cite{1959_rabin}. In the case of Büchi automata, this inequivalence is the main cause that Büchi complementation problem is such a hard problem~\cite{niessner1997deterministic} and until today regarded as unsolved. 



% \subsubsection{Deterministic and Non-Deterministic Büchi Automata}
% As for normal finite state automata, there are deterministic and non-deterministic versions of Büchi automata. The difference lies in the transition function. For the non-deterministic case it is $\delta: \Sigma \times Q \rightarrow 2^Q$, but for the deterministic case it is strictly $\delta: \Sigma \times Q \rightarrow Q$. That means, whereas in a non-deterministic Büchi automaton a state $q$ may have zero, one, or more successors on a given symbol $a$ (denoted by $\delta(q,a) \geq 0$), in a deterministic Büchi automaton this number is always exactly one ($\delta(q,a) = 1$).

% The definition of a Büchi automaton given above is thus in fact the definition of a non-deterministic Büchi automaton. This coincides with a convention that we adopt in this thesis. If not explicitly stated, when we say ``Büchi automaton'' we actually mean a non-deterministi Büchi automaton. This is first, because deterministic Büchi automata are a special case of non-deterministic Büchi automata, and second, the problem of complementation that this thesis is about is only significant for the non-deterministic case.

% A Büchi automaton is complete if every state has at least one outgoing transition for every symbol of the alphabet. Formally, this means that $|\delta(q,a)| \geq 1, \forall q \in Q, \forall a \in \Sigma$. Note that deterministic Büchi automata are always complete, and thus only non-deterministic Büchi automata can be incomplete

% \subsubsection{Equivalences}
% An important property of Büchi automata is that deterministic Büchi automata are less expressive than non-deterministic Büchi automata. That means that there exist non-deterministic Büchi automata for which no deterministic Büchi automata accepting the same language exists.

% Non-deterministic Büchi automata in turn are equivalent to the \om-regular languages. That means that every language that is recognised by any Büchi automaton is an \om-regular language, and for every \om-regular language there exists a non-deterministic Büchi automaton recognising it.

% Furthermore, non-deterministic Büchi automata are equivalent to other classes of \om-automata such as Muller, Rabin, Streett, and Parity automata. Within these classes, determinstic and non-deterministic automata are equivalent. This means that every Büchi automaton can be translated to an equivalent deterministic or non-deterministic Muller, Rabin, Streett, or Parity automaton, and any of these latter automata can be translated to a non-deterministic Büchi automaton. Figure~\ref{equivalences} summarises these expressive relations of Büchi automata.



% \subsection{Other \om-Automata}
% %     - Muller, Rabin, Streett, Parity
% %     - McNaughton's Theorem (NBW = DMW)
% %     - Complete picture of equivalences
% After the introduction of Büchi automata in 1962, several other types of \om-automata have been proposed. The best-known ones are by Muller (Muller automata, 1963)~\cite{1963_muller}, Rabin (Rabin automata, 1969)~\cite{rabin1969decidability}, Streett (Streett automata, 1982)~\cite{Streett1982121}, and Mostowski (parity automata, 1985)~\cite{1985_mostowski}.

% % The best-known ones are Muller (1963)~\cite{1963_muller}, Rabin (1969)~\cite{rabin1969decidability}, Streett (1982)~\cite{Streett1982121}, and parity (1985)~\cite{1985_mostowski} automata. 

% All these automata differ from Büchi automata, and among each other, only in their acceptance condition, that is, the condition for accepting or rejecting a run $\rho$. We can write a general definition of \om-automata that covers all of these types as $(Q, \Sigma, q_0, \delta, Acc)$. The only difference to the 5-tuple defining Büchi automata is the last element, $Acc$, which is a general acceptance condition. We list the acceptance condition of all the different \om-automata types below~\cite{1999_loeding}. Note that again a run $\rho$ is a sequence of states, and $\textsf{inf}(\rho)$ is the set of states that occur infinitely often in run $\rho$. 

% % Itemize of all acceptance conditions, including Büchi
% \begin{tabular}{|l|l|l|}
% \hline
% \textbf{Type} & \textbf{Definitions} & \textbf{Run $\rho$ accepted if and only if\dots} \\
% \hline
% Büchi & $F \subseteq Q$ & $\textsf{inf}(\rho) \cap F \neq \varnothing$ \\
% \hline
% Muller & $F \subseteq 2^Q$ & $\textsf{inf}(\rho) \in F$ \\
% \hline
% Rabin & $\{(E_1,F_1),\dots,(E_r,F_r)\},\,E_i, F_i \subseteq Q$ & $\exists i: \textsf{inf}(\rho) \cap E_i = \varnothing \, \wedge \, \textsf{inf}(\rho) \cap F_i \neq \varnothing$ \\
% \hline
% Streett & $\{(E_1,F_1),\dots,(E_r,F_r)\},\,E_i, F_i \subseteq Q$ & $\forall i: \textsf{inf}(\rho) \cap E_i \neq \varnothing \, \vee \, \textsf{inf}(\rho) \cap F_i = \varnothing$ \\
% \hline
% Parity & $c: Q \rightarrow \{1,\dots,k\},\,k \in \mathbb{N}$ & $\textrm{min}\{c(q)\;|\;q \in \textsf{inf}(\rho) \} \; \textrm{mod} \; 2 = 0$ \\
% \hline
% \end{tabular}

% In the Muller acceptance condition, the set of infinitely occuring states of a run ($\textsf{inf}(\rho)$) must match a predefined set of states.
% % The Muller acceptance condition is the most general one, and all of the other listed conditions can be expressed as a Muller acceptance condition~\cite{1999_loeding}.
% The Rabin and Streett conditions use pairs of state sets, so-called accepting pairs. The Rabin and Streett conditions are the negations of each other. This allows for easy complementation of deterministic Rabin and Streett automata~\cite{1999_loeding}, which will be used for certain Büchi complementation construction, as we will see in Section\ref{review}. The parity condition assigns a number (color) to each state and accepts a run if the smallest-numbered of the infinitely often occuring states has an even number. For all of these automata there exist non-deterministic and deterministic versions, and we will refer to them as NMW, DMW (for non-deterministic and deterministic Muller automata), and so on.

% In 1966, McNaughton made an important proposition, known as \emph{McNaughton's Theorem}~\cite{McNaughton1966}. Another proof given in~\cite{Thomas:1991}. It states that the class of languages recognised by deterministic Muller automata are the \om-regular languages. This means that non-deterministic Büchi automata and deterministic Muller automata are equivalent, and consequently every NBW can be turned into a DMW. This result is the base for the determinisation-based Büchi complementation constructions, as we will see in Section~\ref{det-based}.

% It turned out that also all the other types of the just introduced \om-automata, non-deterministic and determinstic, are equivalent among each other~\cite{2002_roggenbach}\cite{2006_klein}\cite{klein2005linear}\cite{1999_loeding}\cite{Thomas:1991}. This means that all the \om-automata mentioned in this thesis, with the exception of DBW, are equivalent and recognise the \om-regular languages. This is illustrated in Figure~\ref{equivalences}



% % For all of them exist deterministic and non-deterministic versions
% % Properties, such as Rabin acceptance condition is dual of Streett

% % McNaughtons Theorem (1966) \cite{McNaughton1966}, another proof in \cite{Thomas:1991}: NBW = DMW

% % It turns out that all of NMW, DMW, NRW, DRW, NSW, DSW, NPW, DPW are equivalent among each other

% % Picture of expressive equivalences
% \begin{figure}[htb]
% \begin{center}
% \Equivalences
% \caption{Non-deterministic Büchi automata (NBW) are expressively equivalent to Muller, Rabin, Streett, and parity automata (both deterministic and non-deterministic), and to the \om-regular languages. Deterministic Büchi automata (DBW) are less expressive than NBW.}
% \label{equivalences}
% \end{center}
% \end{figure}


% \subsection{Complementation of Büchi Automata}
% \label{intro:complementation}
% Büchi automata are closed under complementation. This result has been proved by Büchi himself when he introduced Büchi automata in~\cite{buchi1960decision}. Basically, this means that for every Büchi automata $A$, there exists another Büchi automaton $B$ that recognises the complement language of $A$, that is, $L(B) = \overline{L(A)}$.

% It is interesting to see that this closure does not hold for the specific case of DBW. That means that while for every DBW a complement Büchi automaton does indeed exist, following from the above closure property for Büchi automata in general, this automaton is not necessarily a DBW. The complement of a DBW may be, and often is, as we will see, a NBW. This result is proved in~\cite{Thomas:1991} (p. 15).

% The problem of Büchi complementation consists now in finding a procedure (usually called a construction) that takes as input any Büchi automaton $A$ and outputs another Büchi automaton $B$ with $L(B) = \overline{L(A)}$, as shown below.

% \hbox to \hsize{\hfill{\Complementation}\hfill}

% For complementation of automata in general, construction usually differ depending on whether the input automaton $A$ is deterministic or non-deterministic. Complementation of deterministic automata is often simpler and may sometimes even provide a solution for the complementation of the non-deterministic ones.

% To illustrate this, we can briefly look at the complementation of the ordinary finite state automata on finite words (FA). FA are also closed under complementation~\cite{hopcroft2006automata} (p. 133). A DFA can be complemented by simply switching its accepting and non-accepting states~\cite{hopcroft2006automata} (p. 133). Now, since NFA and DFA are equivalent~\cite{hopcroft2006automata} (p. 60), a NFA can be complemented by converting it to an equivalent DFA first, and then complement this DFA. Thus, the complementation construction for DFA provides a solution for the complementation of NFA.

% Returning to Büchi automata, the case is more complicated due to the inequivalence of NBW and DBW. The complementation of DBW is indeed ``easy'', as was the complementation of DFA. There is a construction, introduced in 1987 by Kurshan~\cite{Kurshan198759}, that can complement a DBW to a NBW in polynomial time. The size of the complement NBW is furthermore at most the double of the size of the input DBW.

% If now for every NBW there would exist an equivalent DBW, an obvious solution to the general Büchi complementation problem would be to transform the input automaton to a DBW (if it is not already a DBW) and then apply Kurshan's construction to the DBW. However, as we have seen, this is not the case. There are NBW that cannot be turned into equivalent DBW.

% Hence, for NBW, other ways of complementing them have to be found. In the next section we will review the most important of these ``other ways'' that have been proposed in the last 50 years since the introduction of Büchi automata. The Fribourg construction, that we present in Chapter~\ref{fribourg_construction}, is another alternative way of achievin this same aim.


% \subsection{Complexity of Büchi Complementation}

% % (0.76n)^n
% % n = 15
% % (0.76*15)^15 = 7.138 * 10^15 = 7.138 quadrillions
% % 1 quadrillion = 10^15 = 10^6*10^9 = 1 million billions

% Constructions for complementing NBW turned out to be very complex. Especially the blow-up in number of states from the input automaton to the output automaton is significant. For example, the original complementation construction proposed by Büchi~\cite{buchi1960decision} involved a doubly exponential blow-up. That is, if the input automaton has $n$ states, then for some constant $c$ the output automaton has, in the worst case, $c^{c^n}$ states~\cite{PrasadSistla1987217}. If we set $c$ to 2, then an input automaton with six states would result in a complement automaton with about 18 quintillion ($18 \times 10^{18}$) states.

% Generally, state blow-up functions, like the $c^{c^n}$ above, mean the absolute worst cases. It is the maximum number of states a construction \emph{can} produce. For by far most input automata of size $n$ a construction will produce much fewer states. Nevertheless, worst case state blow-ups are an important (the most important?) performance measure for Büchi complementation constructions. A main goal in the development of new constructions is to bring this number down.

% A question that arises is, how much this number can be brought down? Researchers have investigated this question by trying to establish so called lower bounds. A lower bound is a function for which it is proven that no state blow-up of any construction can be less than it. The first lower bound for Büchi complementation has been established by Michel in 1988 at $n!$~\cite{michel1988}. This means that the state blow-up of any Büchi complementation construction can never be less than $n!$.

% There are other notations that are often used for state blow-ups. One has the form $(xn)^n$, where $x$ is a constant. Michel's bound of $n!$ would be about $(0.36n)^n$ in this case~\cite{2006_yan}. We will often use this notation, as it is convenient for comparisons. Another form has 2 as the base and a big-O term in the exponent. In this case, Michel's $n!$ would be $2^{O(n\,log\,n)}$~\cite{2006_yan}.

% Michel's lower bound remained valid for almost two decades until in 2006 Yan showed a new lower bound of $(0.76n)^n$~\cite{2006_yan}. This does not mean that Michel was wrong with his lower bound, but just too reserved. The best possible blow-up of a construction can now be only $(0.76n)^n$ and not $(0.36n)^n$ as believed before. In 2009, Schewe proposed a construction with a blow-up of exactly $(0.76n)^n$ (modulo a polynomial factor)~\cite{schewe2009buchi}. He provided thus an upper bound that matches Yan's lower bound. The lower bound of $(0.76n)^n$ can thus not rise any further and seems to be definitve.

% Maybe mention note on exponential complexity in \cite{1996_vardi} p. 8.


% \subsection{Complementation of Büchi Automata}
% It has been proved by Büchi himself that Büchi automata are closed under complementation~\cite{buchi1960decision}. That means that for every Büchi automaton, there exists another Büchi automaton accepting the complement language of the initial automaton.

% Let us denote by $L(A)$ the language recognised by Büchi automaton $A$. Then the complement language $\overline{L(A)}$ of $L(A)$ is $\overline{L(A)} = \Sigma^\omega \setminus L(A)$.

% \hbox to \hsize{\hfill{
% \begin{tikzpicture}[item/.style={rectangle,draw,text width=2.5cm}]
% \node[] (left) {$A$ with $L(A)$};
% \node[item] (middle) [right=of left] {Complementation algorithm};
% \node[] (right)  [right=of middle] {$B$ with $L(B) = \overline{L(A)}$}; 
% \path[->] (left) edge (middle)
%           (middle) edge (right);
% \end{tikzpicture}}\hfill}

% The problem of Büchi complementation can thus be summarised as follows. Given a Büchi automaton $A$, find a Büchi automaton $B$, such that $L(B) = \overline{L(A}$. For solving this problem we need an algorithm that takes $A$ as input and returns $B$ as output. 

% As a starting point, let us look at the complementation problem for normal finite state automata on finite words. Normal finite state automata recognise the regular languages and are also closed under complementation. For deterministic finite state automata, a possible complementation algorithm consists in simply inverting the accepting and non-accepting states of the automaton. Inuitively, every word that leaves the input automaton in an accepting state will leave the output automoaton in a non-accepting state, and vice versa. For the case of non-deterministic automata, one can take adavantage of the fact that every non-deterministic automata can be converted to an equivalent deterministic automaton. A standard algorithm for this conversion is the subset-construction, which is described in detail in [cite Hopcroft, Sec. 2.3.5]. The subset-construction basically takes all the subsets of states of the input automaton as states of the output automaton. A possible complementation algorithm for non-deterministic finite state automata consists thus in determinisation by the subset-construction and complementation by switching accepting and non-accepting states.

% Again, the cases of deterministic and non-deterministic automata are treated separately. For DBW, the method of switching accepting and non-accepting states does not work. Imagine for example that $\rho$ is the run of the word $x \in \Sigma^\omega$ of automaton $A$ (a DBW has exactly one run for every word of $\Sigma^\omega$). If $\textsf{inf}(\rho)$ contains both an accepting and a non-accepting state, then the switching of accepting and non-accepting states has no effect on the acceptance of $x$, as it is accepted in both cases. A working procedure for complementing DBW has been described by Kurshan [cite Kurshan, 1987]. Kurshan's construction is relatively easy and can be described in one sentence: make all states of the input automaton $A$ non-accepting, add another copy of $A$, remove all its accepting states and make the non-accepting states accepting, and finally add transitions from the states of the first copy of $A$ to the corresponding destination states in the second copy of $A$. The resulting automaton is an NBW $B$ that accepts the complement language of the input DBW $A$.

% In the case of finite-word automata, the complementation procedure for DFA provided a solution for the complementationn of NFA, because there is a translation from every NFA to an equivalent DFA. For Büchi automata this is however not the case. As mentioned above, there are NBW for which no equivalent DBW exists. We say that NBW can in general not be determinised.



% \section{Review of Büchi Complementation Constructions}
% \label{review}
% \subsection{Ramsey-Based Approaches}
% \label{ramsey-based}
% The method is called Ramsey-based because its correctness relies on a combinatorial result by Ramsey to obtain a periodic decomposition of the possible behaviors of a Büchi automaton on an infinite word~\cite{2012_breuers}.

% \subsection{Determinisation-Based Approaches}
% \label{det-based}
% \subsection{Rank-Based Approaches}
% \label{rank-based}
% \subsection{Slice-Based Approaches}
% \label{slice-based}

% \section{Empirical Performance Investigations}