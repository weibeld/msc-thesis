\lettrine{T}{his chapter is} entirely dedicated to the Fribourg construction. The Fribourg construction is the Büchi complementation construction whose empirical performance investigation makes up the core of this thesis (Chapters~\ref{chap_investigation} and~\ref{chap_results}). The Fribourg construction belongs to the \textit{slice-based} complementation approach that we reviewed in Section~\ref{2_slice-based}. This means that it is based on reduced split trees, which we explained in Section~\ref{2_red_split_trees}. The Fribourg construction, as we describe it in this chapter, uses the right-to-left version of reduced split trees. 

The Fribourg construction is being developed at the University of Fribourg by Joel Allred and Ulrich Ultes-Nitsche\footnote{As mentioned, the authors call their construction\textit{subset-tuple construction}, in this thesis we will however use the name \textit{Fribourg construction}.}. A detailed description of the construction has been published in 2014 as a technical report entitled ``Complementing Büchi Automata with a Subset-tuple Construction''~\cite{2014_joel_ulrich}.

The aim of this chapter is to give an intuitive and practically oriented description of the Fribourg construction. We aim at clarifying its practical application. For this reason, we do not focus on a formally rigorous description of the construction. For the formal background, as well as proofs of correctness, we refer to the mentioned publication by the authors of the construction~\cite{2014_joel_ulrich}.

This chapter is structured as follows. In Section~\ref{3_construction}, we describe the basic Fribourg construction without any optimisations. The construction is divided into two sub-constructions, and we explain each of them separately. In Section~\ref{3_optimisations}, we present three optimisations that have been proposed for the Fribourg construction. These optimisations will also be subject to our empirical performance investigation in the next chapter. Finally, in Section~\ref{3_remarks}, we give some general remarks about the Fribourg construction, especially about its relations to other complementation constructions.


% formally precise description of the Fribourg construction, or proofs about its correctness and theoretical, because this has already been done by its authors in~\cite{2014_joel_ulrich}. 

% In this chapter we describe the Fribourg construction, the Büchi complementation construction developed at the University of Fribourg by Joel Allred and Ulrich Ultes-Nitsche. The construction has been published in 2014 as a technical report entitled ``Complementing Büchi Automata with a Subset-tuple Construction''~\cite{2014_joel_ulrich}.

% We do not give a formal description of the Fribourg construction in this chapter, because this has already been done in~\cite{2014_joel_ulrich}. Rather, our aim is to give an intuitive and practically oriented description. That means, demonstrating the concrete steps one has to do when sitting with a pencil in front of an automaton to be complemented. Similarly, this chapter does not contain any proofs of the correctness or complexity of the constructions, because they can be found in~\cite{2014_joel_ulrich}.

% This chapter is structured as follows. In Section~\ref{3_basics} we present some basic properties of the Fribourg construction and put it in relation with other complementation constructions. In Section~\ref{3_construction}, we describe the actual construction which consists of two stages, the construction of the upper part and the construction of the lower part. We present these two stages in separate sections, together with an example. Finally, in Section~\ref{3_optimsations}, we describe three optimisations for the construction, that have the abbreviations R2C, M1, and M2. These optimisations will also be subject to our empirical performance investigation that we describe in the subsequent chapter.

% A note on terminology: the authors themselves call their construction ``subset-tuple construction''. This is because a state of the output automaton consists of a tuple of subsets of states of the input automaton. However, this is also the case for other constructions. To make our construction more distinguishable from the other constructions, we decided to use the more striking name ``Fribourg construction''.

\section{Construction}
\label{3_construction}
In this section we explain the basic Fribourg construction without any applied optimisations. The construction consists of two sub-constructions that we call upper-part construction and lower-part construction. In the following  we first describe features that are common to these two sub-construction (Section~\ref{3_basics}). Then, in Section~\ref{3_upper_part} and~\ref{3_lower_part}, we describe in detail the upper-part construction and the lower-part construction, respectively. We illustrate the application of these two sub-construction with an example that we work through step by step.

\subsection{Basics}
\label{3_basics}
Below we first give a high-level view of the construction, and then present the state generation procedure. The state generation procedure determines the successors for existing states, and lies at the heart of the construction. In its basic form, the state generation procedure is similar for the two sub-constructions.

\subsubsection{High-Level View}
As mentioned, the Fribourg construction consists of two sub-constructions, the \textit{upper-part construction} and the \textit{lower-part construction}. These two sub-constructions are chained together, such that the output of the upper-part construction becomes the input of the lower-part construction. Figure~\ref{fribourg_construction} illustrates this in a functional view of the Fribourg construction.

\begin{figure}[htb]
\centering
\FribourgConstruction
\caption{Functional view of the Fribourg construction with an automaton $A$ as input and its complement $B$ as output.}
\label{fribourg_construction}
\end{figure}

The automaton $A$ to be complemented is the input for the upper-part construction. The upper-part construction builds up a new automaton by starting with an initial state and adding state by state. The output of the upper part construction is an intermediate automaton $U$. This intermediate automaton $U$ will be the \textit{upper part} of the final complement automaton. The lower-part construction takes $U$ as input and adds further states and transitions to it until finally outputting an automaton $B$ which is the complement of the input automaton $A$. We say that the lower-part construction attaches the \textit{lower part} of the final complement automaton to the upper part. This terminology comes from the fact that it is convenient to draw the states of the lower part below the states of the upper part~\cite{2014_joel_ulrich}. This explains why the two sub-constructions are called upper-part construction and lower-part construction.


\subsubsection{State Generation Procedure}
The two sub-constructions can be seen as modified subset constructions. Like the subset construction, they work on a set of existing states and add to each state one successor for each symbol of the alphabet. The principle of how successor states are generated is the same for both sub-construction. The difference between the two is that the lower-part construction adds additional information to the states (the colours), so that the states generated by the lower-part construction are different from the states generated by the upper-part construction. In the following, we explain how the state generation procedure works.

A state of the Fribourg consists of a tuple (that is, an ordered sequence) of subsets of states of the input automaton (note that we often refer to the states of the input automaton as the \textit{input-states}, and to the states of the output automaton as \textit{output-states}). This contrasts with the subset construction in which the output-states consist of a single subset of input-states. The states of the Fribourg construction are thus more structured than the states of the subset construction. We refer to the subsets of a tuple of a state as the \textit{components} of this state.

The sequence of components of each state of the Fribourg construction is imposed by a slice (that is, a level) of a reduced split tree. We will explain the process of going from an existing state over the slices of a reduced split tree to a successor state further below. For now, we look at how a slice defines the structure of a state. Figure~\ref{slices} shows a reduced split tree (on the left), and for each slice (framed by a shaded box), the state that is defined by this slice (on the right).
% The sequence of components of a specific state is defined by a corresponding slice of a reduced split tree. Figure~\ref{slices} illustrates this idea. Each node in a slice of a reduced split tree gives rise to a component in the corresponding state. Furthermore, the left-right order of the nodes is preserved in the order of the components. It is similarly possible to do the conversion in the reverse direction. That is, an output-state can be interpreted as a slice of a reduced split tree. In this case, it is not possible to whether two adjacent nodes are siblings or not, but as we will see, this is not necessary for the construction.

\begin{figure}[htb]
\centering
\Slices
\caption{Relation between slices of a reduced split tree (on the left) and states of the Fribourg construction (on the right).}
\label{slices}
\end{figure}

As can be seen in Figure~\ref{slices}, each node of a slice gives rise to a component in the corresponding state. To this end, it does not matter what the ``familial'' relations of the nodes are (for example, if they are siblings). However, it is important that the order of the components in a state must be the same as the order of the nodes in the corresponding slice. It is similarly possible to interpret a state as a slice of a reduced split tree (indicated by the double-ended arrows in Figure~\ref{slices}). This does not allow to infer the familial relations of the nodes in the slice, however, this is not necessary for the construction.

The state generation procedure that determines a successor state for an existing state (on a specific alphabet symbols) works as follows:
\begin{enumerate}
\item Interpret the existing state as a slice of a reduced split tree
\item Create the subsequent slice for the appropriate alphabet symbol
\item Interpret the new slice as a state
\end{enumerate}
The state that results from the new slice is the successor of the existing state for the given alphabet symbol. If, for example, we want to define the successor on the symbol $a$ (we refer to this successor as the $a$-successor) of the state $(\qm0)$, then as a first step we would create a slice representation of this state. In the case of $(\qm0)$ this slice looks like the first slice from the top in Figure~\ref{slices}. Next, we create the subsequent slice for symbol $a$, based on the input automaton. This new slice might look like the second slice from the top in Figure~\ref{slices}. The last step is to interpret this new slice as a state, for example $(\qqm02, \qm1)$, and set it as the $a$-successor of $\qm0$.

Note that the translation of states to and from slices is only a mental aid and not a strictly necessary. It is possible to deduce a successor from an existing state, for example, $(\qm02,\qm1)$ from $\qm0$, directly, by describing the procedure in a different way. However, by using reduced split trees, we can keep the central features of the state generation procedure (such as the splitting of accepting and non-accepting states, the placement of the accepting states to the right of the non-accepting states, and the precedence of states in a slice from right to left) encapsulated in the concept of reduced split trees.

% This derivation of the states from slices of reduced split trees has the effect that an output-state contains at most one occurrence of each input state. In other words, the subsets in a tuple are pairwise disjoint, that is, there are no two subsets in the tuple that share a common input-state. 


% Effect of reduced split trees is that each output-state contains at most one occurrence of each input-states.


% This distinction between upper and lower part is inspired by Kurshan's construction for complementing deterministic Büchi automata~\cite{Kurshan198759}. In fact, Kurshan's construction is a special case of the Fribourg construction~\cite{2014_joel_ulrich}.

% Relation to Vardi and Wilke's construction



% The Fribourg construction is a \textit{slice-based} complementation construction. That means that, like the other constructions of the slice-based approach (see Section~\ref{2_slice-based}), it is based on reduced split trees. Furthermore, it works in a subset-construction manner, that is, the output automaton is constructed state-by-state, by starting from an initial state.

% The output-states are internally structured as tuples of subsets of input-states (each state consists of one tuple). The subsets of a tuple are pairwise disjoint, that is, no tuple contains two times the same input-state. The input-states of a tuple are the same as in the subset construction. The difference to the subset construction is that the input-states are not all in the same set, but distributed over multiple sets. Furthermore, the order of these sets in the tuple matters. As a convention, we will refer to the subsets contained by a tuple of an output-state as the \textit{components} of this output-state.

% The components output-states are determined by levels of reduced split trees. According to the terminology of Vardi and Wilke~\cite{vardi2007automata}, we call these levels \textit{slices}. Figure~\label{slices} shows how slices of a reduced split tree determine output-states of the Fribourg construction. The relation works also in the other direction, that is, an output-state of the Fribourg construction determines a slice of a reduced split tree. The simple rule is that each vertex of a slice becomes a component in in the tuple of the output-state, and the order of the vertices is preserved.

% \begin{figure}[htb]
% \centering
% \Slices
% \caption{Relation between slices of a reduced split tree (left) and states of the output automaton of the Fribourg construction (right). The sequence of nodes in a slice determines the sequence of components in a state.}
% \label{slices}
% \end{figure}

% This relation between slices of reduced split trees and output-states determines the basic working of the Fribourg construction. It works as follows. Start with an initial output-state containing only the initial input-state in its tuple. This state will be the current state. Translate the current state to a level of a reduced split tree, and, according to the input automaton, determine the next level of the reduced split tree for the first alphabet symbol, say $a$. Translate this new level back to an output-state, and set it as the $a$-successor of the current state. Repeat this procedure for all alphabet symbols, until the current state has a successor for each one. Finally, repeat the entire procedure for each output-state that has no successors yet. As in the subset construction, if a successor state happens to be identical to an already existing state, then just add a transition to this existing state.

% What we just described is the very basic working of the Fribourg construction. However, there are additional details. First, there are two passes of this subset-construction-like procedure. The first one results in the so-called \textit{upper part} of the final complement automaton. The second one is applied on the states of the upper part (and all the newly created states), and results in the so-called \textit{lower part} attached to the upper part. These two parts together form the final complement automaton. The terminology ``upper'' and ``lower'' results from the fact that, when doing the construction by hand, the lower part is typically drawn below the upper part.

% This distinction between upper and lower part is inspired by Kurshan's construction for complementing deterministic Büchi automata~\cite{Kurshan198759}. In fact, Kurshan's construction is a special case of the Fribourg construction~\cite{2014_joel_ulrich}.

% The upper part of the Fribourg construction does not contain any accepting states. The lower part, in turn, may contain accepting states. A run of the final complement automaton starts in the upper part, and has in each upper-part state the non-deterministic choice to move to the lower part. Once in the lower part, a run cannot return to the upper part anymore. Semantically, the upper part represents anything that can happen in a finite prefix of an \om-word, and the lower part takes care of the infinite behaviour on \om-words.

% The fact that the lower part determines the acceptance of a run, requires additional sophistication. This is achieved by the decoration of components. All components of the lower-part states are decorated with one of the three colours 0, 1 and 2. The colour of a component is determined by two things. First, whether the component is accepting or non-accepting. Second, the colour of its predecessor component. The predecessor component $c_{pred}$ of a component $c$ is the component of the predecessor state, that, in terms of reduced split trees, is the parent vertex of the vertex corresponding to component $c$.

% Figure showing predecessor component relation

% This colouration of components in the lower part requires that during the construction of the lower part, we keep track of two properties of each component. First, whether it is accepting or non-accepting, and second, its predecessor component (or just the colour of its predecessor component).

% On a more general note, the Fribourg construction uses a similar idea as Vardi and Wilke's slice-based construction from 2007~\cite{vardi2007automata}. The upper and lower part of the Fribourg construction correspond to the \textit{initial phase} and \textit{repetition phase} of Vardi and Wilke's construction. Furthermore, the colours 0, 1, and 2 of the Fribourg construction correspond to the decorations \textit{inf}, \textit{new}, and \textit{die} of Vardi and Wilke's construction. However, the two constructions still differ in details, especially in the transition from the upper part to the lower part. In any case, the Fribourg construction has been developed independently and is not based on Vardi and Wilke's construction. Rather, the development of the Fribourg construction was based on Kurshan's construction for complementing DBW, which is to the best of our knowledge, not the case for Vardi and Wilke's construction.

% Another difference is that the Fribourg construction uses right-to-left reduced split trees, whereas Vardi and Wilke's construction (as well as Kähler and Wilke's construction~\cite{2008_kaehler}) uses left-to-right reduced split trees. This is howevrer an arbitrary choice, and it has no effect on the final complement automaton. It would be possible to describe the Fribourg construction with left-to-right reduced split trees, and Vardi and Wilke's construction with right-to-left reduced split trees. In this thesis, we will stick with the right-to-left reduced split trees for the Fribourg construction.

% By using reduced split trees, we consider only greedy runs on prefixes of words. That is, if two or more runs on the same words are after a certain number of steps in the same state, then only one of them is considered, the others are omitted. 


\subsection{Upper-Part Construction}
\label{3_upper_part}
In this section, we describe the upper-part construction of the Fribourg construction, and demonstrate its application with an example. The example is based on the automaton $A$ in Figure~\ref{ex_aut_2}.

\subsubsection{Description}
The upper-part construction consists basically only of the state generation procedure that we explained the last section. It starts with an initial state with a single component that contains the initial state of the input automaton. This will be the initial state of the final complement automaton. Then, the state generation procedure is applied for each alphabet symbol to each unprocessed output-state.

If a determined successor state is identical to a state that already exists in the automaton, then only a transition to this state is added. If a determined successor state is empty, that is, contains no components, then no new state or transition at all is added to the automaton. In this case, the state being processed has no successor for the corresponding alphabet symbol, it is thus incomplete.

The state generation procedure is repeated until all states have been processed. At this stage, a deterministic intermediate automaton without any accepting states has been produced. This intermediate automaton is the upper part of the final complement automaton.

A peculiarity is that the upper part must be complete. An automaton is complete, if all of its states are complete. A state is complete if it has an outgoing transition for each symbol of the alphabet. If the upper-part automaton is not complete, then it must be made complete by adding a sink state. A sink state is a state that serves as the ``missing successor'' of all the incomplete states. Note that this sink state that is potentially added to the upper-part automaton must be accepting.

\begin{figure}[htb]
\centering
\Automaton
\caption{Non-deterministic Büchi automaton $A$ that is used for the examples in the present chapter.}
\label{ex_aut_2}
\end{figure}

% The construction of the upper part is simple and works basically as described above. We start with an initial output-state containing only a single component with the initial state of the input automaton. Then, for each output-state $q$ that has no successors so far, we creat a successor slice for each symbol of the alphabet $\alpha$, translate it to a state, and set it as the $\alpha$-successor of $q$. This is repeated until all states have a been processed.

% In case that the resulting automaton is not complete (that is, one or more states do not have successors for certain alphabet symbols), then it is made complete by adding an accepting sink state. This sink state is not actually a part of the upper part, and it is not further processed during the rest of the construction. However, its presence is important in case the upper part is not complete. 

% The result of this first stage of the construction is a deterministic and complete automaton that does not contain any accepting states (except a possible sink state, but which, as mentioned, does not really belong to the upper part).


\subsubsection{Example}
We demonstrate the application of the upper part construction by applying it to the example automaton $A$ in Figure~\ref{ex_aut_2}. Note that this automaton has an alphabet size of one, and thus can run only on a single \om-word, namely \aom. Furthermore, the automaton does not accept this word, which means that it does not accept \textit{any} word and is thus empty. We selected this special  automaton to keep our example small. However, the construction works in exactly the same way for non-empty automata with larger alphabets.

The steps of the upper-part construction on the automaton $A$ in Figure~\ref{ex_aut_2} are showing in Figure~\ref{steps_upper} (a) to (d). In the following, we walk through these steps one by one.

\begin{figure}[htb]
\centering
  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \UpperPartA
  \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \UpperPartB
  \caption{}
  \end{subfigure}

  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \UpperPartC
  \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \UpperPartD
  \caption{}
  \end{subfigure}
\caption{Steps of the upper-part construction applied to the example input automaton in Figure~\ref{ex_aut_2}.}
\label{steps_upper}
\end{figure}

The first step in Figure~\ref{steps_upper} (a) is to start with the initial state. As can be seen, this state $(\qm0)$ contains only one component with the initial state of the input automaton $A$ in Figure~\ref{ex_aut_2}. This state will be the initial state of the final complement automaton $B$.

The next step Figure~\ref{steps_upper} (b) is to add the $a$-successor to the initial state $(\qm0)$. This is done by the state generation procedure that we described in the last section. In particular, this means: (1) interpret the state $(\qm0)$ as a slice of a reduced split tree, (2) based on the input automaton $A$, determine the subsequent slice for symbol $a$, and (3) interpret this new slice as a state. This new state is the $a$-successor of $(\qm0)$. We can illustrate these steps in the following way:

\begin{center}
\SlicesOne
\end{center}

The state $(\qm0)$ results in a slice with only one node containing the set \qq0. For creating the next slice, we determine the set of states of $A$ that can be reached from \qq0 on symbol $a$. By looking at the automaton $A$ in Figure~\ref{ex_aut_2}, we see that this set is \qqqq012. According to the rules of reduced split trees, this set is split into a non-accepting set \qqq02, and an accepting set \qq1. The non-accepting set \qqqq012 becomes the left child, and the accepting set \qq1 becomes the right child of the current node. Translating the resulting new slice to a state results in $(\qqm02, \qm1)$. This state is thus set as the $a$-successor of $(\qm0)$ in the automaton under construction.

The next step in Figure~\ref{steps_upper} (c) is to determine the $a$-successor of the newly created state $(\qqm02, \qm1)$. Applying the same procedure as above, results in the following steps:

\begin{center}
\SlicesTwo
\end{center}

The state $(\qqm02, \qm1)$ corresponds to a slice with two nodes. For creating the next slice, these nodes must be processed from right to left. Regarding the node with \qq1, the set of states in $A$ that is reachable from \qq1 on $a$ is \qq2, which becomes thus the only child of this node. Regarding the next node with \qqq02, the state set reachable from \qqq02 is \qqqq012. Now, since \q2 already exists in the new slice, it is removed from the set. The resulting set \qqq01 is split into a non-accepting \qq0 and an accepting \qq1, which become the left child and right child of this node, respectively. The resulting slice corresponds to the state $(\qm0, \qm1, \qm2)$, which thus becomes the $a$-successor of the state $(\qqm02, \qm1)$.

The last step in Figure~\ref{steps_upper} (d) consists in determining the $a$-successor of the state $(\qm0, \qm1, \qm2)$. In this case, the steps of the state generation procedure are as follows:

\begin{center}
\SlicesThree
\end{center}

The state $(\qm0, \qm1, \qm2)$ results in a slice with three nodes. Again, we have to process these nodes from right to left. The node with \qq2 has a non-accepting \qq2 as its only child. Regarding the node with \qq1, the reachable set in $A$ is \qq2 However, since \q2 already exists in the slice, it is omitted, and since this empties the set, no child of this node is added to the new slice. Regarding the leftmost node, the set of states reachable from \qq0 is \qqqq012. Again, due to the omission of \q2 and the splitting into an accepting and a non-accepting set, this results in the accepting right child \qq1 and the non-accepting left child \qq0. The state corresponding to this slice is $(\qm0, \qm1, \qm2)$, which is identical to the state we are currently processing. Consequently, we add an $a$-loop to the state $(\qm0, \qm1, \qm2)$.

At this stage, all the states in the intermediate automaton have been processed. Since the resulting automaton is complete, there is no need to add a sink state to it. This means that the upper-part construction is finished.

Note that in this example, we had to determine only one successor for each state, because there is only one symbol in the alphabet of our example automaton. For input automata with more than one alphabet symbols, the procedure that we did for each state must be repeated for each symbol of the alphabet. This increases the number of steps, however, the principles of generating new states stay the same.


%We will illustrate the application of the Fribourg construction with the example automaton in Figure~\ref{example_automaton}. This automaton has only  one single alphabet symbol $a$. This choice was made to keep the example simple, because an alphabet size of, say 2, would double the number of steps and the number of transitions in the output-automaton. However, the procedure for automata with larger alphabets is exactly the same, just repeat the step of creating a successor state for the current state for each alphabet symbol.

% The example automaton in Figure~\ref{example_automaton} does not accept any word, because it is impossible for any run to visit the only accepting state $q_1$ infinitely many times. The automaton $A$ is thus empty. Consequently, the complement of $A$ is universal, that is, it accepts every possible word\footnote{The only possible \om-word with the alphabet $\Sigma = \{a\}$ is $a^\omega$, that is an infinite sequence of $a$'s.}.

% Figure~\ref{steps_upper} shows the complete steps for creating the upper part from the example automaton in Figure~\ref{example_automaton}. In Figure~\ref{steps_upper} (a), we start with a state containing only the component \qq0, because \q0 is the initial state of $A$.



% In Figure~\ref{steps_upper} (b), we determine the $a$-successor of the state $(\qm0)$. As explained, this works by looking at the state as a slice of a reduced split tree, and then creating the succeeding slice. For the case of $(\qm0)$, this gives the following two slices:

% \begin{center}
% \SlicesOne
% \end{center}

% From the state \q0 in the example automaton $A$, we can reach states \q0, \q1, and \q2 with the symbol $a$. Since \q1 is accepting, it is separated from the other states and put as a separate child to the right of the other child in the new slice. Transforming this new slice back to a state yields $(\qqm02, \qm1)$, which is the $a$-successor of $(\qm0)$. The component \qq1 is furthermore an accepting component, however, this does not matter in the construction of the upper part. Since there is only the single alphabet symbol $a$, we have already created all the successors of $(\qm0)$. If there would be more alphabet symbols, we would have to repeat the same procedure for each symbol.

% In Figure~\ref{steps_upper} (c), we create the $a$-successor of the previously created $(\qqm02, \qm1)$. Applying the same procedure as before, we get the following two slices:

% \begin{center}
% \SlicesTwo
% \end{center}

% Since we use right-to-left reduced split trees, we have to create the new slice from right to left, that is, first determining the children of vertex \q1, and then of \qqq02. From \q1 we can only reach \q2 on symbol $a$, thus the only child of \qq1 is \qq2. From the states in \qqq02, we can reach \q0, \q1, and \q2 on symbol $a$. However, \q1 already appears in the new slice, so it drops out. From the remaining states \q0 and \q1, \q1 is accepting, so it becomes a separate right-child, whereas \q0 becomes the left-child. Translating this slice to a state yields $(\qm0, \qm1, \qm2)$, which is the $a$-successor of $(\qqm02, \qm1)$.

% In Figure~\ref{steps_upper} (d), we determine in turn the $a$-successor of $(\qm0, \qm1, \qm2)$. Applying again the slice-procedure, we get the following:

% \begin{center}
% \SlicesThree
% \end{center}

% Again, we process the vertices of the upper slice from right to left. The only $a$-successor of \q2 in automaton $A$ is \q2, thus \qq2 is the only child of the vertex \qq2 in the upper slice. The state \q1 has \q2 as its $a$-successor. However, \q2 already appears in the new slice, and thus it drops out. Since \q1 has no remaining $a$-successors, the vertex \qq1 in the upper slice remains childless\footnote{In the terminology that we will use starting from the next section, we say that the runs going through this \q1 ``disappear''.}. Finally, the $a$-successors of \q0 are \q0, \q1, and \q2, however, as before, \q2 drops out because it already appears to the right, and \q0 and \q1 are separated because \q1 is accepting. Translating the new slice back to a state results in $(\qm0, \qm1, \qm2)$, whichi s identical to the current state. Thus, instead of adding a new state to the automaton, we just add an $a$-loop to $(\qm0, \qm1, \qm2)$.

% At this stage, all the existing states have successors for all the alphabet symbols, and thus the construction of the upper part is completed. The next step is to attach the lower part to the upper part in order to form the final complement automaton.



\subsection{Lower-Part Construction}
\label{3_lower_part}
In this section, we describe the lower-part construction. The lower-part construction can be seen as an extension of the upper-part construction. The difference is that the lower-part construction additionally assigns colours to the components of the generated states. Our explanation below are mainly about these colour assignments, because the rest of the construction is similar to the upper-part construction, which we explained above. We demonstrate the application of the lower-part construction by continuing the same example that we started for upper-part construction.

\subsubsection{Description}
The lower-part construction takes the intermediate automaton resulting from the upper-part construction as input. It works on the states of this upper part by regarding them as the unprocessed states to be processed. This results in additional successors for the states of the upper part, and finally in the entire lower part growing out of the upper part. Note that in the final complement automaton, there will be transitions from the upper part to the lower part, but no transitions back from the lower part to the upper part. This means that once a run of the output automaton enters the lower part, it cannot get back to the upper part.

The basic state generation procedure for the lower-part construction is similar as for the upper-par construction. The difference between the two sub-constructions is that the lower-part construction adds an additional piece of information to each component of new states. This piece information consists of one of three colours, that we denote by 0, 1, and 2. We shed light on the meaning of these colours further below. For now, we explain the rules that determine the colour of a specific component.

The colour of component $c$ of a new output-state $q$ that is the successor (for a given alphabet symbol) of an existing output-state $p$, is determined by three pieces of information:

\begin{enumerate}
\item Whether the component $c$ is accepting or non-accepting
\item The colour of the predecessor component of $c$ 
\item Whether the predecessor state $p$ contains any 2-coloured components
\end{enumerate}

Regarding the first point, a component is accepting if it contains accepting input-states. Regarding the second point, each component $c$ in a state $q$ has exactly one predecessor component $c_{pred}$ in the predecessor state $p$. This relation emerges from the parent-child relation in the reduced split tree representation of the two states. That is, from this perspective $c_{pred}$ is the parent of $c$. Consequently, every component has exactly one predecessor component, but every component may have zero, one, or two successor components. This relation of components can be best illustrated by an example. Consider the following two state $p$ and $q$ and their corresponding slice representation:
%from this In a slice representation of the two states, $c_{pred}$ is the component corresponding to the node which is the parent of the node corresonding to $c$.  The predecessor component of a component $c$ is the parent of $c$ in a slice-representation of the two states. It can be imagined as merging the edges between two slices into the two corresponding states. These virtual edges then link each component of the successor state with its predecessor component in the predecessor state. For example, consider the following two states $p$ and $q$, which are created by the state generation procedure on the example input automaton $A$ in Figure~\ref{ex_aut_2}:

\begin{center}
\PredCompsFirst
\end{center}

The edges of the slice representation of the states (on the right) can be mentally merged into the states (indicated as dotted arrows). This makes the relation between the components of the two states visible. We can see that the predecessor component of \qq0 in $q$ is \qq0 in $p$, the predecessor component of \qq1 in $q$ is \qq0 in $p$ as well, and the predecessor component \qq2 in $q$ is \qq2 in $p$. On the other hand, regarding the components of $p$, we can see that \qq0 has two successor components (\qq0 and \qq1 in $q$), \qq1 has no successor components, and \qq2 has one successor component (\qq2 in $q$). For the case of \qq1 of $p$ which has no successor components, we say that the input-runs leading through this components \textit{disappear}.

Having explained the notions of accepting component and predecessor component, we can turn to the actual rules that determine the colour of a given component. However, one remark is still necessary. The colouring rules need a way to recognise components that belong to the upper part of the output automaton. A way to guarantee this is to preliminarily assign the colour $-1$ to all the components of upper-part states. We will follow this convention throughout the rest of the thesis. Figure~\ref{colour_rules} shows the complete set of rules for determining the colour of a component $c$.

\begin{figure}[htb]
\centering
  \begin{subtable}[t]{\textwidth}
  \renewcommand{\arraystretch}{1.3}
  \centering
  \begin{tabular}{|C{3cm}|C{3cm}|C{3cm}|}
    \hline
    Colour of $c_{pred}$ & $c$ is non-accepting & $c$ is accepting \\
    \hline
    $-1$ & \textbf{0} & \textbf{2} \\
    0 & \textbf{0} & \textbf{2} \\
    1 & \textbf{2} & \textbf{2} \\
    \hline
  \end{tabular}
  \caption{Case A: the predecessor state has \textit{no} 2-coloured components.}
  \end{subtable}
  \vskip0.5cm

  \begin{subtable}[t]{\textwidth}
  \renewcommand{\arraystretch}{1.3}
  \centering
  \begin{tabular}{|C{3cm}|C{3cm}|C{3cm}|}
    \hline
    Colour of $c_{pred}$ & $c$ is non-accepting & $c$ is accepting \\
    \hline
    0 & \textbf{0} & \textbf{1} \\
    1 & \textbf{1} & \textbf{1} \\
    2 & \textbf{2} & \textbf{2} \\
    \hline
  \end{tabular}
  \caption{Case B: the predecessor state \textit{has} 2-coloured components.}
  \end{subtable}
\caption{Rules for determining the colour of a component $c$ (in bold). The identifier $c_{pred}$ denotes the predecessor component of $c$.}
\label{colour_rules}
\end{figure}

As can be seen in Figure~\ref{colour_rules} the colour rules are divided into two cases. Case A applies if the predecessor state does not contain any components with the colour 2, and case~B applies if the predecessor state contains one or more components with the colour 2. In each of the cases, the colour of a component $c$ is unambiguously determined by the two remaining parameters, namely the colour of the predecessor component $c_{pred}$, and the fact whether $c$ is an accepting or non-accepting component. We explain the reasons for these rules below when we explain the meaning of the colours.

Note that in case~A, the possible colours of the predecessor component includes $-1$, 0, and 1. That is, the colour 2 is missing. This is because by definition case~A applies only if the predecessor state has no 2-coloured components, thus the colour of the predecessor component cannot be 2. However, in this case, the colour of the predecessor component may be $-1$, namely in the case that the predecessor state is an upper-part state. On the other hand, in case~B, the possible colours of the predecessor component are 0, 1, and 2, that is, $-1$ is missing. This is because case~B applies only if the predecessor state contains a 2-coloured component, which cannot be the case if the predecessor state is an upper-part state. Thus, the predecessor component cannot have colour $-1$.

% In the first case, that the predecessor state contains no 2-coloured components, the possible colours of the predecessor components are $-1$, 0, and 1. Naturally, the predecessor component cannot be 2-coloured, but on the other hand, it might have colour $-1$, if the predecessor state is a state of the upper part. For the other case, that the predecessor state contains 2-coloured components, the possible colours for the predecessor component naturally include colour 2, but do not include colour $-1$, because a state containing 2-coloured components cannot be a state of the upper part.

Having explained the rules for determining the colour of a components, we now give some insight into the meaning of these colours. The purpose of the colours is to signalise the presence or absence of certain runs of the input automaton  in a run of the output automaton (note that we will often refer to runs of the input automaton as \textit{input-runs} and runs of the output automaton as \textit{output-runs}). We divide these input-runs into \textit{dangerous} and \textit{safe} runs. Dangerous input-runs have visited at least one accepting input-state since entering the lower part. These runs are dangerous in the sense that they might become accepting if they keep visiting accepting input-states. Safe runs, on the other hand, are runs that have not yet visited an accepting input-state since entering the lower part. Input-runs that never become dangerous correspond to non-accepting runs in the input automaton.

The purpose of the distinction of safe and dangerous input-runs is to recognise whether \textit{all} input-runs corresponding to an output-run on a specific word are safe. In this case, the output-run must be accepting. From a practical point of view, the colours of the components of an output-state determine whether this state must be added to the accepting set (according to a rule that we present at the end of this section).

In particular, the meaning of the three colours 0, 1, and 2 is as follows:

 % on a specific word. Note that the complement of a non-deterministic automaton must accept a word if and only if \textit{all} the runs of the input automaton on this words are rejecting. If there is a single run of the input automaton that accepts the word, then the complement automaton must not accept the word. Thus, we need a way to be sure that there are \textit{no} accepting runs of the input automaton on a specific word, and then we can accept this word with the complement automaton. 

{\setlist[description]{leftmargin=0.5cm, itemsep=\parskip}
\begin{description}
\item[Colour 2]
Signalises the presence of dangerous input-runs, that is, runs that have visited at least one accepting input-state since entering the lower part. Colour 2 appears when a group of input-runs, that have previously been safe, visits an accepting component (see Figure~\ref{colour_rules} (a) lines 1 and 2). Once a component has colour 2, it passes on this colour to all its successor components, no matter if they are accepting or non-accepting (see Figure~\ref{colour_rules} (b) line 3). This means that a path of 2-coloured components can only be cut if at some point the input-runs going through this component disappear (that is, the component has no successors). In this case, we say for brevity that the 2-coloured component \textit{disappears}.


 % the potential to becom accepting. If a component has colour 2, it means that there are input-runs that made a right-turn, in terms of slices of reduced split trees, that is, visited an accepting state (see rules in Figure~\ref{colour_rules} (a) line 1 and 2). Note that all the successor components of a 2-coloured component are also 2-coloured, no matter if they are accepting or non-accepting (Figure~\ref{colour_rules} (b) line 3). A ``string'' of 2-coloured components can only be cut if a 2-coloured component has no successor components (no children in terms of reduced split trees). In this case we say that the 2-coloured component ``disappears''.

\item[Colour 1]
Means basically the same as colour 2, namely the presence of dangerous runs. The idea behind colour 1 is a caveat that can arise if we would assign colour 2 to \textit{every} component whose corresponding input-runs just visited for the first time an accepting state. In this case, it could happen that in a sequence of output-states, there are constantly newly appearing 2-coloured components, and at the same time constantly disappearing 2-coloured components. The disappearance of the 2-coloured components means that the dangerous runs disappear, which in fact makes the corresponding output-states safe. However, this disappearance is hidden by the constant appearance of new 2-coloured components. The reason for colour 1 is to prevent this from happening. If the predecessor state already contains 2-coloured components (case~B in Figure~\ref{colour_rules}), then all the components that according to case~A in Figure~\ref{colour_rules} would deserve colour 2, get colour 1 instead (see Figure~\ref{colour_rules} (b) lines 1 and 2). We say that these are dangerous runs that are \textit{on hold}. However, as soon as all 2-coloured components disappear, and consequently case~A applies again, then all the successors of the 1-coloured component get colour 2 (see Figure~\ref{colour_rules} (a) line 3). In this way, the dangerous components \textit{on hold} become the new \textit{active} dangerous components.

% However, the detection of the disappearance of 2-coloured components is important with regard to whether an output-state is made accepting or not, at the end of the construction.

%  we miss the disappearance of 2-coloured components, and thus keep the containing output-state non-accepting instead of accepting. For this reason, the trick with colour 1 works as follows. If the predecessor state already contains 2-coloured components, then every component of the current state that deserves to be 2-coloured gets colour 1 instead of colour 2. This can be seen in Figure~\ref{colour_rules} (b) line 1 and 2. These are actually ``dangerous'' components kept ``on hold'', becaus then trick goes on as follows. As soon as all the 2-coloured components of a state disappear, the successors of all the 1-coloured components get 2-coloured. This can be seen in Figure~\ref{colour_rules} (a) line 3. At this point, these ``dangerous'' components ``on hold'' get the real ``dangerous'' components.

\item[Colour 0]
Signalises that all input-runs are safe. This means that these input-runs have not yet visited an accepting input-state since entering the lower part. If these runs stay safe indefinitely, then they are non-accepting in the input automaton. 
\end{description}}

As mentioned, the colours of the components of a state determines if a state must be made accepting at the end of the construction. The corresponding rule is as follows:

\begin{quote}
\centering
\textit{Each state of the lower part that contains no 2-coloured components must be made accepting.}
\end{quote}

That is, states that contain only 0-coloured and 1-coloured components must be made accepting. The rationale behind this rule is that if an output-run visits such a state infinitely often, then all the input-runs on the corresponding word are non-accepting. For states with only 0-coloured components, this is clear, as colour 0 means that there are no dangerous runs. For states with 1-coloured components, the case is slightly more complicated. As mentioned, 1-coloured components actually signalise the presence of dangerous runs. However, note that the situation of a state containing a 1-coloured component, but no 2-coloured component (case~A in Figure~\ref{colour_rules}), can only occur if previously all 2-coloured components disappeared. If this happens an infinite number of times (which is implied by the output-run visiting this state infinitely often), then an infinite number of 2-coloured components disappear. This means that all the corresponding dangerous input-runs eventually die, which means that none of them can be accepting. Consequently, a state with 1-coloured components guarantees that all the corresponding input-runs are non-accepting.

All these rules and mechanisms become clearer by seeing them in action. In the following, we demonstrate the application of the lower-part construction by an example.

\subsubsection{Example}
We continue the complementation of the example automaton $A$ in Figure~\ref{ex_aut_2} that we left off after the upper-part construction in Figure~\ref{steps_upper}. In the following, we apply the lower-part construction to the intermediate automaton in Figure~\ref{steps_upper} (d), and obtain finally the complement automaton of $A$.

Note that for this example, we use the following notation to indicate the colour of a component $\{q_i, \dots \}$:
\begin{itemize}
\item $\cl^{\{q_i, \dots \}}$: colour $-1$
\item $\cl0{\{q_i, \dots \}}$: colour 0 \vphantom{$\cl2{\{c\}}$}  % Strut
\item $\cl1{\{q_i, \dots \}}$: colour 1 \vphantom{$\cl2{\{c\}}$}  % Strut
\item $\cl2{\{q_i, \dots \}}$: colour 2
\end{itemize}

Figure~\ref{steps_lower} shows snapshots of the lower-part construction at different stages. In the following, we will explain each step that leads from the intermediate automaton in Figure~\ref{steps_upper} (d) to the final complement automaton in Figure~\ref{steps_lower} (d).

\begin{figure}[htb]
\centering
  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \ComplementA
  \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \ComplementB
  \caption{}
  \end{subfigure}

  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \ComplementC
  \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.49\textwidth}
  \centering
  \ComplementD
  \caption{}
  \end{subfigure}
\caption{Snapshots of the lower-part construction at different stages, applied to the intermediate automaton in Figure~\ref{steps_upper} (d).}
\label{steps_lower}
\end{figure}

The first step of the lower-part construction in Figure~\ref{steps_lower} (a) is to start with the upper part (as depicted in Figure~\ref{steps_upper} (d)), and assign colour $-1$ to all the components. As mentioned, we use this convention with colour $-1$ throughout this thesis.

The following steps of the lower-part construction consist in fact of the state generation function (as described in Section~\ref{3_basics}) plus the assignment of colours as described above. In Figure~\ref{steps_lower} (b) we add the $a$-successors for all the upper-part states. The state generation procedure results in the successor states $(\qqm02, \qm1)$, $(\qm0, \qm1, \qm2)$, and $(\qm0, \qm1, \qm2)$. To determine the colours of the components of these states, we consult the colour rules in Figure~\ref{colour_rules}. The predecessor states of all the new states do not contain a 2-coloured component, thus case~A of the colour rules applies. Furthermore, since the predecessor states are upper-part states, all the predecessor components have colour $-1$. That means that for each component only the rule in line 1 of Figure~\ref{colour_rules} applies. According to this rule, the non-accepting components get colour 0 and the accepting components get colour 2. This results in the successor states $(\qqm02, \cl2{\qm1})$ for $(\cl^{\qm0})$, $(\qm0, \cl2{\qm1}, \qm2)$ for $(\cl^{\qqm02}, \cl^{\qm1})$, and $(\qm0, \cl2{\qm1}, \qm2)$ for $(\cl^{\qm0}, \cl^{\qm1}, \cl^{\qm2})$. Note that this makes the upper-part states non-deterministic. In particular, this is the way how the runs of the final output automaton can switch non-deterministically to the lower part. 

% In Figure~\ref{steps_lower} (b), we created the $a$-successors of the three states of the upper part. The structure of these new states, apart from the colours, is determined by the same method that we used for the upper part. The only difference in the construction of the lower part is that each component is assigned a colour. For both new states, the predecessor states do not contain any 2-coloured components, thus we only need to consider the colour rules in Figure~\ref{colour_rules} (a). Regarding the colour of the predecessor components, they all have colour $-1$, thus we have to use the rule in Figure~\ref{colour_rules} (a) line 1 for all the new components. In this way, the components \qqq02, \qq0, and \qq2 are assigned colour 0, because they are non-accepting, and component \qq1 gets colour 2, because it is accepting.

% Note how we have to keep track for each component of the lower part whether it is accepting or non-accepting, and which is its predecessor component in the predecessor state.

In Figure~\ref{steps_lower} (c), we create the $a$-successor of the state $(\qqm02, \cl2{\qm1})$. Again, the new state is first determined by the state generation procedure, which results in $(\qm0, \qm1, \qm2)$. Now, we have to determine the colour for each of the components of this state. In this case, the predecessor state $(\qqm02, \cl2{\qm1})$ contains a 2-coloured component, thus case~B of the colour rules in Figure~\ref{colour_rules} applies. Next, we need to know the colour of the predecessor of each component. To figure this out, we refer to the slice representation of the two states that we used for the state generation procedure. As explained earlier, we can mentally merge the edges between the nodes of the slices into the two states. This results in the following picture, where the component relations are indicated by dotted arrows:

\begin{center}
\PredCompsOne
\end{center}

Consequently, the predecessor component of both, \qq0 and \qq1, is \qqq02, and the predecessor component of \qq2 is $\cl2{\qm1}$. Regarding \qq0 and \qq1, the colour of their predecessor component is 0, thus the rule on line 1 of Figure~\ref{colour_rules} (b) applies. Since \qq0 is non-accepting, it gets colour 0, and since \qq1 is accepting, it gets colour 1. Note how the assignment of colour 1 instead of colour 2 to \qq1 sets it \textit{on hold} because there exists already a 2-coloured component in the predecessor state. Regarding \qq2, the colour of its predecessor component is 2, and thus, according to the rule on line 3 of Figure~\ref{colour_rules} (b) it gets colour 2. This results in the state $(\qm0, \cl1{\qm1}, \cl2{\qm2})$.

Still in Figure~\ref{steps_lower} (c) we create the $a$-successor of this new state $(\qm0, \cl1{\qm1}, \cl2{\qm2})$. By the state generation procedure, we obtain $(\qm0, \qm1, \qm2)$. Since the predecessor state  $(\qm0, \cl1{\qm1}, \cl2{\qm2})$ has a 2-coloured component, case~B of Figure~\ref{colour_rules} applies. Regarding the predecessors of the components in $(\qm0, \cl1{\qm1}, \cl2{\qm2})$ we observe the following relations:

\begin{center}
\PredCompsTwo
\end{center}

By applying the appropriate colour rules depending on the colour of the predecessor component and the acceptance or non-acceptance of the component itself, \qq0 gets colour 0, \qq1 gets colour 1, and \qq2 gets colour 2. The resulting state is $(\qm0, \cl1{\qm1}, \cl2{\qm2})$, which is identical to its predecessor state. Consequently, we just add an $a$-loop to $(\qm0, \cl1{\qm1}, \cl2{\qm2})$.

In Figure~\ref{steps_lower} (d), we add the successor of the state $(\qm0, \cl2{\qm1}, \qm2)$. After the state generation procedure that generates $(\qm0, \qm1, \qm2)$, again case~B of the colour rules in Figure~\ref{colour_rules} applies. The predecessor component relations are as follows:

\begin{center}
\PredCompsThree
\end{center}

By applying the colour rules,  \qq0, gets colour 0, \qq1 gets colour 1, and \qq2 gets colour 0. This results in the state $(\qm0, \cl1{\qm1}, \qm2)$. It is interesting to see that between these two states, the 2-coloured component $\cl2{\qm1}$ disappears, because it has no successors. This disappearance is reflected in the fact that $(\qm0, \cl1{\qm1}, \qm2)$ contains a 1-coloured component but no 2-coloured components, which can only be the case if a 2-coloured component disappears (as mentioned above).

Still in Figure~\ref{steps_lower} (d), we create the $a$-successor of this new state $(\qm0, \cl1{\qm1}, \qm2)$. After the state generation procedure, which results in $(\qm0, \qm1, \qm2)$, we have to apply case~A of the colour rules in Figure~\ref{colour_rules}, because $(\qm0, \cl1{\qm1}, \qm2)$ does not contain a 2-coloured component. The component relations between the two states are as follows:

\begin{center}
\PredCompsFour
\end{center}

By applying the appropriate colour rules, \qq0 gets colour 0, \qq1 gets colour 2, and \qq2 gets colour 0, which results in the state $(\qm0, \cl2{\qm1}, \qm2)$. This state already exists in the automaton, and thus we only add an $a$-transition to it.

At this point, all the states in the automaton have been processed. The last thing that remains to do is to define the accepting set. The rule is that every state of the lower part that does not contain any 2-coloured components must be made accepting. In our case, this applies only to the state $(\qm0, \cl1{\qm1}, \qm2)$, and thus, this is the only accepting state of the complement automaton.

The automaton depicted in Figure~\ref{steps_lower} (d) is the complement $B$ of the automaton $A$ in Figure~\ref{ex_aut_2}. It is easy to verify that this automaton is indeed the complement of $A$. Both automata have an alphabet size of one, and thus work only on the word $\Sigma^\omega = \{a^\omega\}$. Whereas $A$ does not accept this word (what makes $A$ empty), $B$ does accept it (what makes $B$ universal). Consequently, $B$ is the complement of $A$.

% In Figure~\ref{steps_lower} (c), we added the $a$-successor to the state $(\qqm02, \cl2{\qm1})$. Disregarding the colours, this state has the form $(\qm0, \qm1, \qm2)$. Its predecessor state $(\qqm02, \cl2{\qm1})$ contains a 2-coloured component, thus we have to use the colour rules in Figure~\ref{colour_rules} (b). Now we need to know which are the predecessor components of the components in $(\qm0, \qm1, \qm2)$. This information is contained in the two slices of the reduced split tree that were used to determine the structure of the new state. For the case of our two states, the successor relation of their components is as follows:

% \begin{center}
% \PredCompsOne
% \end{center}

% The predecessor component of \qq0 is \qqq02, which has colour 0. Thus, we have to use the rule in Figure~\ref{colour_rules} (b) line 1, and \qq0 gets the colour 0, because it is non-accepting. The predecessor component of \qq1 is also \qqq02, and we have to use the same rule. However, since \qq1 is accepting, it gets colour 1. Note how the use of colour 1 here prevents the introduction of a further 2-coloured component before an already existing 2-coloured component has disappeared. The predecesor component of \qq2 is the 2-coloured $\cl2{\qm1}$, and thus, according to the rule in Figure~\ref{colour_rules} (b) line 3, \qq2 also gets colour 2.

% Next, still in Figure~\ref{steps_lower} (c), we create in turn the successor state of $(\qm0, \cl1{\qm1}, \cl2{\qm2})$. The structure of the components stays the same for the successor. The succesor relation of the two states is as follows:

% \begin{center}
% \PredCompsTwo
% \end{center}

% The result is that \qq0 gets colour 0, \qq1 gets colour 1, and \qq2 gets colour 2. Thus, the successor state is identical to the current state, and we add loop.

% Figure~\ref{steps_lower} (d) includes the remaining for arriving at the final complement automaton. First, we created the $a$-successor of the state $(\qm0, \cl2{\qm1}, \qm2)$. The complement successor relation of this state with its successor is as follows:

% \begin{center}
% \PredCompsThree
% \end{center}

% According to the rules in Figure~\ref{colour_rules} (b), component \qq0 gets colour 0, \qq1 gets colour 1, and \qq2 gets colour 0. This results in a new state, since the colours are different from the ones in the current state. Interesting here is that we have the case that a 2-coloured component ``disappears''. This is because the component $\cl2{\qm1}$ has no successor component in the successor state. For the $a$-successor of the new state $(\qm0, \cl1{\qm1}, \qm2)$, this means in turn that we have to use the rules in Figure~\ref{colour_rules} (a), what results in the already existing state $(\qm0, \cl2{\qm1}, \qm2)$.

% At this point, all the states in the automaton have been processed, and the construction is therefore completed. The only thing that remains to be done is to determine the accepting states of the automaton. The rule is that each state of the lower part that does not contain any 2-coloured component is an accepting state. In our automaton this applies only to the state $(\qm0, \cl1{\qm1}, \qm2)$, which is thus the only accepting state of the automaton.

% It can be easily seen that the automaton in Figure~\ref{steps_lower} accepts the word $a^\omega$, which is not accepted by the input automaton in Figure~\ref{example_automaton}. Thus, the result of our construction is a correct complement of the input automaton.

A loose upper bound for the worst-case state complexity of the entire Fribourg construction (including upper-part and the lower-part construction) has been calculated to be $O((1.59n)^n)$~\cite{2014_joel_ulrich}. This result is subject to ongoing research, and may be sharpened to a smaller number in future work.

This concludes our explanation of the basic Fribourg construction. In the next section, we present three optimisations that can be applied to the Fribourg construction in order to increase its performance. 


\section{Optimisations}
\label{3_optimisations}
There are three optimisations for the Fribourg construction, ad in this section, we describe each of them. For easier reference, we define the abbreviations R2C, M1, and M2 for the three optimisations. The optimisations can be added to the construction like add-ons, and they can be combined in different ways. This results in different \textit{versions} of the Fribourg construction. Throughout this thesis, we specify a specific version of a construction by appending the included optimisations after the construction name. For example, Fribourg+R2C means the Fribourg construction including the R2C optimisation, and Fribourg+M1+R2C means the Fribourg construction including the M1 and the R2C optimisation.

\subsection{R2C: Remove States With 2-Coloured Rightmost Component}

The R2C optimisation can be summarised as follows:

\begin{quote}
\centering
\textit{If the input automaton is complete, then states of the lower part whose\\rightmost component has colour 2 can be omitted.}
\end{quote}

It is important to highlight that his optimisation can only be applied if the input automaton is complete. We hint at this restriction by the letter C in R2C. If the completeness of the input automaton is given, then the optimisation allows to remove all the states whose rightmost component is 2-coloured. 

The reason that it is allowed to remove these states is as follows. If the input automaton is complete, then every input-state has at least one successor state on every alphabet symbol. This means that in the corresponding reduced split trees, that are used for the Fribourg construction, the rightmost nodes are guaranteed to have a successor node. Note that this guarantee applies only to the rightmost nodes, because the successors of the other nodes might be omitted in the right-to-left processing of the slices. Consequently, in terms of states, all rightmost components are guaranteed to have a successor component. 

If the colour of the rightmost component is 2, then all successor components inherit this colour (see the rule on line 3 of Figure~\ref{colour_rules} (b)). Since rightmost colours \textit{always} have a successor, \textit{all} the successor states with a rightmost 2-coloured component will contain a 2-coloured component. And since states containing a 2-coloured component are non-accepting, these states form a non-accepting cycle in the automaton. Consequently, it is safe to remove this cycle without changing the language of the automaton.

In our example from the last section, we could thus remove the states $(\qqm02, \cl2{\qm1})$ and $(\qm0, \cl1{\qm1}, \cl2{\qm2})$ from the output automaton in Figure~\ref{steps_lower} (d). However, remember that this is only allowed if the input automaton is complete, which in our case is true for the automaton $A$ in Figure~\ref{ex_aut_2}. The R2C optimisation is described in~\cite{2014_joel_ulrich} (Section 4.F).


\subsection{M1: Merge Adjacent Components}
The M1 optimisation allows the merging of certain constellations of adjacent components depending on their colour. Components can be merged in three cases in the following way:

\begin{enumerate}
\item Two adjacent 1-coloured components can be merged to a single 1-coloured component
\item Two adjacent 2-coloured components can be merged to a single 2-coloured component
\item An adjacent 2-coloured and 1-coloured component, where the 1-coloured component is to the right of the 2-coloured component, can be merged to a single 2-coloured component
\end{enumerate}

These mergers can be done recursively. This means that the result of a merger is in turn subject to further mergers. For example, given the state $(\qm0, \cl2{\qm1}, \cl2{\qm2}, \cl1{\qm3}, \cl1{\qm4}, \cl2{\qm5})$, the following chain of mergers is possible:

{\renewcommand{\arraystretch}{1.7}
\begin{tabular}{llll}
$(\qm0, \cl2{\qm1}, \cl2{\qm2}, \cl1{\qm3}, \cl1{\qm4}, \cl2{\qm5})$ & $\longrightarrow$ & $(\qm0, \cl2{\{q_1,q_2\}}, \cl1{\{q_3,q_4\}}, \cl2{\qm5})$ &
By rules 1 and 2 \\
& $\longrightarrow$  & $(\qm0, \cl2{\{q_1,q_2,q_3,q_4}\}, \cl2{\qm5})$ &
By rule 3 \\
& $\longrightarrow$ & $(\qm0, \cl2{\{q_1, q_2, q_3, q_4, q_5\}})$ &
By rule 2
\end{tabular}}

This means that with the M1 optimisation, we would add the state $(\qm0, \cl2{\{q_1, q_2, q_3, q_4, q_5\}})$ rather than $(\qm0, \cl2{\qm1}, \cl2{\qm2}, \cl1{\qm3}, \cl1{\qm4}, \cl2{\qm5})$ to the automaton. For the formal description and proof of correctness of the M1 optimisation, we refer to~\cite{2014_joel_ulrich} (Section 4.E).

The application of these mergers obviously reduces the maximum number of states that the construction can produce. The worst-case state growth regarding the number of states of the lower part has been calculated in~\cite{2014_joel_ulrich} to be $O((1.195n)^n)$. This must be added to a worst-case state growth of the upper part of $(0.53n)^n$. However, the resulting term is dominated by $O((1.195n)^n)$. It will be a subject of our empirical performance investigation in Chapter~\ref{chap_investigation} to investigate the impact of the M1 optimisation on example automata.


\subsection{M2: Keep Single 2-Coloured Component}
The M2 optimisation is the most complicated of the three optimisations. Its effect on the output automaton can be summarised as follows:

\begin{quote}
\centering
\textit{States of the lower part contain at most one 2-coloured component.}
\end{quote}

Note that without the M2 optimisation, it is possible that states contain two or more 2-coloured components. This can happen if the predecessor state contains no 2-coloured components and the new state contains multiple accepting components (see colour rules on line 1 and 2 of Figure~\ref{colour_rules} (a)). With the M2 optimisation, in this case only one of the accepting components gets colour 2, and the others get colour 1. The purpose of the M2 optimisation is to further reduce the maximum number of states that the construction can produce. 

It is important to note that the M2 optimisation is dependent on the M1 optimisation. That means that the M2 optimisation can only be applied if the M1 optimisation is also applied. We selected the abbreviation M2 for this optimisation to highlight that it is based on M1.

Below we first explain how a single 2-coloured component of a state is created. Next, we explain in detail the steps that the disappearance of this single 2-coloured component entails.

\subsubsection{Creation of a 2-Coloured Component}
As mentioned, when creating a new state, only one of the components, that without the M2 optimisation would become 2-coloured, gets colour 2. This component is defined to be the rightmost of the candidates for colour 2. A possible procedure to ensure this restriction is to determine the colours for the components from right to left, and assign colour 2 only if it has not been previously assigned in the state. If it has been previously assigned, then assign colour 1 instead of 2.

A special case applies if the component that gets assigned colour 2 has a 2-coloured predecessor component and a sibling to the left of it. With sibling we mean an adjacent component that has the same predecessor component. If this two criteria are fulfilled, then the sibling gets colour 2 as well. Note that without this special treatment, it would get colour 1 instead of 2. Thus, there are two 2-coloured components in the state. However, since the M2 optimisation also requires the M1 optimisation to be applied, these two 2-coloured components are merged to a single 2-coloured components. In this way, statement that all states have at most one 2-coloured components is still true.


\subsubsection{Actions on the Disappearance of a 2-Coloured Component}
The restriction of having only one 2-coloured component in a state entails special actions when this 2-coloured components disappears (that is, has no successor components). Imagine a state $p$ with a single 2-coloured component, and its successor state $q$. If after the assignment of colours as described above, $q$ has no 2-coloured component, then we have the situation that the 2-coloured component of $p$ disappeared. The required action in this situation is to change the colour of one of the 1-coloured components of $q$ (if there are any) to 2. If $q$ does not contain any 1-coloured components, then nothing is done and the creation of the state is finished. If $q$ contains exactly one 1-coloured component, then the colour of this component is changed to 2. If $q$ contains multiple 1-coloured components, then the following procedure is applied.

\begin{itemize}
\item Go to the position in $q$ where the successor of the disappeared 2-coloured component of $p$ \textit{would} be
\item From this position, go to the left until arriving at a 0-coloured component
  \begin{itemize}
  \item If the search arrives at the leftmost component, continue with the rightmost component
  \end{itemize}
\item From this 0-coloured component, go to the left until arriving at the first 1-coloured component
  \begin{itemize}
  \item If the search arrives at the leftmost component, continue with the rightmost component
  \end{itemize}
\item Change the colour of this 1-coloured component to 2
\end{itemize}

That is, if there are multiple 1-coloured components in the state, then we select the first 1-coloured component that is to the left of the first 0-coloured component that is to the left of the position where the successor of the disappeared component would be, and change its colour to 2. The relation ``to the left of'' has to be understood cyclically, such that the component to the left of the leftmost component in the state is the rightmost component of the state.

The effect of changing the colour of a 1-coloured component of a state $q$ to 2 is that $q$, which previously contained no 2-coloured  components, now contains a 2-coloured component. However, since a 2-coloured component disappeared, $q$ must still be accepting, even though it contains a 2-coloured component. For this reason, we mark states such as $q$ with a star ($*$). In general, each state that has been subject to a change of a 1-coloured component to a 2-coloured component is marked with a star. Finally, the rule for adding states to the accepting set is changed such that it includes all the states of the lower part that contain no 2-coloured component \textit{and} all the states that contain a 2-coloured component but are marked with a star.


Figure~\ref{complement_with_m2} shows the result of applying the Fribourg construction with the M1 and M2 optimisations to the example automaton in Figure~\ref{ex_aut_2}. The difference of this automaton to the complement resulting from the Fribourg construction without the M1 and M2 optimisation (see Figure~\ref{steps_lower} (d)) is the state at the bottom right of the automaton. As can be seen in the figures, without the optimisation the component \qq1 of this state is 1-coloured. With the M1 and M2 optimisations, however, \qq1 is 2-coloured. In both cases, the 2-coloured component of the predecessor state disappeared, however, with the M1 and M2 optimisations, the resulting 1-coloured \qq1 is made 2-coloured. Additionally, the state is marked with a star, so that it is still added to the accepting set. Regarding the successors of this marked state, the same procedure is repeated indefinitely: the 2-coloured component disappears, and one of the 1-coloured components is made 2-coloured. This is the reason why this state has a loop.

\begin{figure}[htb]
\centering
\ComplementWithMTwo
\caption{Result of applying the Fribourg construction with the M1 and M2 optimisation (Fribourg+M1+M2) to the automaton in Figure~\ref{ex_aut_2}.}
\label{complement_with_m2}
\end{figure}

The M2 optimisation further reduces the maximum number of states that the construction can produce. A loose upper bound of $O((0.86n)^n)$ for the worst-case state growth of the lower part of the automaton has been calculated in \cite{2014_joel_ulrich} (Section 4.H). However, calculations of actual values suggest that the real bound for the lower part might be as low as $O((0.76n)^n)$. The investigation of the worst-case state complexity of the M1 and M2 optimisation is subject to ongoing research by the authors of the Fribourg construction. Note that $O((0.86n)^n)$ or $O((0.76n)^n)$ is the maximum number of states of the lower part, and must be added to the maximum number of $(0.53n)^n$ upper-part states. However, the resulting term is dominated by either $O((0.86n)^n)$ or $O((0.76n)^n)$.


\section{General Remarks}
\label{3_remarks}
The Fribourg construction has many similarities to the slice-based construction by Vardi and Wilke~\cite{vardi2007automata} (see Section~\ref{2_slice-based}) that has been published in 2007. The upper part and lower part of the Fribourg construction correspond to the initial phase and repetition phase of Vardi and Wilke's construction. Furthermore, the colours 0, 1, and 2 of the Fribourg construction correspond to the decorations \textit{inf}, \textit{new}, and \textit{die} of Vardi and Wilke's construction. However, the Fribourg construction has been developed independently, and is not based on Vardi and Wilke's construction.

Rather, the Fribourg construction is based on Kurshan's complementation construction for deterministic Büchi automata~\cite{Kurshan198759}. Kurshan's construction also uses an upper and a lower part that have a similar function as the upper and the lower part of the Fribourg construction. The Fribourg construction has actually initially been devised as an adaptation of Kurshan's construction to non-deterministic Büchi automata, with the slice-based approach in mind.

With these remarks, we conclude the present chapter about the Fribourg construction. At this point, we have provided all the background that is needed in order to start with our empirical performance investigation of the Fribourg construction, which is the subject of the next chapter.


% The Fribourg construction draws from several ideas: the subset construction, run analysis based on reduced split trees, and Kurshan's construction~\cite{Kurshan198759} for complementing DBW. Following the classification we used in Section~\ref{review}, it is a slice-based construction. Some of its formalisations are similar to the slice-based construction by Vardi and Wilke~\cite{vardi2007automata}, however, the Fribourg construction has been developed independently. Furthermore, as we will see in Chapter~\ref{results}, the empirical performance of Vardi and Wilke's construction and the Fribourg construction differ considerably, in favour of the latter.

% Basically, the Fribourg construction proceeds in two stages. First it constructs the so-called upper part of the complement automaton, and then adds to it its so-called lower part. These terms stem from the fact that it is often convenient to draw the lower part below the previously drawn upper part. The partitioning in these two parts is inspired by Kurshan's complementation construction for DBW. The upper part of the Fribourg construction contains no accepting states and is intended to model the finite ``start phase'' of a run. At every state of the upper part, a run has the non-deterministic choice to either stay in the upper part or to move to the lower part. Once in the lower part, a run must stay there forever (or until it ends if it is discontinued). That is, the lower part models the infinite ``after-start phase'' of a run. The lower part now includes accepting states in a sophisticated way so that at least one run on word $w$ will be accepted if and only if all the runs of the input NBW on $w$ are rejected.

% As it may be apparent from this short summary, the construction of the lower part is much more involved than the construction of the upper part.

% \begin{figure}
% \begin{center}
% \Automaton
% \caption{Example automaton $A$}
% \label{example_automaton}
% \end{center}
% \end{figure} 


% \section{First Stage: Constructing the Upper Part}
% The first stage of the subset-tuple construction takes as input an NBW $A$ and outputs a deterministic automaton \Bp. This \Bp is the upper part of the final complement automaton $B$ of $A$. The construction of \Bp can be seen as a modified subset construction. The difference to the normal subset construction lies in the inner structure of the constructed states. While in the subset construction a state consists of a subset of the states of the input automaton, a \Bp-state in the subset-tuple construction consists of a \emph{tuple of subsets} of $A$-states. The subsets in a tuple are pairwise disjoint, that is, every $A$-state occurs at most once in a \Bp-state. The $A$-states occurring in a \Bp-state are the same that would result from the classic subset construction. As an example, if applying the subset construction to a state \qq0 results in the state \qqqq012, the subset-tuple construction might yield the state $(\qqm02,\qm1)$ instead.

% The structure of \Bp-states is determined by levels of corresponding reduced split trees. Vardi, Kähler, and Wilke refer to these levels as \emph{slices} in their constructions~\cite{vardi2007automata,2008_kaehler}. Hence the name slice-based approach. In the following, we will use the terms levels and slices interchangebly. A slice-based construction can work with either left-to-right or right-to-left reduced split trees. Vardi, Kähler, and Wilke use the left-to-right version in their above cited publications. In this thesis, in contrast, we will use right-to-left reduced split trees, which were also used from the beginning by the authors of the subset-tuple construction.

% Figure~\ref{levels_to_states} shows how levels of a right-to-left reduced split tree map to states of the subset-tuple construction. In essence, each node of a level is represented as a set in the state, and the order of the nodes determines the order of the sets in the tuple. [INFORMATION ABOUT ACC AND NON-ACC IS NEEDED IN THE LOWER PART BUT IMPLICIT IN THE STATES OF A]. To determine the successor of a state, say $(\qqm02,\qm1)$, one can regard this state as level of a reduced split tree, determine the next level and map this new level to a state. In the example of Figure~\ref{levels_to_states}, the successor of $(\qqm02,\qm1)$ is determined in this way to $(\qm0,\qm1,\qm2)$.

 

% Apart from this special way of determining successor states, the construction of \Bp proceeds similarly as the subset construction. One small further difference is that if at the end of determining a successor for every state in \Bp, the automaton is not complete, it must be made complete with an \emph{accepting} sink state. The steps for constructing \Bp from $A$ can be summarised as follows.

% \begin{itemize}
% \item Start with the state $(\qm0)$ if \q0 is the initial state of $A$
% \item Determine for each state in \Bp a successor for every input symbol
% \item It at the end \Bp is not complete, make it complete with an accepting sink state
% \end{itemize}

% For the example automaton $A$ in Figure~\ref{example_automaton}, we would start with $(\qm0)$, determine $(\qqm02,\qm1)$ as its $a$-successor, whose $a$-successor in turn we determine a $(\qm0,\qm1,\qm2)$. The $a$-successor of $(\qm0,\qm1,\qm2)$ is $(\qm0,\qm1,\qm2)$ again what results in a loop. Figure~\ref{upper_part} shows the final upper part \Bp of $A$.

% \begin{figure}
% \begin{center}
% \UpperPart
% \caption{Upper part \Bp of example automaton $A$.}
% \label{upper_part}
% \end{center}
% \end{figure} 


% The construction of the upper part takes as input a NBW $A$ and outputs a deterministic automaton $B^\prime$ that will be the upper part of the final complement automaton $B$. The construction of $B^\prime$ is in its approach similar to the subset construction. One starts with a $B^\prime$-state representing the initial state of $A$ and then recursively determines and adds for each $B^\prime$-state one successor state per input symbol. The difference to the subset construction lies in the inner structure of the $B^\prime$-states. In the subset construction this would simply be a single set of $A$-states. In the subset-tuple construction, however, a $B^\prime$-state is a tuple of sets of $A$-states. A tuple is an ordered list, so differently phrased, a $B^\prime$-state consists of one or more sets of $A$-states where the order of these sets matters. As we will see, the $A$-states present in a $B^\prime$-state are the same that would result from the subset construction. But while in the subset construction all these states are thrown together in one set, in the subset-tuple construction they are split up in multiple sets where additionally the order of these sets is important. The subset-tuple construction can thus be seen as a modified subset construction that includes additional structure.

% The structure of $B^\prime$-states is defined by ``level-clippings'' of reduced split trees, as we explain in a moment. But, talking about reduced split trees, we have to make a decision first. In Section~\ref{r_split_trees} we mentioned that reduced split trees come in equivalent left-to-right and right-to-left versions. The construction has to adopt one of these variants and stick to it. In this thesis we use the right-to-left version. The final complement automata look the same with either version except that the order of the tuples is reversed. Note that the optimisations described in Section~\ref{optimisations} is also based on this ordering and would need to be rephrased for the left-to-right version.

% \begin{figure}
% \begin{center}
% \Slices
% \end{center}
% \caption{From levels of a reduced split tree to the slices of the subset-tuple construction.}
% \label{levels_to_states}
% \end{figure} 

% A new $B^\prime$-state $q$, successor on symbol $a$ of an already existing $B^\prime$-state $p$, now is created in the following way. The predecessor $p$ is regarded as a level of a reduced split tree by looking at its sets as the nodes on this level. Then, the next level for the given symbol $a$ is constructed as described in Section~\ref{r_split_tree}. This new level then directly defines $q$ by taking the nodes as the sets of $q$'s tuple and keeping their order. Figure~\ref{tree_to_slices} illustrates this with the example automaton $A$ that we already used before. If a state with a simlar tuple to the just created $q$ already exists in $B^\prime$, then just a transition from $p$ to this state is added (hence the loop in the third state of Figure~\ref{tree_to_slices}). The construction starts with a $B^\prime$-state containing only $A$'s initial state and ends when all states of $B^\prime$ have been processed for all input symbols. In Figure~\ref{tree_to_slices}, the construction is complete, thus the automaton shown at the right is the upper part of the complement of $A$.

% If all the $A$-states of a $B^\prime$-state $p$ have no successors on an input symbol $a$, then $p$ will have no $a$-successor in $B^\prime$. This results in the upper part $B^\prime$ being incomplete at the end of the construction. In this case, it has to be made complete by adding a sink state. Furthermore, this sink state has to be accepting.

% States of the subset-tuple construction are thus levels of reduced split trees. In the constructions of Varid and Wilke~\cite{vardi2007automata}, and Kähler and Wilke~\cite{2008_kaehler} states are called \emph{slices} of reduced split trees, hence the name slice-based approach.

% \begin{figure}
% \begin{center}
% \UpperPart
% \end{center}
% \caption{Upper part of complement of $A$.}
% \label{upper_part}
% \end{figure} 


% \section{Second Stage: Adding the Lower Part}
% The second stage of the subset-tuple construction adds the lower part to the upper part \Bp. The two parts together form the final complement automaton $B$. The lower part is constructed by again applying a modified subset construction to the states of the upper part \Bp. This modified subset construction is an extension of the construction for the upper part. The addition is that each set gets decorated with a colour. These colours later determine which states of the lower part are accepting states.

% We divide our discussion of the lower part in two sections. In the following one (\ref{lower_part:steps}), we explain the ``mechanical'' construction of the lower part, the steps that have to be done to arrive at the final complement automaton $B$. In the next section (\ref{lower_part:intuition}) we give the idea and intuition behind the construction and explain why it works.

% \subsection{Construction}
% \label{lower_part:steps}
% As mentioned, every set of the states of the lower part gets a colour. There are three colours and we call them 0, 1, and 2. In the end we have to be able to disinguish the states of the upper part from the states of the lower part. This can be achieved by preliminarily assigning the special colour -1 to every set of the states of the upper part. After that the extended modified subset construction is applied, taking the states of the upper part (except a possible sink state) as the pre-existing states.

% At first, the extended modified subset construction determines the successor tuple (without the colours) of an existing state in the same way as the construction of the upper part. We will refer to the state being created as $p$ and to the existing state as $p_{pred}$. Then, one of the colours 0, 1, or 2 is determined for each set $s$ of $p$. We denote the colour of $s$ as $c(s)$. The choice of $c(s)$ depends on three factors.
% \begin{itemize}
% \item Whether $p_{pred}$ has a set with colour 2 or not
% \item The colour of the predecessor set $s_{pred}$ of $s$
% \item Whether $s$ is an accepting or non-accepting set
% \end{itemize}
% The predecessor set $s_{pred}$ is the set of $p_{pred}$ that in the corresponding reduced split tree is the parent node of the node corresponding to $s$. Figure~\ref{colours} shows the values of $c(s)$ for all possible situations as two matrices. There is one matrix for the two cases of factor 1 above ($p_{pred}$ has colour 2 or not) and the other two factors are laid out along the rows and columns of either matrix. Note that $c(s_{pred}) = -1$ is only present in the upper matrix, because in this case $p_{pred}$ is a state of the upper part and cannot contain colour 2.



% We will use the following notation to denote the colour of $s$: $\cl^{s}$ if $c(s) = -1$, $s$ if $c(s) = 0$, $\cl1{s}$ if $c(s) = 1$, and $\cl2{s}$ if $c(s) = 2$. Let us look now at a concrete example of this construction. We will add the lower part to the upper part \Bp in Figure~\ref{upper_part}, and thereby complete the complementation of the example automaton $A$ in Figure~\ref{example_automaton}.

% First of all, we assign colour $-1$ all the sets of the states of \Bp. We might then start processing the state $(\cl^{\qm0})$, let us call it $p_{pred}$. The resulting successor tuple, without the colours, of $p_{pred}$ is, as in the upper part, $(\qqm02,\qm1)$. We now have to determine the colours of the sets \qqq02 and \qq1. Since $p_{pred}$ does not contain any 2-coloured sets, we need only to consult the upper matrix in Figure~\ref{colours}. For \qq1, the predecessor set is $\cl^{\qm1}$ with colour $-1$. Furthermore \qq1 is accepting. So, the colour of \qq1 is 2, because we end up in the first-row, second-column cell of the upper matrix ($M_1(1,2)$). The other set, \qqq02, in turn is non-accepting, so its colour is 0 ($M_1(1,1)$). The successor state of $(\cl^{\qm0})$ is thus $(\qqm02,\cl2{\qm1})$.

% We can then continue the construction right with this new state $(\qqm02,\cl2{\qm1})$, and call it $p_{pred}$ in turn. The successing tuple without the colours of $p_{pred}$ is $(\qm0,\qm1,\qm2)$. Since $p_{pred}$ contains a set with colour 2, we have to consult the lower matrix of Figure~\ref{colours} to determine the colours of \qq0, \qq1, and \qq2. For \qq2, we end up with colour 2 ($M_2(3,1)$), because its predecessor set, which is $\cl2{\qm1}$, has colour 2. \qq1 gets colour 1 as it is accepting and its predecessor set, \qqq02, has colour 0 ($M_2(1,2)$). \qq0, which has the same predecessor set, gets colour 0, because it is non-accepting ($M_2(1,1)$). The successor state of $(\qqm02,\cl2{\qm1})$ is thus $(\qm0,\cl1{\qm1},\cl2{\qm2})$.

% \begin{figure}[htb]
% \centering
%   \begin{subfigure}[t]{0.49\textwidth}
%   \centering
%   \ComplementA
%   \caption{Upper part}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[t]{0.49\textwidth}
%   \centering
%   \ComplementB
%   \caption{Complete}
%   \end{subfigure}

%   \begin{subfigure}[t]{0.49\textwidth}
%   \centering
%   \ComplementC
%   \caption{Upper part}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[t]{0.49\textwidth}
%   \centering
%   \ComplementD
%   \caption{Complete}
%   \end{subfigure}
% \caption{The final complement automaton $B$.}
% \label{complement}
% \end{figure}

% \begin{figure}[htb]
% \centering
% \Complement
% \end{figure}

% The construction continues in this way until every state has been processed. The resulting automaton is shown in Figure~\ref{complement}. The last thing that has to be done is to make every state of the lower part that does not contain colour 2 accepting. In our example, this is only one state. The NBW $B$ in Figure~\ref{complement} is the complement of the NBW $A$ in Figure~\ref{example_automaton}, such that $L(B) = \cl1{L(A)}$. This can be easily verified, since $A$ is empty and $B$ is universal (with regard to the single \om-word $a^\omega$).

% \subsection{Meaning and Function of the Colours}


% \section{Intuition for Correctness}
% The general relation between a non-deterministic automaton $A$ and its complement $B$ is that a word $w$ is accepted by $B$, if and only if all the runs of $A$ on $w$ are rejecting. Of course for the subset-tuple construction, as we have just described it above, this is also true. A formal proof can be found in~\cite{2014_joel_ulrich}. In this section, in contrast, we try to give an intuitive way to understand this correctness. One one hand, there is the question, if there is an accepting run of $B$ on $w$, how can we conclude that all the runs of $A$ on $w$ are rejected?

% \begin{itemize}
% \item If there is an accepting run of $B$ on $w$, how can we conclude that all the runs of $A$ on $w$ are rejected?
% \item If all the runs of $A$ on $w$ are rejected, how can we conclude that there must be an accepting run of $B$ on $w$?
% \end{itemize}


% Since this condition is on \emph{all} runs of $A$, the construction somehow has to keep track of them. 
% \label{lower_part:intuition}
% \begin{figure}
% \begin{center}
% \RunTypes
% \caption{Different notions of runs.}
% \label{run_types}
% \end{center}
% \end{figure}

% The construction of the lower part takes as input the upper part $B^\prime$ (and the initial automaton $A$) and outputs the final complement automaton $B$ with $L(B) = \cl1{L(A)}$. The construction of the lower part is basically an extension of the construction of the upper part that is applied to the states of the upper part. The extension consists therein that every set in the states of the lower part is assigned a \emph{colour}. These colours will be used to keep track of certain properties of runs of $B$ that finally allow to decide which states of the lower part of $B$ may be accepting. In this section we will first explain the mechanical construction of $B$ and give the intuition behind it afterwards.

% There are three colours that sets of the lower part can have, let us call them 0, 1, and 2. The colour of a set says something about the history of the runs that reach this set. We have to clarify what we mean by run at this point. Conceptually, the subset-tuple construction unifies runs of the input automaton $A$. The construction conceptually includes two abstraction levels of this unification. Figure~\ref{runs} illustrates this. The figure shows three copies of two states of the upper part of the last section. The leftmost pair shows in dotted lines the runs of the original automaton $A$. These runs go from $A$-state to $A$-state, and are the ones that are unified by the construction. The middle part shows the conceptual unification of the $A$-runs to at most two outgoing branches per subset-tuple state, one for the accepting successors and one for the non-accepting successors. These runs go from state set to state set and correspond to the run analysis done with reduced split trees. The rightmost part finally shows the real run of the automaton excerpt. This is the run that is seen from the outside, when the inner structure of the states is now known. It unifies all the $A$-runs to one single run.

% In the following we will always refer to the notion of run in the middle of Figure~\ref{runs}. That is, the notion that directly corresponds to reduced split trees. This conceptual view unifies and simplifies the $A$-runs as much as possible, but still guards enough information for figuring out a correct acceptance behaviour of the final complement automaton $B$.

% A run arriving at a set is thus a branch of a corresponding reduced split tree. It can be obtained by starting at the node corresponding to the set in question and following the edges upwards toward the root of the tree. A given set may occur in many reduced split trees, as there is a reduced split tree for every word of $A$'s alphabet. The set of runs arriving at a set are thus the corresponding branches of all the reduced split tree where the set occurs.

% In the construction of the lower part, we are interested in the history of the runs back until the time when they left the upper part. The crucial information is whether this history of a run includes a so-called right-turn. The notion of right-turn can be understood figuratively. In a reduced split tree, a run can be thought of as having at any node $p$ the choice of either going to the accepting child of $p$ or to the non-accepting one. Since in the right-to-left version of reduced split trees accepting children are to the right of non-accepting children, the run literally ``turns right'' when going to the accepting child. Consequently, if a run has a right-turn in its history, then it has visited at least one accepting set since leaving the upper part. On the other hand, if a run has no right-turns in its history, then it has visited no accepting sets since leaving the upper part.

% That leads us back to the colours that we use for labelling the sets of the lower part. The meaning of the colours 0, 1, and 2 is the following.
% \begin{itemize}
% \item 2: the run includes a right-turn in the lower part
% \item 1: the run includes a right-turn in the lower part, but in the $B$-state where the run visited the accepting child, there was already another set with colour 2
% \item 0: the run does not include right-turns in the lower part
% \end{itemize}

% The role of colour 0 and colour 2 should be clear from the above explanations. The role colour 1 is more subtle and we will explain it later in this section when we give the intuition behind the selection of the accepting states of $B$. For now, we will complete the description of how to construct the lower part and thereby the final complement automaton $B$.

% As mentioned, constructing the states of the lower part is done in the same way as constructing the states of the upper part, with the difference that every set $s$ is assigned a colour. This colour depends on the colour of the predecessor set $s_{pred}$ of $s$ and on whether $s$ itself is an accepting or non-accepting set. Furthermore, there are different rules for the two cases where the $B$-state $p$ containing $s_{pred}$ contains one or more 2-coloured sets or does not contain any 2-coloured sets. Figure~\ref{colours} contains the complete rules for determining the colour of set $s$. Note that states of the upper part are treated as all their sets would have colour 0.


% The colour rules are in fact simple. The first rows in the two matrices in Figure~\ref{colours} treat the case where the run was still ``clean'' when it arrived at $s$'s predecessor $s_{pred}$. If now $s$ is the non-accepting child of $s_{pred}$, then the run stays clean and $s$ gets colour 0. But if $s$ is the accepting child, then the run just commits its first right-turn and gets dirty. Depending on whether there is another 2-coloured set in the state, $s$ gets either colour 1 or colour 2. The remaining rows in the matrices of Figure~\ref{colours} express the continuation of ``dirtiness''.

